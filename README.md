What are we learning from language? Associations between gender biases and distributional semantics in 25 languages
===

Lewis, M. & Lupyan, G. (under review). What are we learning from language? Associations between gender biases
and distributional semantics in 25 languages. [[preprint]](writeup/journal/iat_lang.pdf) [[source]](writeup/journal/iat_lang.Rmd) [[supplemental materials]](https://mollylewis.shinyapps.io/iatlang_SI/).

In this project, we use word embedding models to measure bias in the distributional statistics of 25 languages and find that languages with larger biases tend to have speakers with larger implicit biases (_N_ = 657,335). These biases are further related to the extent that languages mark gender in their lexical forms (e.g., “waiter”/“waitress”) hinting that linguistic biases may be causally related to biases shown in people's implicit judgments.

The file `writeup/journal/iat_lang.Rmd` contains the text of the paper and the code for the analyses reported in the paper. The entire manuscript can be re-rendered from this Rmarkdown file. A rendered version of the paper can be found at `writeup/journal/iat_lang.pdf`. The `analysis` directory contains all scripts used to pre-process the data before analysis. The `data` directory contains all the relevant data.  The Supplemental Materials to the paper can be found at https://mollylewis.shinyapps.io/iatlang_SI/, and in the repository at `paper/jounal/SI/`.

Below is a key figure from the paper (Fig. 2) showing that languages with more gender-biased language statistics tend to have speakers with greater gender bias.

<br>

<img src="writeup/journal/iat_lang_files/figure-latex/unnamed-chunk-11-1.png?raw=true" height="400">



Feel free to email me with questions and comments at mollyllewis@gmail.com.
