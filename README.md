Associations between gender biases and distributional semantics in 25 languages
===

Lewis, M. & Lupyan, G. (in press). Associations between gender biases
and distributional semantics in 25 languages. _Nature Human Behavior_. [[preprint]](writeup/journal/iat_lang.pdf) [[source]](writeup/journal/iat_lang.Rmd) [[supplemental materials]](https://mollylewis.shinyapps.io/iatlang_SI/)


<br>

<img src="resources/key_fig.png?raw=true" height="400">

In this project, we use word embedding models to measure bias in the distributional statistics of 25 languages and find that languages with larger biases tend to have speakers with larger implicit biases (_N_ = 657,335). These biases are further related to the extent that languages mark gender in their lexical forms (e.g., “waiter”/“waitress”) hinting that linguistic biases may be causally related to biases shown in people's implicit judgments.

The file `writeup/journal/iat_lang.Rmd` contains the text of the paper and the code for the analyses reported in the paper. The entire manuscript can be re-rendered from this Rmarkdown file. A rendered version of the paper can be found at `writeup/journal/iat_lang.pdf`. The `analysis` directory contains all scripts used to pre-process the data before analysis. The `data` directory contains all the relevant data.  The Supplemental Materials to the paper can be found at https://mollylewis.shinyapps.io/iatlang_SI/, and in the repository at `paper/jounal/SI/`.

The above figure from teh paper suggests that languages with more gender-biased language statistics tend to have speakers with greater gender bias.

Feel free to email me with questions and comments at mollyllewis@gmail.com.
