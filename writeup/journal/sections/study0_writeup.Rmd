# Description of Cross-Cultural Dataset of Psychological Gender Bias

```{r}
library(tidyverse)
library(broom)
library(here)
```
## Materials and Methods
To quantify cross-cultural gender bias, we used data from a large-scale administration of an Implicit  Association Task [IAT; @greenwald1998measuring] by Project Implicit [https://implicit.harvard.edu/implicit/; @nosek2002harvesting]. The IAT measures the strength of respondents' implicit associations between two pairs of concepts (e.g., male-career/female-family vs. male-family/female-career) accessed via words (e.g., “man," “business”). The underlying assumption of the IAT  is that words denoting more similar meanings should be easier to pair together compared to more dissimilar pairs. 

Meanings are paired in the task by assigning them to the same response keys in a two-alternative forced-choice categorization task. In the critical blocks of the task, meanings are assigned to keys in a way that is either bias-congruent (i.e.\ Key A = male/career; Key B = female/family) or bias-incongruent (i.e.\ Key A = male/family; Key B = female/career). Participants are then presented with a word related to one of the four concepts and asked to classify it as quickly as possible (see Study 1b Methods for list of target words). Slower reaction times in the bias-incongruent blocks relative to the bias-congruent blocks are interpreted as indicating an implicit association between the corresponding concepts (i.e.\ a bias to associate male with career and female with family).

```{r}
BY_PARTICIPANT_DF <-  here("data/study0/processed/by_participant_df.csv")
participant_iat <- read_csv(BY_PARTICIPANT_DF)
country_ns_final <- count(participant_iat, country_code)
```

We analyzed gender-career IAT scores collected by Project Implicit between 2005 and 2016, restricting our sample based on participants' reaction times and error rates using the same criteria described in Nosek, Banjai, and Greenwald (2002, pg.\ 104). We only analyzed data for countries that had complete demographic information and complete data from the IAT for least 400 participants (2% of these respondents did not give responses to the explicit bias question). This cutoff was arbitrary, but the pattern of findings reported here holds for a range of minimum participant values (see SM\footnote{Available here: \url{https://mollylewis.shinyapps.io/iatlang_SI/}}). Our final sample included `r format(nrow(participant_iat), big.mark=",")` participants from `r nrow(country_ns_final)` countries, with a median of `r format(round(median(country_ns_final$n)), big.mark = ",")` participants per country. Importantly, although the respondents were from largely non-English speaking countries, the IAT was conducted in English. We do not have language background data from the participants, but we assume that a large fraction of the respondents from non-English speaking countries were native speakers of the dominant language of the country and second language speakers of English. The fact that the test was administered in English lowers the prior likelihood of finding language-specific predictors of the kind we report here. 

To quantify participants performance on the IAT we adopt the widely used _D-score_, which measures the difference between critical blocks for each participant while controlling for  individual differences in response time [@greenwald2003understanding]. After completing the IAT, participants were asked "How strongly do you associate the following with males and females?" for both the words "career" and "family." Participants indicated their response on a Likert scale ranging from _female_ (1) to _male_ (7). We calculated an explicit gender/career bias score for each participant as the Career response minus the Family response, such that greater values indicate a greater bias to associate males with career. 

```{r}
# age
participant_age_correlation <- cor.test(participant_iat$overall_iat_D_score,
                                        participant_iat$log_age) %>%
  tidy()

# sex
sex_summaries <- participant_iat %>%
  group_by(sex) %>%
  summarize(mean_D = mean(overall_iat_D_score),
            sd_D = sd(overall_iat_D_score))

participant_sex_t_test <- t.test(overall_iat_D_score ~ sex, participant_iat) %>%
  tidy()

# block order
participant_order_t_test <- t.test(overall_iat_D_score ~ order, participant_iat) %>%
  tidy()
```


```{r mapplot, fig.env="figure", fig.pos = "t", fig.align='center', fig.height = 5, fig.cap = "Gender bias at the country level as measured by the IAT, adjusted for  participant age, participant sex, and block order. Larger values indicate a larger bias to associate women with the concept of family and men with the concept of career. Countries in grey correspond to countries for which there was insufficient data to estimate the country-level gender bias.", include = F}

BY_COUNTRY_DF <- here("data/study0/processed/by_country_df.csv")
country_iat <- read_csv(BY_COUNTRY_DF)

knitr::include_graphics(here("writeup/journal/figs/map_figure.pdf"))
```

```{r implicit-explicit_corrs}
imp_exp_cor_participant <- cor.test(participant_iat$es_iat_sex_age_order_implicit_resid,
         participant_iat$es_iat_sex_age_order_explicit_resid) %>%
  tidy()

imp_exp_cor_country <- cor.test(country_iat$es_iat_sex_age_order_implicit_resid,
         country_iat$es_iat_sex_age_order_explicit_resid) %>%
  tidy()
```

## Results
At the participant level, implicit bias scores were positively correlated with
participant age (_r_ = `r round(pull(participant_age_correlation, estimate), 2)`, _p_ < .0001). Male participants (_M_ = `r round(pull(filter(sex_summaries, sex == 1), mean_D), 2)`, _SD_ = `r round(pull(filter(sex_summaries, sex == 1), sd_D), 2)`) had a significantly smaller implicit gender bias than female participants (_M_ = `r  round(pull(filter(sex_summaries, sex == 0), mean_D), 2)`, _SD_ = `r round(pull(filter(sex_summaries, sex == 0), sd_D), 2)`; _t_ = `r participant_sex_t_test$statistic`, _p_ < .0001), a pattern consistent with previous findings [@nosek2002harvesting]. Finally, implicit bias scores were larger for participants that received the block of trials with bias-incongruent mappings first relative to the opposite order  (_t_ = `r participant_order_t_test$statistic`, _p_ < .0001). 

Because we did not have language information at the participant level, in the remaining analyses we examine gender bias and its predictors at the country level. To account for the above-mentioned influences on implicit bias, we calculated a residual implicit bias score for each participant, controlling for participant age, participant sex, and block order. We also calculated a residual explicit bias score controlling for the same set of variables. We then averaged across participants to estimate the country-level gender bias  (implicit: _M_ = `r mean(country_iat$es_iat_sex_age_order_implicit_resid)`; _SD_ = `r sd(country_iat$es_iat_sex_age_order_implicit_resid)`; explicit: _M_ = `r mean(country_iat$es_iat_sex_age_order_explicit_resid)`; _SD_ = `r sd(country_iat$es_iat_sex_age_order_explicit_resid)`). Implicit gender biases were moderately correlated with explicit gender biases at the level of participants (_r_ = `r round(pull(imp_exp_cor_participant, estimate), 2)`, _p_ < .0001) but not countries (_r_ = `r round(pull(imp_exp_cor_country, estimate), 2)`, _p_ = `r round(pull(imp_exp_cor_country, p.value), 2)`). 

```{r country_measures}
imp_objective <- cor.test(country_iat$es_iat_sex_age_order_implicit_resid, country_iat$per_women_stem_2012_2017) %>%
  tidy()

exp_objective <- cor.test(country_iat$es_iat_sex_age_order_explicit_resid, country_iat$per_women_stem_2012_2017) %>%
  tidy()

country_age <- cor.test(country_iat$es_iat_sex_age_order_implicit_resid,
                          country_iat$median_country_age) %>%
  tidy()
```

Do the implicit and explicit biases measured by the Project Implicit dataset predict any real world outcomes? We compared our residual country-level implicit and explicit gender biases to a gender equality metric reported by the United Nations Educational, Scientific and Cultural Organization (UNESCO) for each country: the percentage of women among STEM graduates in tertiary education from 2012 to 2017 (Miller et al., 2015; Stoet & Geary, 2018;  available here: http://data.uis.unesco.org/). These data were available for 33 out of 39 of the countries in our sample. Consistent with previous research [@miller2015women], we found that implicit gender bias was negatively correlated with percentage of women in STEM fields: Countries with a smaller gender bias tended to have more women in STEM fields (_r_ = `r round(pull(imp_objective, estimate), 2)`, _p_ < .001). In contrast, there was no relationship between the percentage of women in STEM fields and the explicit gender-bias measure used by Project Implicit (_r_ = `r round(pull(exp_objective, estimate), 2)`, _p_ = `r round(pull(exp_objective, p.value), 2)`). In addition, we found a strong correlation between the median age of each country's population (as reported by the CIA factbook, 2017) and the residual implicit bias (in which participant age was held constant): Countries with older populations tended to have larger gender biases (_r_ = `r round(pull(country_age, estimate), 2)`, _p_ < .0001). 

In sum, we replicate previously-reported patterns of gender bias in the gender-career IAT literature, with roughly comparable effect sizes (c.f.\ Nosek, et al., 2002). The weak correlation between explicit and implicit measures is consistent with claims that these two measures tap into different cognitive constructs [@forscher2016meta]. In addition, we find that an objective measure of gender equality---female enrollment in STEM fields---is associated with implicit gender bias. The finding that older participants show stronger biases may stem from a cohort effect, but it is not obvious why there is a strong positive association between the median age of a country's population and a larger implicit bias when adjusting for the age of individual participants.
