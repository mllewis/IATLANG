```{r}
library(tidyverse)
library(here)
library(ggrepel)
library(lme4)
library(broom)
```

# Study 2: Gender bias and lexicalized gender

If language statistics play a causal role in shaping psychological gender biases, we predicted that those statistics would be influenced by the presence of explictly-marked gender distinctions referring to people. Languages make gender distinctions on words referring to people in order to indicate the biological sex of the referent, as in  "waiter" versus "waitress" in English. We hypothesized that the presence of these kinds of distinctions might *lead to* more gender biased language statistics for those words. This prediction is a stronger test of the language-as-causal hypothesis because these gender markings are fossilized as part of the lexicon, and thus less likely to be caused by people's gender biases. 

Languages can mark gender distinctions on words referring to people either as part of a  grammatical gender system, as in Spanish ("enfermero" (nurse-<span style="font-variant:small-caps;">masc</span>) versus "enfermera" (nurse-<span style="font-variant:small-caps;">fem</span>)), or through idiosyncratic marking on particular nouns (e.g., "waiter" versus "waitress" in English). Languages that have grammatical gender systems make gender distinctions more frequently, since it is an obligatory part of the grammar.  Further, languages that mark gender on the noun tend to mark gender on other arguments in the sentence as part of an agreement system (“el enfermo alto” (the tall nurse-<span style="font-variant:small-caps;">masc</span>) versus “la enferma alta” (the tall nurse-<span style="font-variant:small-caps;">fem</span>)), potentially making the reference to biological sex even more salient to speakers.

Thus, in Study 2, we asked whether languages that make gender distinctions more often on words referring to people tend to have more biased language statistics for those words.  In this cases,  gender marking highlights the gender of the person and thereby might exaggerate the gender biases present in the language. To test this possibility, we used word embedding models to examine the semantic associates that emerge from language statistics for a set words referring to occupations (e.g., "nurse" and "waiter"). We hypothesized that words referring to occupations that contained lexicalized  gender distinctions would be more likely to have biased language statistics. To the extent that language statistics are causally related to people's implicit biases, we also hypothesized that speakers of languages with  more biased language statistics for these words would also have larger overall psychological gender biases, as measured by the IAT. 


### Method

We identified 20 words referring to occupations that were relatively common
<!-- are they? "sailor" is not especially high-frequency--> 
<!--[ML] we tried to select ones we thought all languages would have clear tranlstations for--> 
 and balanced for their perceptions of gender bias in the workforce, on the basis of previously-collected gender perception norms  [@misersky2014norms]. We then translated these words into each of the 26 
 <!-- cf. 25 languages in study 1. are all 26 included here?--> 
 <!--[ML] Zulu is the language in question gere. We have translations for the occupation words in Zulu based on an online dictionary, but we don't have any of the language embedding measures (in Study 1b or 2). Maybe we should just exclude Zulu throughout for consistency?--> languages in our sample, distinguishing between male and female variants (e.g., "waiter" vs. "waitress") where present. The words were translated by consulting native speakers and dictionaries as necessary.

To estimate the extent to which a language lexically encoded gender, we calculated the proportion of male and female forms that were identical for each item, and then averaged across items within each language. This measure reflects the degree to which a language marks gender lexically, with larger values indicating more  gender-neutral forms. We also estimated the extent to which each occupation word was gender biased in its language statistics using word embedding models trained. This measure was obtained using the same procedure as in Study 1a and 1b based on models trained on both subtitle and Wikipedia corpora in each language. Larger values indicate greater gender bias (larger difference between associations to females vs. males). <!-- Note here the measure is female - male, where as male - female in 1a above -> should maybe change this so consistent - yes, definitely.--> We compared these measures to the psychological gender measures described in Study 1b (implicit association bias effect size adjusted for age, sex and block order, and explicit bias score). 

### Results


```{r by_language_data}
# occupation form overlap by language
OCCUPATION_OVERLAP_PATH <- here('data/study2/occupation_gender_scores.csv')
by_lang_scores_tidy <- read_csv(OCCUPATION_OVERLAP_PATH)

# Occupation semantics by language
BY_LANGUAGE_OCCUPATION_PATH  <- here("data/study2/occupation_gender_score_by_language.csv")
occupation_semantics <- read_csv(BY_LANGUAGE_OCCUPATION_PATH) 

# Behavioral IAT by languages measure
BEHAVIORAL_IAT_PATH <- here("data/study0/processed/by_language_df.csv")
iat_behavioral_es <- read_csv(BEHAVIORAL_IAT_PATH) %>%
  rename(language_code = "wiki_language_code") %>%
  select(language_code, median_country_age, 
         prop_male,log_age, es_iat_sex_age_order_explicit_resid,
         es_iat_sex_age_order_implicit_resid, per_women_stem_2012_2017, n_participants)

# Theoretical grammar
#THEORETICAL_GRAMMAR_PATH <- here("data/study2/general_gender_by_lang.csv")
#theoretical_gender <- read_csv(THEORETICAL_GRAMMAR_PATH)  %>%
#  select(language_code, wikipedia_grammar_type) %>%
#  mutate(wikipedia_grammar_type2 = ifelse(wikipedia_grammar_type %in%  c("none", "CN"),
#                                         "No Gender", 
#                                         "Gender")) 

LANG_IAT_PATH <- here("data/study1b/iat_es_lang.csv")
iat_lang_es <- read_csv(LANG_IAT_PATH)

all_es_tidy2 <- full_join(by_lang_scores_tidy, iat_behavioral_es) %>%
 # left_join(theoretical_gender) %>%
  left_join(iat_lang_es)  %>%
  left_join(occupation_semantics) 
```

```{r full_tidy_corrs_for_text}
text_tidy_corrs <- tidy_corrs %>%
  filter(rowname != var2) %>%
  mutate_at(vars(simple_r, partial_r, simple_p, partial_p), ~ round(.,2)) %>%
  rowwise() %>%
  mutate(r_equality_sign = case_when(simple_p < .01 ~ ", _p_ < .01", 
                                     TRUE ~ paste0(", _p_ = ", simple_p)),
          partial_equality_sign = case_when(partial_p < .01 ~  ", _p_ < .01", 
                                     TRUE ~ paste0(", _p_ = ", partial_p)),
          r_print_text = paste0("_r_ = ", simple_r , r_equality_sign),
          partial_print_text = paste0("_r_ = ", partial_r , partial_equality_sign)) %>%
    mutate_if(is.numeric, ~str_remove(as.character(.), "^0+|^-0+")) 

GN_B <- text_tidy_corrs %>%
  filter(rowname ==  "Prop. Gender-Distinct Labels", var2 == "Residualized Behavioral IAT") %>%
  pull(r_print_text)
GN_B_partial <- text_tidy_corrs %>%
  filter(rowname ==  "Prop. Gender-Distinct Labels", var2 == "Residualized Behavioral IAT") %>%
  pull(partial_print_text)

# Note: full table produced in study1_writeup
```

```{r, fig.pos = "!t!", fig.height = 3.5, fig.width = 4, fig.cap = "Residualized behavioral IAT gender bias as a function of the proportion of gender-distinct labels for set of words referring to occupations. Error bands indicate standard error of the model estimate."}

distinct_behavior_corr <- cor(all_es_tidy2$mean_prop_distinct_occs,
     all_es_tidy2$es_iat_sex_age_order_implicit_resid) %>%
  round(2)

# implicit behavioral ~ prop distinct
ggplot(all_es_tidy2, aes(x = mean_prop_distinct_occs,
                    y = es_iat_sex_age_order_implicit_resid)) +
  geom_smooth(method = "lm", alpha = .1) +
  geom_text_repel(aes(label = language_code), size = 3) +
  geom_point() +
  theme_classic() +
  ggtitle("Behavioral Gender Bias and \nLexicalized Gender") +
  ylab("Behavioral IAT Gender Bias \n(residualized)") +
  xlab("Proportion Gender-Distinct Occupation Labels") +
   annotate("text", x = .75, y = -.05, label = 
             paste0("r = ", distinct_behavior_corr), 
           color = "red", size = 4) +
  theme(legend.position = "none",
        text = element_text(size = 10),
        axis.text.y = element_text(angle = 90, hjust = 0.5, size = 12))
```


<!-- Positive relationships are easier to interpret than negative ones, so I switched the polarity in the caption; please adjust figure to match -->
<!-- [ML] Fixed. ] -->

Languages with more distinct forms for male and female referents tended to have speakers with higher psychological gender bias (_M_ = `r  mean(all_es_tidy2$mean_prop_distinct_occs)`, _SD_ = `r  sd(all_es_tidy2$mean_prop_distinct_occs)`; `r GN_B`), even after partialling out the effect of median country age (`r GN_B_partial`; Table 1).

```{r by_word_mixed_effect_models}
GENDER_BIAS_BY_WORD_SUB <- here("data/study2/sub_occupation_gender_score.csv")
GENDER_BIAS_BY_WORD_WIKI <- here("data/study2/wiki_occupation_gender_score.csv")

bias_by_word <- read_csv(GENDER_BIAS_BY_WORD_SUB) %>%
  mutate(model = "sub") %>%
  bind_rows(read_csv(GENDER_BIAS_BY_WORD_WIKI) %>% mutate(model = "wiki")) %>%
  rename(gender_diff_score_fm = gender_diff_score) %>%
  mutate(gender_diff_score_mf = male_score - female_score)

DISTINCT_BY_WORD <- here('data/study2/occupation_gender_scores_by_word.csv')
distinct_by_word <- read_csv(DISTINCT_BY_WORD) %>%
  mutate(mean_distinct = 1 - mean_overlap)

by_word_df <- full_join(bias_by_word, distinct_by_word) %>%
  mutate_if(is.numeric, scale)

# Subtitles model
sub_model <- lmer(gender_diff_score_fm ~ mean_distinct + (mean_distinct|language_code),
                  data = by_word_df %>% filter(model == "sub")) %>%
  tidy() %>%
  filter(term == "mean_distinct")

sub_model_print <- paste0(round(pull(sub_model, estimate),2), 
                          "; _SE_ = ", round(pull(sub_model, std.error),2),
                          "; _t_ = ", round(pull(sub_model, statistic),2))

# Wiki model
wiki_model <- lmer(gender_diff_score_fm ~ mean_distinct + (mean_distinct|language_code),
                   data = by_word_df %>% filter(model == "wiki"))   %>%
  tidy() %>%
  filter(term == "mean_distinct")

wiki_model_print <- paste0(round(pull(wiki_model, estimate),2), 
                          "; _SE_ = ", round(pull(wiki_model, std.error),2),
                          "; _t_ = ", round(pull(wiki_model, statistic),2))
```

```{r by_language_occupation_correlations}
GN_OB_S <- text_tidy_corrs %>%
  filter(rowname ==  "Prop. Gender-Distinct Labels", 
         var2 == "Occupation Bias (Subtitles)") %>%
  pull(r_print_text)
GN_OB_W <- text_tidy_corrs %>%
  filter(rowname ==  "Prop. Gender-Distinct Labels", 
         var2 == "Occupation Bias (Wikipedia)") %>%
  pull(r_print_text)
```

We next examined whether having distinct forms for males and females in a particular occupation was associated with greater gender bias in the language statistics. <!-- Switched polarity from neg to positive in the text; please adjust  model as necessary so that sign of the effect matches the text and the figure -->  <!-- [ML] Fixed --> We fit a mixed effect model predicting degree of gender bias in language statistics (estimated from word embedding models) as a function of degree of overlap between male and female forms for that word, with random intercepts and slopes by language. Degree of form overlap was a strong predictor of language statistic for models trained on both the subtitle corpus ($\beta$ = `r sub_model_print`) and Wikipedia corpus ($\beta$ = `r wiki_model_print`), with words with shared male and female forms tending to have less gender bias. This relationship also held at the level of languages: languages with more distinct forms had a greater gender-career bias in language statistics (Subtitle corpus: `r GN_OB_S`; Wikipedia corpus: `r GN_OB_W`).

```{r behavioral_bias}
B_OB_S <- text_tidy_corrs %>%
  filter(rowname ==  "Residualized Behavioral IAT", 
         var2 == "Occupation Bias (Subtitles)") %>%
  pull(r_print_text)

B_OB_S_partial <- text_tidy_corrs %>%
  filter(rowname ==  "Residualized Behavioral IAT", 
         var2 == "Occupation Bias (Subtitles)") %>%
  pull(partial_print_text)

B_OB_W <- text_tidy_corrs %>%
  filter(rowname ==  "Residualized Behavioral IAT", 
         var2 == "Occupation Bias (Wikipedia)") %>%
  pull(r_print_text)

B_OB_W_partial <- text_tidy_corrs %>%
  filter(rowname ==  "Residualized Behavioral IAT", 
         var2 == "Occupation Bias (Wikipedia)") %>%
  pull(partial_print_text)

#lm(es_iat_sex_age_order_implicit_resid~ subt_occu_semantics + mean_prop_overlap_occs + median_country_age,
#   data = all_es_tidy2)  %>%
#  summary()

#lm(es_iat_sex_age_order_implicit_resid~ wiki_occu_semantics + mean_prop_overlap_occs #+ median_country_age,
 #  data = all_es_tidy2)  %>%
 # summary()
```


Finally, we examined the relationship between gender bias in language statistics and psychological gender bias at the level of languages. Unlike in Study 1, all the target words in the present study referred to people (occupations) and thus potentially could be  marked for the gender of the referenced person. Consequently, if explicit gender marking drives language statistics, we should expect to see a strong positive relationship at the level of languages between bias in language statistics _for occupation words_ and behavioral biases of speakers of that language. Consistent with this prediction, gender bias in language statistics for occpuation words was positively correlated with behavioral gender bias for both language models
(Subtitle corpus: `r B_OB_S`; Wikipedia corpus: `r B_OB_W`), and remained reliable after partialling out the effect of median country age (Subtitle corpus: `r B_OB_S_partial`; Wikipedia corpus: `r B_OB_W_partial`; Figure 4). To examine the relative predictive power of gender bias in language statistics and proportion distinct forms, we fit a linear regression predicting behavioral gender bias with both measures, controlling for median country age. Bias in language statistics did not reliably predict explicit gender bias. [MEDIATION MODEL]

```{r fig.pos = "!t!", fig.height = 3.5, fig.cap = "Residualized behavioral IAT gender bias as a function of mean gender bias of words referring to occupations, with each point corresponding to a language (Study 2). Linguistic biases are estimated from models trained on text in each language from a subtitle corpus (left) and a Wikipedia corpus (right)."}
# plot lang vs behavioral
all_es_tidy2 %>%
  select(language_code, subt_occu_semantics_fm,
         wiki_occu_semantics_fm,
         es_iat_sex_age_order_implicit_resid) %>%
  gather("model", "occ_lang_es", -language_code,
         -es_iat_sex_age_order_implicit_resid) %>%
  mutate(model = fct_recode(model, "Subtitle Embeddings" = "subt_occu_semantics_fm",
                                   "Wikipedia Embeddings" = "wiki_occu_semantics_fm")) %>%
  ggplot(aes(x = occ_lang_es, y = es_iat_sex_age_order_implicit_resid)) +
  facet_wrap( . ~ model) +
  geom_smooth(method = "lm", alpha = .1, size = .9) +
  ggrepel::geom_text_repel(aes(label = language_code), 
                           size = 3, box.padding = 0.1) + 
  geom_point(size = .7) + 
  theme_minimal() +
  ggtitle("Behavioral and Linguistic Gender Biases") +
  ylab("Behavioral IAT Gender Bias (residualized)\n") +
  xlab("Occupation Gender Bias from Language Statistics") +
  theme_classic(base_size = 12) 
```

# Discussion
```{r, eval = F, include = F}
cor.test(full_df$es_iat_sex_age_order_implicit_resid, 
         full_df$mean_prop_overlap_occs)
m_base1 <- lm(es_iat_sex_age_order_implicit_resid ~ mean_prop_overlap_occs + median_country_age,
   data = full_df)
m_base2 <- lm(es_iat_sex_age_order_implicit_resid ~ wikipedia_grammar_type2 + median_country_age,
   data = full_df)
m_additive <- lm(es_iat_sex_age_order_implicit_resid ~ mean_prop_overlap_occs + wikipedia_grammar_type2 + median_country_age,
   data = full_df) 
m_interaction <- lm(es_iat_sex_age_order_implicit_resid ~ mean_prop_overlap_occs * wikipedia_grammar_type2 + median_country_age,
   data = full_df)
anova(m_additive, m_interaction)
# explicit behavioral
cor.test(full_df$es_iat_sex_age_order_explicit_resid, 
         full_df$mean_prop_overlap_occs)
lm(es_iat_sex_age_order_explicit_resid ~ mean_prop_overlap_occs * wikipedia_grammar_type2 + median_country_age,
   data = full_df) %>%
  summary()
# wiki iat
lm(lang_es_wiki ~ mean_prop_overlap_occs * wikipedia_grammar_type2,
   data = full_df) %>%
  summary()
lm(lang_es_sub ~ mean_prop_overlap_occs * wikipedia_grammar_type2,
   data = full_df) %>%
  summary()
lm(scale(lang_es_sub) ~ scale(mean_prop_overlap_occs) * wikipedia_grammar_type2,
   data = full_df) %>%
  summary()
lm(lang_es_wiki ~ mean_prop_overlap_occs +
     lang_es_wiki
   data = full_df) %>%
  summary()
```


```{r mediation, eval = F, include = F}
# y ~ x
lm(es_iat_sex_age_order_implicit_resid ~ mean_prop_overlap_occs, 
  data = all_es_tidy2) %>%
  summary()
# m ~ x
lm(wiki_occu_semantics ~ mean_prop_overlap_occs, 
  data = all_es_tidy2) %>%
  summary()
lm(subt_occu_semantics ~ mean_prop_overlap_occs, 
  data = all_es_tidy2) %>%
  summary()
# y ~ x + m
lm(es_iat_sex_age_order_implicit_resid ~ mean_prop_overlap_occs + wiki_occu_semantics, 
  data = all_es_tidy2) %>%
  summary()
lm(es_iat_sex_age_order_implicit_resid ~  mean_prop_overlap_occs +
     subt_occu_semantics  + 
     median_country_age, 
  data = all_es_tidy2) %>%
  summary()
## testing for mediation
library(multilevel)
sobel(scale(all_es_tidy2$mean_prop_overlap_occs), 
      scale(all_es_tidy2$subt_occu_semantics),
      scale(all_es_tidy2$es_iat_sex_age_order_implicit_resid))
library(robmed)
all_es_tidy2 %>%
  fit_mediation(
    x = "mean_prop_overlap_occs",
    y = "es_iat_sex_age_order_implicit_resid",
    m = "subt_occu_semantics",
    covariates = "median_country_age") %>%
   test_mediation() %>% 
   p_value()
all_es_tidy2 %>%
  fit_mediation(
    x = "mean_prop_overlap_occs",
    y = "es_iat_sex_age_order_implicit_resid",
    m = "subt_occu_semantics") %>%
   test_mediation() %>% 
   p_value()
```
