---
title: "What are we learning from language? Similarity in gender associations and distributional semantics in 25 languages"
author: "Molly Lewis and Gary Lupyan"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: yes
    theme: paper
    toc: yes
    toc_float: no
runtime: shiny
subtitle: Supplementary Information
---

******
******

```{r setup, include = F}
# load packages
library(tidyverse)
library(knitr)
library(langcog)
library(DT)
library(ggrepel)
library(shiny)
library(maps)
library(countrycode)
library(viridis)
library(broom)
library(kableExtra)
library(here)

opts_chunk$set(echo = F, message = F, warning = F, 
               error = F, cache = F, tidy = F, fig.height = 4.5)

tidy_r_to_text_r <- function(tidy_row){
  round_tidy <- tidy_row %>%
    mutate_at(vars(estimate, contains("conf")), round, 2)
  
  p_value <- case_when(pull(round_tidy, p.value) < .0001 ~ "_p_ < .0001",
                       pull(round_tidy, p.value) < .001 ~ "_p_ < .001",
                       TRUE ~ paste0("_p_ = ", round(pull(round_tidy, p.value),2)))
  
  paste0(
    "_r_(",
    pull(round_tidy, parameter),
    ") = ", 
    pull(round_tidy, estimate),
    " [",
    pull(round_tidy, conf.low),
    ", ",
    pull(round_tidy, conf.high),
    "], ",
    p_value
  )
}

theme_set(theme_classic())
options(shiny.sanitize.errors = FALSE)
```  

<a href="https://github.com/mllewis/IATLANG" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm</style>

This document was created from an R markdown file. The manuscript itself was also produced from an R markdown file, and all analyses presented in the paper can be reproduced from that document (https://github.com/mllewis/IATLANG/blob/master/writeup/journal/iat_lang.Rmd). The respository for the project can be found here: https://github.com/mllewis/IATLANG/.

# Description of IAT data

As described in the Main Text, the IAT data come from Project Implicit (https://implicit.harvard.edu/implicit/; Nosek, Banaji, & Greenwald, 2002), for a sample collected 2005 - 2016.

## Demographics{.tabset}
### N by country

```{r}
BY_COUNTRY_DF <- "data/by_country_df.csv"
country_iat <- read_csv(BY_COUNTRY_DF)
```
Number of participants by country after exclusions. Our final sample `r format(sum(country_iat$n_participants), big.mark=",")` participants from `r nrow(country_iat)` countries. Participants were exclude who:

* did not have complete gender, country, age, and implicit IAT measures (53%; the majority of these exclusions (69%) are due to missing IAT data - likely cases where the participant started but did not complete the IAT task).
* had average latencies for either critical block were over 1,800 ms or whose average overall latency was above 1,500 ms (as in Nosek, Banaji, & Greenwald, 2002; 5% of participants with complete data).
* made excess of 25% errors in any single critical block (as in Nosek, Banaji, & Greenwald, 2002; 14% of participants with complete data). 
* were from countries with less than 400 participants (1% of remaining participants; in the  "Correlations by language exclusion threshold" section below we show analyses with a range of threshold values)


```{r, fig.cap = "Note: Data from the US are excluded from this plot because of the large number of participants (N =  638,082)."}
country_iat %>%
  filter(country_name != "United States of America")  %>%
  ggplot(aes(x = fct_reorder(country_name, -n_participants),
                          y = n_participants)) +
         geom_bar(stat = "identity")  +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  xlab("Country Name") +
  ylab("N Participants") +
  scale_y_continuous(breaks = seq(0,30000,5000)) +
  ggtitle("Number of Participants by Country")
```

### Gender by country

Across countries, there tended to be more female participants, compared to male participants (_M_ = `r round(mean(country_iat$prop_male),2)` proportion males; _SD_  = `r round(sd(country_iat$prop_male),2)`)

```{r}
country_gender <- country_iat %>%
  select(country_name, prop_male) %>%
  rename(Male = prop_male) %>%
  mutate(Female = 1 - Male) %>%
  gather("Gender", "prop", -country_name)

country_gender %>%
  ggplot(aes(x = country_name, y = prop, fill = Gender, group = Gender)) +
         geom_bar(stat = "identity")  +
  scale_fill_manual(values = c("red", "blue")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_hline(aes(yintercept = .5), linetype = 2) +
  xlab("Country Name") +
  ylab("Proportion participants") +
  ggtitle("Participant Gender by Country")
```

### Age by country

```{r, fig.cap = "Bars show mean participant age by country; ranges correspond to 95% CIs. Red points show median age by country from CIA factbook data."}
country_iat %>%
  ggplot(aes(x = fct_reorder(country_name, -mean_age),
                          y = mean_age)) +
         geom_bar(stat = "identity")  +
  geom_point(aes(x = fct_reorder(country_name, -mean_age), y = median_country_age), color = "red") +
  geom_linerange(aes(ymin = age_ci_lower, ymax = age_ci_upper)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  xlab("Country Name") +
  ylab("Mean Participant Age (years)") +
  ggtitle("Participant Age by Country")
```


### Language by country
For each country, we identified the language with the most speakers using Ethnologue (Simons & Charles, 2018). Note that Ethnologue reports "Bavarian" as the primary language of Germany, and "Daric" as the primary language of Afghanistan. In order to map between the other data sources in our study, we used the more general language variant for these countries, German and Persian, respectively. 

```{r}
COUNTRY_TO_LANG <- "data/top_lang_by_country_ethnologue.csv"
country_to_lang <- read_csv(COUNTRY_TO_LANG) %>%
  select(country_name, language_name,family, wiki_language_code)  %>%
  arrange(country_name)
  
country_to_lang_tidy <- country_to_lang %>%
  select(-wiki_language_code) %>%
  mutate(language_name = case_when(language_name == "Zulu" ~ "Zulu*",
                                   TRUE ~ language_name))

datatable(country_to_lang_tidy, colnames = c("Country", "Language", "Language Family"),
          options = list(
  autoWidth = TRUE,
  columnDefs = list(list(width = '250px'))
))
```
Asterisks correspond to languages that were excluded from our analysis because word embedding models were unavailable.

## Dependent Measures{.tabset}

Below are histograms for the implicit and explicit measures in the IAT Project Implicit data presented for each country separately. The implicit raw scores are the D-score values (estimate of career-gender association, with postive values indicating strong bias to associate men with career), and the residualized values are the D-scores with participant age, participant sex and trial order residualized out. For the explicit measure, the raw score is the difference between participants answer to the question,  “How strongly do you associate the following with males and females?” for the words “career” and for the word "family". Participants indicated their response on a Likert scale ranging from female (1) to male (7). For each participant, a single explicit score was calculated as the Career response minus the Family response, such that greater values indicate a greater bias to associate males with family. The residualized explicit value is the difference score with participant age, participant sex and trial order residualized out (we had no a priori reason for residualizing out trial order for explicit responses but did so to remain consistent with the residualized implicit measure).

### Implicit

```{r, echo = FALSE, cache = F}
HISTO_DATA_PATH <- "data/DV_histo_data.csv"
histo_data <- read_csv(HISTO_DATA_PATH)

shinyApp(
  ui = fluidPage(
    selectInput("this_country_name", "Select Country:", 
                choices = unique(histo_data$country_name), width = '50%'),
  plotOutput("by_language_plot")

  ),
  
  server = function(input, output) {
    
     output$by_language_plot <- renderPlot({
       histo_data %>%
        filter(country_name == input$this_country_name,
               measure %in% c("overall_iat_D_score", "es_iat_sex_age_order_implicit_resid")) %>%
        mutate(measure = fct_recode(measure, 
                                    Residualized = "es_iat_sex_age_order_implicit_resid",
                                    Raw = "overall_iat_D_score"),
               measure = fct_rev(measure)) %>%
        ggplot(aes(x = bin, y = n)) +
        geom_bar(stat = "identity", width = .2) +
        facet_grid(.~measure)  +
        xlab("Score") +
        ggtitle(paste0("\nImplicit IAT data for: ", input$this_country_name)) + 
        theme(
          strip.text = element_text(size = 16, face = "bold"),
          text = element_text(size = 17),
          legend.position = "none")
    })
  },
  
  options = list(height = 500)
)

 #test <- filter(histo_data, country_name == "Afghanistan",
 #               measure == "es_iat_sex_age_order_implicit_resid")
   
```

### Explicit

```{r, echo = FALSE, cache = F}
shinyApp(
  ui = fluidPage(
    selectInput("this_country_name", "Select Country:", 
                choices = unique(histo_data$country_name), width = '50%'),

  plotOutput("by_language_plot")

  ),
  
  server = function(input, output) {
    
     output$by_language_plot <- renderPlot({
       histo_data %>%
        filter(country_name == input$this_country_name,
               measure %in% c("explicit_dif", 
                              "es_iat_sex_age_order_explicit_resid")) %>%
         mutate(measure = fct_recode(measure, 
                              Residualized = "es_iat_sex_age_order_explicit_resid",
                              Raw = "explicit_dif"),
              measure = fct_rev(measure)) %>%
        ggplot(aes(x = bin, y = n)) +
          geom_bar(stat = "identity", width = 1) +
          facet_grid(.~measure)  +
          xlab("Score") +
         ggtitle(paste0("\nExplicit bias data for: ", input$this_country_name)) + 
         theme(
          strip.text = element_text(size = 16, face = "bold"),
          text = element_text(size = 17),
          legend.position = "none")
    })
  },
  
  options = list(height = 600)
)
```

## Geographic distribution of IAT scores  

Residualized implicit career-gender association (IAT score) shown by country. Larger values (blue) indicate a larger bias to associate men with the concept of career and women with the concept of family. Countries in grey correspond to countries for which there was insufficient data to estimate the country-level career-gender association. Inset shows IAT scores for European countries only.

```{r}
map_world <- map_data(map = "world") %>%
    mutate(country_code = countrycode(region, 'country.name', 'iso2c'))

map_data <- country_iat %>%
  full_join(map_world, by = "country_code") %>%
  filter(lat > -57,
         long > -165)

full_world <- ggplot(map_data, aes(x = long, y = lat,
                            group = group,
                            fill = es_iat_sex_age_order_implicit_resid)) +
  scale_fill_viridis(direction = -1, 
                     limits = c(-.065, .045),
                       breaks = c(-.06, -.04,  -.02, 0, .02, .04),  na.value="white",
                     label = c(" (male-\n family)", " -0.04",  " -0.02", " 0.00", " 0.02", " (male-\n career)"))  +
  geom_polygon(color = "black", size = .1) +
  ggtitle("Implicit career-gender association by country ") +
  theme(
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        legend.position = c(.1, .35),
        plot.margin = margin(t = 60, r= 30, 0, 0, "pt"),
        legend.title = element_blank(),
        legend.key.size = unit(0.3, "in"))


### Europe
euro_countries <- c("Austria","Belgium","Bulgaria","Croatia",
                   "Czech Republic", "France", "Denmark", "Switzerland",
                   "Germany","Greece","Hungary","Ireland","Italy",
                   "Luxembourg","Malta","Netherlands","Poland", "UK",
                   "Portugal","Romania","Slovakia","Slovenia","Spain")

map_europe <- map_data %>%
  filter(region %in% euro_countries)

europe_inset <- ggplot(map_europe, aes(x = long, y = lat,
                            group = group,
                            fill = es_iat_sex_age_order_implicit_resid)) +
  scale_fill_viridis(direction = -1, limits=c(-.065, .045), na.value="white")  +
  #scale_fill_continuous()
  geom_polygon(color = "black", size = .1) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.margin = margin(.2,.2,0,0, "cm"),
        panel.background = element_rect(fill = "white"),
        plot.background = element_rect(
            fill = "white",
            colour = "black",
            size = 2),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        legend.position = "none")

full_world +
  annotation_custom(grob = ggplotGrob(europe_inset),
                    xmin = 40, xmax = 160, ymin = 50, ymax = 130)
```

Note that while Hindi is identified as the most frequently spoken language in India, India is highly multilingual and so Hindi embeddings may be a poor representation of the linguistic statistics for speakers inIndia as a group.

## IAT scores and country age

At the participant level, median country age predicts IAT bias over and above participant age: Countries with older populations tend to have individuals with stronger career-gender associations, even after controlling for participant age. The analysis below presents an additive mixed-effect regression predicting IAT D-score at the participant level with participant age and median country age, controlling for participant sex and trial order. The model includes by-country random intercepts. 

```{r}
MODEL_PATH_0a  <- "data/study_0a_model_print.txt"
model_print_0a <- readChar(MODEL_PATH_0a, file.info(MODEL_PATH_0a)$size)
```
`r model_print_0a`

<br>
<br>
The relationship between median country age and IAT bias holds, even after controlling for the percentage women in STEM. The model below presents an additive mixed effect model predicting IAT D-score at the participant level with participant age, median country age and percentage women in STEM in country,  controlling for participant sex and trial order. The model includes by-country random intercepts. 


```{r}
MODEL_PATH_0b  <- "data/study_0b_model_print.txt"
model_print_0b <- readChar(MODEL_PATH_0b, file.info(MODEL_PATH_0b)$size)
```
`r model_print_0b`

# Study 1b: Career-Gender association across languages
## Replication of Caliskan et al. (2017){.tabset}

```{r english-language-caliskan-es-wiki}
CALISKAN_WIKI_PATH <- "data/caliskan_wiki_es.csv"
wiki_es <- read_csv(CALISKAN_WIKI_PATH,
                            col_names = c("test", "study_name", "wiki"))

CALISKAN_PATH <- "data/caliskan_paper_es.csv"
caliskan_es <- read_csv(CALISKAN_PATH)
all_es <- wiki_es %>%
  left_join(caliskan_es) %>%
  gather("es_source", "d", 4:6)  %>%
  filter(es_source != "original") %>%
  mutate(study_name2 = case_when(test == "WEAT_1" ~ "flowers-insects",
                                  test == "WEAT_2" ~  "instruments-weapons",
                                  test == "WEAT_3" ~  "race", 
                                  test == "WEAT_4" ~  "race",
                                  test == "WEAT_5" ~  "race", 
                                  test == "WEAT_6" ~  "gender-career",
                                  test == "WEAT_7" ~  "gender-math",
                                  test == "WEAT_8" ~  "gender-science",
                                  test == "WEAT_9" ~  "mental-physical",
                                  test == "WEAT_10" ~  "age"),
         WEAT_name = case_when(test == "WEAT_1" ~ "(WEAT 1)",
                                  test == "WEAT_2" ~  "(WEAT 2)",
                                  test == "WEAT_3" ~  "(WEAT 3-5)", 
                                  test == "WEAT_4" ~  "(WEAT 3-5)",
                                  test == "WEAT_5" ~  "(WEAT 3-5)", 
                                  test == "WEAT_6" ~  "(WEAT 6)",
                                  test == "WEAT_7" ~  "(WEAT 7)",
                                  test == "WEAT_8" ~  "(WEAT 8)",
                                  test == "WEAT_9" ~  "(WEAT 9)",
                                  test == "WEAT_10" ~  "(WEAT 10)"),
         point_color = study_name2,
         study_name2 = paste0(as.character(study_name2),
                              "\n", WEAT_name),
         study_name2 = ifelse(es_source == "AC_w2v" & 
                                test %in% c("WEAT_1", 
                                            "WEAT_2",
                                            "WEAT_3",
                                            "WEAT_7", 
                                            "WEAT_8", 
                                            "WEAT_9", 
                                            "WEAT_10", 
                                            "WEAT_6"),
                              study_name2, ""), 
         es_source = fct_recode(es_source,
                                `Common Crawl (GloVe)` = "AC_glove",
                                `Google News (word2vec)` = "AC_w2v"))
gender_bias_es_wiki <- filter(all_es, study_name == "gender-bias-career-family")$wiki[1]
gender_bias_es_cc <- filter(all_es, study_name == "gender-bias-career-family" &
                              es_source == "Common Crawl (GloVe)" )$d[1]
gender_bias_es_gn <- filter(all_es, study_name == "gender-bias-career-family" &
                              es_source == "Google News (word2vec)")$d[1]

```

```{r english-language-caliskan-es-sub}
CALISKAN_SUB_PATH <- "data/caliskan_sub_es.csv"
sub_es <- read_csv(CALISKAN_SUB_PATH,
                            col_names = c("test", "study_name", "sub")) 

all_es_sub <- sub_es %>%
  left_join(caliskan_es) %>%
  gather("es_source", "d", 4:6)  %>%
  filter(es_source != "original") %>%
  mutate(study_name2 = case_when(test == "WEAT_1" ~ "flowers-insects",
                                  test == "WEAT_2" ~  "instruments-weapons",
                                  test == "WEAT_3" ~  "race", 
                                  test == "WEAT_4" ~  "race",
                                  test == "WEAT_5" ~  "race", 
                                  test == "WEAT_6" ~  "gender-career",
                                  test == "WEAT_7" ~  "gender-math",
                                  test == "WEAT_8" ~  "gender-science",
                                  test == "WEAT_9" ~  "mental-physical",
                                  test == "WEAT_10" ~  "age"),
         WEAT_name = case_when(test == "WEAT_1" ~ "(WEAT 1)",
                                  test == "WEAT_2" ~  "(WEAT 2)",
                                  test == "WEAT_3" ~  "(WEAT 3-5)", 
                                  test == "WEAT_4" ~  "(WEAT 3-5)",
                                  test == "WEAT_5" ~  "(WEAT 3-5)", 
                                  test == "WEAT_6" ~  "(WEAT 6)",
                                  test == "WEAT_7" ~  "(WEAT 7)",
                                  test == "WEAT_8" ~  "(WEAT 8)",
                                  test == "WEAT_9" ~  "(WEAT 9)",
                                  test == "WEAT_10" ~  "(WEAT 10)"),
         point_color = study_name2,
         study_name2 = paste0(as.character(study_name2),
                              "\n", WEAT_name),
         study_name2 = ifelse(es_source == "AC_w2v" & 
                                test %in% c("WEAT_1", 
                                            "WEAT_2",
                                            "WEAT_3",
                                            "WEAT_7", 
                                            "WEAT_8", 
                                            "WEAT_9", 
                                            "WEAT_10", 
                                            "WEAT_6"),
                              study_name2, ""), 
         es_source = fct_recode(es_source,
                                `Common Crawl (GloVe)` = "AC_glove",
                                `Google News (word2vec)` = "AC_w2v"))

gender_bias_es_sub <- filter(all_es_sub, study_name == "gender-bias-career-family")$sub[1]
gender_bias_es_cc_sub <- filter(all_es_sub, study_name == "gender-bias-career-family" & es_source == "Common Crawl (GloVe)" )$d[1]
gender_bias_es_gn_sub <- filter(all_es_sub, study_name == "gender-bias-career-family" & es_source == "Google News (word2vec)")$d[1]

```

Here we replicate the original set of Caliskan, Bryson, and Narayanan (2017; henceforth _CBN_) findings using the models trained on the corpora used in our paper, English Wikipedia (Bojanowski, Grave, Joulin, & Mikolov, 2016) and Subtitles (Lison & Tiedemann, 2016; Van Paridon & Thompson, in prep.).

For both the Wikipedia and Subtitle trained models, we calculate an effect size for each of the 10 biases reported in CBN which correspond to behavioral IAT results existing in the literature:   flowers/insects--pleasant/unpleasant, instruments/weapons--pleasant/unpleasant, European-American/Afro-American--pleasant/unpleasant, males/females--career/family, math/arts--male/female, science/arts--male/female, mental-disease/physical-disease--permanent/temporary, and young/old--pleasant/unpleasant (labeled as Word-Embedding Association Test (WEAT) 1-10 in CBN). Note that CBN test three versions of race bias. We calculate the bias using the same effect size metric described in CBN, a  standardized difference score of the relative similarity of the target words to the target attributes (i.e.\ relative similarity of male to career vs.\ relative similarity of female to career). This measure is  analogous to the behavioral effect size measure  where larger values indicate larger gender bias.

The figure below shows the effect size measures derived from the English Wikipedia corpus and the English Subtitle corpus plotted against effect size estimates reported by CBN from two different models (trained on the Common Crawl and  Google News corpora). With the exception of biases related to race and age, effect sizes from our corpora are comparable to those reported by CBN. In particular, for the gender-career IAT---the bias relevant to our current purposes---we estimate the effect size to be  `r round(gender_bias_es_wiki,2)`, while CBN estimates it as approximately  `r round(mean(c(gender_bias_es_cc,gender_bias_es_gn)),2)`.

### Wikipedia
```{r, fig.width = 5, fig.cap = "Effect sizes for the 10 IAT biases types (WEAT 1-10) reported in Caliskan et al.\ (2017; CBN). CBN effect sizes  are plotted against effect sizes derived from the Wikipedia (left) and Subtitle (right) corpora.  Point color corresponds to  bias type, and point shape corresponds to the two CBN models trained on different corpora and with different algorithms."}

ggplot(all_es, aes(x = wiki, 
                   y = d, 
                   shape = es_source, 
                   color = point_color)) +
  geom_abline(intercept = 0, slope = 1, linetype = 2, color = "darkgrey") +
  geom_point(size = 2.5) +
  ylim(-.6, 2.2) +
  xlim(-.6, 2.2) +
  ggtitle("Language-Embedding IAT biases") +
  xlab("Effect size (Wikipedia corpus)") +
  ylab("Effect size (Caliskan, et al., 2017)") +
  geom_text_repel(aes(label = study_name2), 
                             force = 5, 
                             color = "black", 
                             size = 2.3, 
                             fontface = 'bold', 
                             point.padding = 1) +
  theme_minimal() +
  scale_shape_discrete(name = "Caliskan et al. model") +
  scale_color_discrete(guide = FALSE) +
  theme(text = element_text(size = 9),
        legend.position = c(.75, 0.15),
        legend.background = element_rect(fill = "white"),
        legend.text = element_text(size = 9-1),
        legend.margin = margin(3, 3, 0, 3, unit = 'pt'))
```

### Subtitles
```{r, fig.width = 5, fig.cap = "Effect sizes for the 10 IAT biases types (WEAT 1-10) reported in Caliskan et al.\ (2017; CBN). CBN effect sizes  are plotted against effect sizes derived from the Wikipedia (left) and Subtitle (right) corpora.  Point color corresponds to  bias type, and point shape corresponds to the two CBN models trained on different corpora and with different algorithms."}

ggplot(all_es_sub, aes(x = sub, 
                   y = d, 
                   shape = es_source, 
                   color = point_color)) +
  geom_abline(intercept = 0, slope = 1, linetype = 2, color = "darkgrey") +
  geom_point(size = 2.5) +
  ylim(-.6, 2.2) +
  xlim(-.6, 2.2) +
  ggtitle("Language-Embedding IAT biases") +
  xlab("Effect size (Subtitle corpus)") +
  ylab("Effect size (Caliskan, et al., 2017)") +
  geom_text_repel(aes(label = study_name2), 
                             force = 5, 
                             color = "black", 
                             size = 2.3, 
                             fontface = 'bold', 
                             point.padding = 1) +
  theme_minimal() +
  scale_shape_discrete(name = "Caliskan et al. model") +
  scale_color_discrete(guide = FALSE) +
  theme(text = element_text(size = 9),
        legend.position = c(.75, 0.15),
        legend.background = element_rect(fill = "white"),
        legend.text = element_text(size = 9-1),
        legend.margin = margin(3, 3, 0, 3, unit = 'pt'))
```

```{r}
# Language exclusions
#[to do]
#* 20 percent from *calculated* vectors
#* averaged across multiple translations
#* what does it look like when you change this criteria
```

## Descriptive statistics for all language-level measures

Below are the mean and standard deviation estimates for all measures presented in Table 1 of the Main Text.
```{r}
ALL_MEASURES_PATH <- "data/tidy_measures.csv"
all_es <- read_csv(ALL_MEASURES_PATH) %>%
  select(language_name, median_country_age, es_iat_sex_age_order_explicit_resid,
         es_iat_sex_age_order_implicit_resid, per_women_stem_2012_2017,
         lang_es_sub, lang_es_wiki, lang_es_wiki_native, mean_prop_distinct_occs, subt_occu_semantics_fm, 
         wiki_occu_semantics_fm, n_participants)  %>%
        rename(`Residualized Implicit Bias (IAT)` = "es_iat_sex_age_order_implicit_resid",
          `Residualized Explicit Bias` = "es_iat_sex_age_order_explicit_resid",
          `Language IAT (Subtitle)` = "lang_es_sub",
          `Language IAT (Wikipedia)` = "lang_es_wiki",
           `Language IAT (Wikipedia, untranslated)` = "lang_es_wiki_native",
          `Occupation Bias (Subtitle)` = "subt_occu_semantics_fm",
          `Occupation Bias (Wikipedia)` = "wiki_occu_semantics_fm",
          `Prop. Gender-Distinct Labels` = "mean_prop_distinct_occs",
          `Percent Women in STEM` = "per_women_stem_2012_2017",
          `Median Country Age` = "median_country_age")  

summary_stat <- all_es %>%
    select(-"Language IAT (Wikipedia, untranslated)", -n_participants, -language_name) %>%
    summarize_all(mean, na.rm = T) %>%
    gather("Measure", "Mean") %>%
    full_join(
      summarize_all(all_es, sd, na.rm = T) %>%
      gather("Measure", "SD"))

summary_stat_reordered <- summary_stat[c(2,3,4,5,6,7,8,9,1),]

kable(summary_stat_reordered, format = "html", digits = 3) %>%
    kable_styling(font_size = 9)

```

## Correlations by language exclusion threshold
In the Main Text, we report psychological IAT data for participants who came from countries with at least 400 participants. This cutoff was largely arbitrary, but was selected to allow for a relatively large number of languages to be included in our analysis while also excluding languages with small sample sizes (and therefore less reliable estimates). Nevertheless, the pattern of findings we report in the Main Text remains broadly the same when larger thresholds of minimum number of participants per country are used. The plot below shows pairwise correlations between the language bias measures and three psychological/objective measures described in Study 1: Residualized behavorial IAT, residualized explicit IAT, and percent women in STEM. As in the main text, the residualized values are participant age, participant sex, and trial order. Point size corresponds to the number of languages included in the analysis at that threshold, and point color corresponds to the p-value of the pairwise Pearson's _r_ coefficient.

```{r, fig.width = 9, fig.height = 5}
exclusions_df <- "data/corrs_by_exclusions.csv"

corr_exclusions <- read_csv(exclusions_df,
                             col_names = c("var1", "var2", "simple_corr", "simple_p",
                                           "partial_corr", "partial_p", "min_per_country",
                                           "complete_explicit", "n_language_sub",
                                           "n_languages_wiki")) %>%
         filter(min_per_country >= 400)

corr_exclusions_tidy <- corr_exclusions %>%
  rowwise()%>%
  mutate(var1 = sort(c(var1, var2))[1],
         var2 = sort(c(var1, var2))[2]) %>%
  distinct(var1, var2, min_per_country, complete_explicit, .keep_all = T) %>%
  filter(var1 != var2) %>%
  filter(!(var1 %in%  c("Median Country Age", "Residualized Behavioral IAT")) ) %>%
  mutate(simple_p_cat = case_when(simple_p < .05 ~ "p < .05",
                              simple_p < .1 ~ "p < .1",
                              TRUE ~ "p > .1"),
         n = case_when(var1 == "Language IAT (Subtitles)" ~ n_language_sub, 
                       TRUE ~ n_languages_wiki))

women_stem_df <- corr_exclusions_tidy %>%
 filter(var1 == "Percent Women in STEM") %>%
 mutate(var1 = var2,
        var2 = "Percent Women in STEM") %>%
 distinct(var1, var2)

corr_exclusions_tidy %>%
  filter(var1 != "Percent Women in STEM",
         !complete_explicit,) %>%
  bind_rows(women_stem_df) %>%
  filter(!is.na(complete_explicit)) %>%
  ggplot(aes(x = min_per_country, y = simple_corr, 
             group = complete_explicit)) +
  geom_hline(aes(yintercept = 0), linetype = 2) +
  geom_line() +
  ggtitle("Language IAT correlations with range \nof minimum participants per country thresholds") +
  geom_point(aes(color = simple_p_cat, size = n)) +
  facet_grid(var1 ~ var2) +
  labs(color = "p-value", size = "# of languages") +
  ylab("Pairwise Correlation (Pearson's r)") +
  xlab("Minimum number of participants per country") +
  ylim(-.8, .8) +
  theme_bw()
```

## Partial correlations controlling for median country age
Partial correlation (Pearson's r) for all measures in Study 1 and 2 at the level of languages, controlling for median country age. Single asterisks indicate p < .05 and double asterisks indicate p < .01. The + symbol indicates a marginally significant p-value, p < .1.

```{r}
CACHE_TABLE_PATH <- "data/cached_corr_table.csv"
cached_corr_table <- read_csv(CACHE_TABLE_PATH, na = character()) %>%
  rename(" " = X1)

kable(cached_corr_table[c(12:16,18:20),c(-7, -10, -11)],  booktabs = T, escape = F, # partial corrs only
      align = "l") %>% 
  kable_styling(full_width = F,font_size = 9)  
  #row_spec(0, angle = 180) 
```

## Replication on untranslated corpus
Both the Subtitle and Wikipedia corpora likely contain some documents that are translated from other languages (e.g., the Wikipedia article on "Paris" is written in French and then translated into English). The parallel content across languages allows us to estimate the gender bias in language statistics, while holding content constant across languages. Nevertheless, content may itself be a driver of gender bias (e.g. one language may have more articles about male politicians relative to another). 

To understand the contribution of language-specific content on gender bias, we constructed a corpus of Wikipedia articles in each language that were originally written in the target language (untranslated). We identified untranslated articles by examining the [interlanguage links](https://en.wikipedia.org/wiki/Help:Interlanguage_links) on a Wikipedia article page. These links are pointers to the same article content in other languages (e.g. the "Paris" article in French contains a link to the "Paris" article in English). Since the original source language of an article could not be inferred, we excluded all articles that contained one or more interlanguage links. This ensured that all remaining articles contained only text originally written in the target language.

We constructed a corpus for each language containing all untranslated articles. There were a median of 168,326 articles per language (range: 10,307-14,676,484). We trained fastText (Joulin, et al. 2016) on each language corpus with default parameters and a dimension size of 200. We then used these models trained on native text to calculate by-language IAT bias scores and by-language occupation bias scores, using the same procedure as with the models described in the Main Text (Studies 1b and 2).  One language was excluded following the same exclusion criteria as in the main analyses (>= 20% missing words in model; Mandarin), but the results remain the same  when this language is included. 

Using models trained on the untranslated corpora, we replicate the key finding from Study 1b showing a postive correlation between the bias measured behaviorally with the IAT and measured in language (_r_ = .60; _p_ = .002; fig below). Notably, the effect size is somewhat larger relative to the other two corpora types, presumably because additional bias is introduced by allowing the corpus content to vary across languages. 

```{r, fig.width = 5.5}
all_es %>%
  ggplot(aes(x = `Language IAT (Wikipedia, untranslated)`, 
             y = `Residualized Implicit Bias (IAT)`, size = n_participants)) +
  geom_smooth(method = "lm", alpha = .1, size = .9) +
  geom_point(alpha = .2) +
  ggrepel::geom_text_repel(aes(label = language_name), 
                           size = 1.8, box.padding = 0.1) + 
  scale_x_continuous(breaks = c(-.3, -0, .5, 1), 
                     label = c("\n(male-\nfamily)", "0", ".5","1\n(male-\ncareer)") , limits = c(-.35, 1.1)) +
  scale_y_continuous(breaks = c(-.075, -.05, -.025, 0, .025, .05), 
                     label = c("-.075\n(male-\nfamily)", "-.05", "-.025", "0", ".025", ".05\n(male-\ncareer)") , limits = c(-.08, .06) ) +
  scale_size(trans = "log10", labels = scales::comma, name = "N participants") +
  ggtitle("Psychological and Linguistic Career-Gender\nAssociation (Unstranslated Corpus)") +
  ylab("Implicit  Career-Gender\nAssociation (residualized effect size)") +
  annotate("text", y = -.06, x = .75, label = "r = .60**", color = "red" ) +
  xlab("Language Career-Gender Association\n(effect size)") +
  theme_classic()  +
  theme(legend.position = "right")
```

The table below shows the correlation (Pearson’s r) for all measures in Study 1 and 2 at the level of languages, including estimates of language bias obtained from models trained on the untranslated Wikipedia corpus (highlighted in yellow).  

```{r}
kable(cached_corr_table[c(1:11),],  booktabs = T, escape = F, # full corrs only
      align = "l") %>% 
  kable_styling(full_width = F,font_size = 9)  %>%
  row_spec(6,  background = "#ffffed") %>%
  row_spec(10,  background = "#ffffed")
```

Single asterisks indicate p < .05 and double asterisks indicate p < .01. The + symbol indicates a marginally significant p-value, p < .1
 
# Study 1c: Pre-registered Analysis of British vs. American English
The pre-registeration to this study can be found here: https://osf.io/3f9ed.

## IAT Target Words

Presented below are the target words for each of the 31 IATs used in our analyses. Each IAT has two target categories (e.g. "money" and "love") and two attribute categories (e.g. negative and positive). Select an IAT below to view the corresponding set of target words.

```{r, echo = FALSE, cache = F}
WORD_LIST <-"data/all_stim_lists_5.RData"
load(WORD_LIST) # list of target words (all_stim_sets)

iat_types <- map_chr(all_stim_sets,
                     ~pluck(.,"test_name"))

shinyApp(
  ui = fluidPage(
    selectInput("this_iat_name", h4("Select IAT type:"), 
                choices = iat_types, width = '30%'),
  #h5(textOutput("bias_type")),
  textOutput("cat1"),
  textOutput("cat2"),
  textOutput("att1"),
  textOutput("att2")
  ),
  
  server = function(input, output) {
    
    target_iat <- reactive({
      keep(all_stim_sets, ~.x$test_name == input$this_iat_name)[[1]]
     })
            
    output$att1 <- renderText({
        paste("ATTRIBUTE 1: ", paste(pluck(target_iat(), "attribute_1"), 
                                             collapse = ", ") )
    })
    output$att2 <- renderText({
        paste("ATTRIBUTE 2: ", paste(pluck(target_iat(), "attribute_2"), 
                                             collapse = ", ") )
    })
    output$cat1 <- renderText({
        paste("CATEGORY 1: ", paste(pluck(target_iat(), "category_1"), 
                                             collapse = ", ") )
    })
    output$cat2 <- renderText({
        paste("CATEGORY 2: ", paste(pluck(target_iat(), "category_2"), 
                                             collapse = ", ") )
    })
  },
  
  options = list(height = 200)
)

```

## Behavioral data exclusion criteria

We excluded participants using the pre-defined criteria in the AIID dataset, described below. Participants were excluded if any one of the seven criteria were not satisfied.

1. $>$= 35% responses $<$ 300ms responses in any one practice block.
2. $>$= 25% responses $<$ 300ms responses in any one critical block.
3. $>$= 10% responses $<$ 300ms in critical blocks.
4. $>$= 50% error rate in any one practice block.
5. $>$= 40% error rate in practice blocks.
6. $>$= 40% error rate in any one critical block.
7. $>$= 30% error rate in critical blocks.

## Pre-registered model
The exact pre-registered analysis (https://osf.io/3f9ed/) of Study 1c is presented below. Pairwise corelations between all variables (language bias, behavioral bias, and UK-US difference measures) are shown, averaging across estimates of language bias from the 5 model runs. Error bars are 95% CIs. As stated in the pre-registration, the key test of our hypothesis is that the correlation between the UK - US linguistic difference ("Language Bias Difference") and the UK - US behavioral difference  ("Behavioral Bias Difference") is greater than 0 (shown in red below). That data are consistent with this prediction.

The confirmatory dataset is shown on the right, along with the smaller exploratory dataset on the left for reference. 

```{r, fig.height = 4.5}
STUDY1C_ANALYSIS <- "data/study1c_preregistered_analysis.csv"
study1c_data <- read_csv(STUDY1C_ANALYSIS) %>%
  mutate(group = case_when(data_type == "confirmatory" & corr == "Behavioral Bias Difference ~ Language Bias Difference" ~ "targ", TRUE ~ "other"))

ggplot(study1c_data, aes(x = corr, y = mean, color = group)) +
  geom_hline(aes(yintercept = 0), linetype = 2) +
  facet_grid(~ fct_rev(data_type)) +
  geom_pointrange(aes(ymin = ci_lower, max = ci_upper)) +
  theme_classic() +
  scale_color_manual(values = c("black", "red")) +
  xlab("Correlation Type") +
  ylab("Mean correlation") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none",
          plot.margin = margin(0, 0, 0, 5, "cm"))
```

## Mixed-effect model
The full results to the mixed-effect model described in the paper are presented below:

```{r}
MODEL_PATH  <- "data/study_1c_model_print.txt"
model_print <- readChar(MODEL_PATH, file.info(MODEL_PATH)$size)
```
`r model_print`

# Study 2: Gender association and lexicalized gender

## Grammatical gender coding

Below is the binary coding (gender vs. no gender) of each language for a sex-based grammatical gender system, based on WALS (Dryer & Haspelmath, 2013) and other sources when information was not available from WALS.

```{r}
THEORETICAL_GRAMMAR_PATH <- "data/general_gender_by_lang.csv"
theoretical_gender <- read_csv(THEORETICAL_GRAMMAR_PATH)  %>%
  select(language_code, wikipedia_grammar_type) %>%
  mutate(wikipedia_grammar_type2 = ifelse(wikipedia_grammar_type %in%  c("none", "CN"),
                                         "No Gender", 
                                         "Gender"))  %>%
  left_join(country_to_lang %>% select(wiki_language_code, language_name) %>% distinct(language_name, .keep_all = T),
            by = c("language_code" = "wiki_language_code")) %>%
  select(language_name, wikipedia_grammar_type2) %>%
  filter(language_name != "Zulu")


datatable(theoretical_gender, 
          colnames = c("Language", "Sex-based Grammatical Gender Coding"),
          options = list(
  autoWidth = TRUE,
  columnDefs = list(list(width = '100px'))
))
```

## Occupation Items
In Study 2, we selected 20 occupation labels from the set of items used in Misersky, et al. (2014). Listed below are the 20 items along with their perceived gender bias as reported in Misersky, et al. (2014; larger values indicate occupation is perceived to be more closely associated with women).

```{r }
MISERSKY_PATH <- "data/misersky_target_items.csv"
misersky_norms <- read_csv(MISERSKY_PATH)

datatable(misersky_norms, colnames = c("Occupation", 
                    "Perceived Gender Bias \n(Misersky, et al., 2014)"),
          options = list(
  autoWidth = TRUE,
  columnDefs = list(list(width = '300px'))
))

```

## Occupation Translations

Below are the translations of the 20 occupation words for each of the 25 target langauges. "Translation ID" identifies the translation  when multiple  translations were provided for a given occupation/language.

```{r}
TRANSLATION_PATH <- "data/occupation_translations_tidy.csv"
translations <- read_csv(TRANSLATION_PATH) %>%
  select(language, occupation, word_form_type, translation_id, translation) %>%
  arrange(language, occupation, word_form_type) %>%
  mutate(word_form_type = fct_recode(word_form_type, 
                                     "M" = "male_form", 
                                     "F" = "female_form"),
         language = str_to_title(language)) %>%
  filter(language != "Zulu")

datatable(translations, 
          colnames = c("Language", "Occupation", "Gender", 
                       "Translation ID", "Translation"),
          options = list(
              autoWidth = TRUE,
              columnDefs = list(list(width = '500px'))
))
```

## Predicting career-gender association with both language measures 
In this analysis, we predict the magnitude of implicit career-gender association by language with an additive linear model. As predictors, we include   proportion gender distinct labels and linguistic career-gender association (as measured by word embeddings of the IAT words). Model coefficients are shown below for models based on the Subtitle (top) and Wikipedia (bottom) corpora. 

<b> Subtitle Corpus: </b>
```{r}
LANG_MEASURE_PATH <- "data/all_es_tidy2_scaled.csv"
all_lang_model_scaled <- read_csv(LANG_MEASURE_PATH)

# regressions with lang_es_sub/wiki instead of occupation statistics
subt_regression_r2_no_age <- lm(es_iat_sex_age_order_implicit_resid ~ mean_prop_distinct_occs + 
     lang_es_sub, 
   data = all_lang_model_scaled)

subt_regression_r2_no_age  %>%
  tidy() %>%
  mutate(term = fct_recode(term,
         `Language IAT (Subtitle)` = "lang_es_sub",
         `Prop. Gender-Distinct Labels` = "mean_prop_distinct_occs")) %>%
  kable(digits = 3, format = "html") %>%
  kable_styling(font_size = 9)
```
This model accounts for `r round(summary(subt_regression_r2_no_age)$r.squared * 100, 2)`% variance. 

<b> Wikipedia Corpus: </b>
```{r}
wiki_regression_r2_no_age <- lm(es_iat_sex_age_order_implicit_resid ~ mean_prop_distinct_occs + 
     lang_es_wiki, 
   data = all_lang_model_scaled)  

wiki_regression_r2_no_age %>%
  tidy() %>%
  mutate(term = fct_recode(term,
         `Language IAT (Wikipedia)` = "lang_es_wiki",
         `Prop. Gender-Distinct Labels` = "mean_prop_distinct_occs")) %>%
  kable(digits = 3, format = "html") %>%
  kable_styling(font_size = 9)
```
This model accounts for `r round(summary(wiki_regression_r2_no_age)$r.squared * 100, 2)`% variance. 


Presented below are models that include median country age as an additional predictor. 

<b> Subtitle Corpus: </b>
```{r}
# regressions with lang_es_sub/wiki instead of occupation statistics
subt_regression_r2 <- lm(es_iat_sex_age_order_implicit_resid ~ mean_prop_distinct_occs + 
     lang_es_sub +  
     median_country_age, 
   data = all_lang_model_scaled) 

subt_regression_r2 %>%
  tidy() %>%
  mutate(term = fct_recode(term,
         `Language IAT (Subtitle)` = "lang_es_sub",
         `Prop. Gender-Distinct Labels` = "mean_prop_distinct_occs",
         `Median Country Age` = "median_country_age")) %>%
  kable(digits = 3, format = "html") %>%
    kable_styling(font_size = 9)
```
This model accounts for `r round(summary(subt_regression_r2)$r.squared * 100, 2)`% variance. 

<b> Wikipedia Corpus: </b>

```{r}
wiki_regression_r2 <- lm(es_iat_sex_age_order_implicit_resid ~ mean_prop_distinct_occs + 
     lang_es_wiki +  
     median_country_age, 
   data = all_lang_model_scaled)  

wiki_regression_r2 %>%
  tidy() %>%
  mutate(term = fct_recode(term,
         `Language IAT (Wikipedia)` = "lang_es_wiki",
         `Prop. Gender-Distinct Labels` = "mean_prop_distinct_occs",
         `Median Country Age` = "median_country_age")) %>%
  kable(digits = 3, format = "html") %>%
  kable_styling(font_size = 9)
```
This model accounts for `r round(summary(wiki_regression_r2)$r.squared * 100, 2)`% variance. 

# Gender associations in language and other psychological measures{.tabset}

Several recent studies (Falk & Hermle, 2018; Stoet & Geary, 2018) have presented novel theories to account for cases of structural insequality related to gender. Both of these papers argue that psychological differences play a causal role in the emergence of structural inequality. Here, we show that degree of gender bias in language is correlated with these psychological differences at the country level, consistent with the idea that language experience could be playing a causal role in the emergence of psychological differences.

## Falk and Hermle (2018)
```{r}
OTHER_PATH <- "data/tidy_other_psych_measures.csv"

other_data <- read_csv(OTHER_PATH) %>%
  select(country_name, lang_es_sub, genderdif_fh, self_efficacy_diff_sg, gdp_2017,
         es_iat_sex_age_order_implicit_resid, per_women_stem) 

implicit_gender_dif <- cor.test(other_data$lang_es_sub, 
                                other_data$genderdif_fh) %>%
    tidy() %>%
    tidy_r_to_text_r()

implicit_gdp <- cor.test(other_data$lang_es_sub,
                         other_data$gdp_2017) %>%
  tidy() %>%
  tidy_r_to_text_r()
```

Gender differences in preferences (Falk & Hermle, 2018; composite score of “six fundamental preferences with regard to social and nonsocial domains: willingness to take risks; patience, which captures preferences over the intertemporal timing of rewards; altruism; trust; and positive and negative reciprocity, which capture the costly willingness to reward kind actions or to punish unkind actions, respectively.”)  as a function of linguistic gender bias measured in the Subtitle corpus. Thest two measures are correlated (`r implicit_gender_dif`): Countries with greater differences in gender preferences also have greater gender bias present in their languages. We also find that per capita GDP (World Bank database; 2017 GDP per capita (current US$ indicator) is correlated with linguistic gender bias measured in the Subtitle corpus (`r implicit_gdp`).

```{r, fig.height = 4.5, fig.width = 4.5}
ggplot(other_data, aes(x = lang_es_sub, y = genderdif_fh, label = country_name)) +
  ylab("Gender Differences in Preferences\n(Falk & Hermle, 2018)") +
  xlab("Language Career-Gender Association \n(effect size)") +
  ggtitle("Language Career-Gender Association vs.\nGender Differences in Preferences") +
  geom_smooth(method = "lm", alpha = .2) +
  geom_point() +
  geom_text_repel(size = 3) +
  theme_classic(base_size = 12)
```

## Stoet and Geary (2018)
```{r}
lang_sg <- cor.test(other_data$lang_es_sub, 
                    other_data$self_efficacy_diff_sg) %>%
    tidy() %>%
    tidy_r_to_text_r()

boot_mediation_model_sub <- other_data %>%
  mutate_if(is.numeric, scale) %>%
  robmed::fit_mediation(
    x = "lang_es_sub",
    y = "per_women_stem",
    m = "self_efficacy_diff_sg") %>%
   robmed::test_mediation(type = "bca")    # bias-corrected bootstrap
   
sub_p <- round(robmed::p_value(boot_mediation_model_sub),2)

sub_ab <-  boot_mediation_model_sub %>%
  coef() %>%
  as.list() %>%
  pluck("ab") %>%
  round(2)
```

Gender difference in STEM Self Efficacy (Stoet & Geary, 20178; “The sex difference in self efficacy (boys – girls)”) as a function of linguistic gender bias measured in the Subtitle corpus. Thest two measures are correlated (`r lang_sg`):  Countries with greater gender differences in self-efficacy also have greater gender bias present in their languages. Futher, self-efficacy mediated the effect of language statistics on percentage of women in stem (path-ab = `r sub_ab`; _p_ = `r sub_p`), suggesting that language statistics could be critical causal factor underlying gender differences in STEM participation. 


```{r, fig.height = 4.5, fig.width = 4.5}
ggplot(other_data, aes(x = lang_es_sub, y = self_efficacy_diff_sg, label = country_name)) +
  ylab("Gender difference in STEM Self Efficacy\n(Stoet & Geary, 2018)") +
  xlab("Language Career-Gender Association \n(effect size)") +
  ggtitle("Language Career-Gender Association vs.\nGender Differences in STEM Self Efficacy  ") +
  geom_smooth(method = "lm", alpha = .2) +
  geom_point() +
  geom_text_repel(size = 3) +
  theme_classic(base_size = 12)
```



# References 

Benesty, M. (2018). fastrtext: 'fastText' Wrapper for Text Classification and Word Representation (R package version 0.2.5). https://CRAN.R-project.org/package=fastrtext/
Bojanowski, P., Grave, E., Joulin, A., & Mikolov, T. (2016). Enriching word vectors with subword information. https://arxiv.org/abs/1607.04606

Caliskan, A., Bryson, J. J., & Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. _Science_, _356_(6334), 183–186.

Dryer, M. S., & Haspelmath, M. (Eds.). (2013). _WALS online_. Leipzig: Max Planck Institute for Evolutionary Anthropology. Retrieved from http://wals.info/

Falk, A., & Hermle, J. (2018). Relationship of gender differences in preferences to economic development and gender equality. _Science_, 362 (6412), eaas9899.

Joulin A, Grave E, Bojanowski P, Mikolov T (2016) Bag of tricks for efficient text classification. _818arXiv preprint arXiv:1607.01759)_

Lison, P., & Tiedemann, J. (2016). OpenSubtitles2016: Extracting large parallel corpora from movie and TV subtitles. In _Proceedings of the 10th International Conference on Language Resources and Evaluation_.

Misersky, J., Gygax, P. M., Canal, P., Gabriel, U., Garnham, A., Braun, F., . . . others. (2014). Norms on the gender perception of role nouns in Czech, English, French, German, Italian, Norwegian, and Slovak. _Behavior Research Methods_, _46_(3), 841–871.

Nosek, B. A., Banaji, M. R., & Greenwald, A. G. (2002). Harvesting implicit group attitudes and beliefs from a demonstration web site. _Group Dynamics: Theory, Research, and Practice_, _6_(1), 101.

Simons, G. F., & Charles, D. F. (Eds.). (2018). Ethnologue: Languages of the world. Dallas, Texas: Online version: http://www.ethnologue.com. SIL International.

Stoet, G., & Geary, D. C. (2018). The gender-equality paradox in science, technology, engineering, and mathematics education. _Psychological Science_, 29 (4), 581–593.

Van Paridon, J., & Thompson, B. (in prep.). Sub2Vec: Word embeddings from OpenSubtitles in 62 languages.
