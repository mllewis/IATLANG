---
title: 'Language use shapes cultural stereotypes: Large scale evidence from gender'
author: "Molly Lewis and Gary Lupyan"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: yes
    theme: paper
    toc: yes
    toc_float: no
runtime: shiny
subtitle: Supplementary Materials
---

******
******

```{r setup, include = F}
# load packages
library(tidyverse)
library(knitr)
library(langcog)
library(DT)
library(ggrepel)
library(shiny)
library(maps)
library(countrycode)
library(viridis)

opts_chunk$set(echo = T, message = F, warning = F, 
               error = F, cache = T, tidy = F, fig.height = 4.5)

theme_set(theme_classic())
options(shiny.sanitize.errors = FALSE)

```  

This document was created from an R markdown file. The manuscript itself was also produced from an R markdown file, and all analyses presented in the paper can be reproduced from that document (https://github.com/mllewis/IATLANG/blob/master/writeup/journal/iat_lang.Rmd). The respository for the project can be found here: https://github.com/mllewis/IATLANG/.

# Description of IAT data

## Demographics{.tabset}
### N by country

```{r}
PARTICIPANT_DF <- "data/by_participant_df.csv"
participant_df <- read_csv(PARTICIPANT_DF)

country_ns_final <- participant_df %>%
  mutate(country_name = ifelse(country_name == "Hong Kong", "China", country_name)) %>%
  count(country_name) 
```
Number of participants by country after exclusions. Our final sample `r format(nrow(participant_df), big.mark=",")` participants from `r nrow(country_ns_final)` countries. Participants were exclude who:

* did not have complete gender, country, age, and implicit IAT measures (PERCENT)
* were from countries with less than 400 participants (in the  "Correlations by language exclusion threshold" section below we show analyses with a range of threshold values)
* had average latencies for either critical block were over 1,800 ms or whose average overall latency was above 1,500 ms (as in Nosek, Banaji, & Greenwald, 2002; PERCENT)
* made excess of 25% errors in any single critical block (as in Nosek, Banaji, & Greenwald, 2002; PERCENT). 

```{r, fig.cap = "Note: Data from the US are excluded from this plot because of the large number of participants (N =  638,082)."}
country_ns_final %>%
  filter(country_name != "United States of America")  %>%
  ggplot(aes(x = fct_reorder(country_name, -n),
                          y = n)) +
         geom_bar(stat = "identity")  +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  xlab("Country Name") +
  ylab("N Participants") +
  scale_y_continuous(breaks=seq(0,30000,5000)) +
  ggtitle("Number of Participants by Country")
```

### Gender by country

```{r}
country_gender <- participant_df %>%
  mutate(country_name = ifelse(country_name == "Hong Kong", "China", country_name)) %>%
  group_by(country_name) %>%
  summarize(Male = sum(sex)/n(),
            Female = 1-Male) %>%
  gather("Gender", "prop", -country_name)

country_gender_male <- filter(country_gender, Gender == "Male")
```

Across countries, there tended to be more female participants, compared to male participants (_M_ = `r round(mean(country_gender_male$prop),2)` proportion males; _SD_  = `r round(sd(country_gender_male$prop),2)`)

```{r}
country_gender %>%
  ggplot(aes(x = country_name, y = prop, fill = Gender, group = Gender)) +
         geom_bar(stat = "identity")  +
  scale_fill_manual(values = c("red", "blue")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_hline(aes(yintercept = .5), linetype = 2) +
  xlab("Country Name") +
  ylab("Proportion participants") +
  ggtitle("Participant Gender by Country")
```

### Age by country

```{r}
MEDIAN_AGE_PATH <- "data/median_country_age_world_factbook.csv"
median_age <- read_csv(MEDIAN_AGE_PATH)

country_ages <- participant_df %>%
 mutate(country_name = if_else(country_name == "Hong Kong", "China", country_name)) %>%
 mutate(age = exp(log_age)) %>%
 group_by(country_name) %>%
 multi_boot_standard(col = "age")

country_ages_with_median <- country_ages %>%
  left_join(median_age)

```

```{r, fig.cap = "Bars show mean participant age by country; ranges correspond to 95% CIs. Red points show median age by country from CIA factbook data."}
country_ages_with_median %>%
  ggplot(aes(x = fct_reorder(country_name, -mean),
                          y = mean)) +
         geom_bar(stat = "identity")  +
  geom_point(aes(x = fct_reorder(country_name, -mean), y = median_age), color = "red") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  xlab("Country Name") +
  ylab("Mean Participant Age (years)") +
  ggtitle("Participant Age by Country")
```


### Language by country
For each country, we identified the language with the most speakers using Ethnologue (CITATION). Note that Ethnologue reports "Bavarian" as the primary language of Germany, and "Daric" as the primary language of Afghanistan. In order to map between the other data sources in our study, we used the more general language variant for these countries, German and Persian, respectively. In Section 3 below, rather than assume each country has a single language, we estimate language level biases for each country by weighting by the number of speakers in each country.

```{r}
COUNTRY_TO_LANG <- "data/top_lang_by_country_ethnologue.csv"
country_to_lang <- read_csv(COUNTRY_TO_LANG) %>%
  select(country_name, language_name)  %>%
  arrange(country_name)
  
country_to_lang_tidy <- country_to_lang %>%
  mutate(language_name = case_when(language_name == "Zulu" ~ "Zulu*",
                                   TRUE ~ language_name))

datatable(country_to_lang_tidy, colnames = c("Country", "Language"),
          options = list(
  autoWidth = TRUE,
  columnDefs = list(list(width = '200px'))
))
```
Asterisks correspond to languages that were excluded from our analysis because native speakers were not available.

## Dependent Measures{.tabset}

Below are histograms for the implicit and explicit measures in the IAT Project Implicit data presented for each country separately. The implicit raw scores are the D-score values (estimate of gender bias, with postive values indicating strong bias to associate men with career), and the residualized values are the D-scores with participant age, sex and trial order residualized out. For the explicit measure, the raw score is the difference between participants answer to the question,  “How strongly do you associate the following with males and females?” for the words “career” and for the word "family". Participants indicated their response on a Likert scale ranging from female (1) to male (7). For each participant, a single explicit score was calculated as the Career response minus the Family response, such that greater values indicate a greater bias to associate males with family. The residualized explicit value is the difference score with participant age, sex and trial order residualized out (we had no a priori reason for residualizing out trial order for explicit responses but did so to remain consistent with the residualized implicit measure).

### Implicit

```{r, echo = FALSE, cache = F}
shinyApp(
  ui = fluidPage(
    selectInput("this_country_name", "Select Country:", 
                choices = unique(participant_df$country_name), width = '50%'),
  plotOutput("by_language_plot")

  ),
  
  server = function(input, output) {
    
     output$by_language_plot <- renderPlot({
       participant_df %>%
        filter(country_name == input$this_country_name) %>%
        select(overall_iat_D_score, es_iat_sex_age_order_implicit_resid) %>%
        mutate(id = 1:n()) %>%
        gather("measure", "value", -id) %>%
        mutate(measure = fct_recode(measure, 
                                    Residualized = "es_iat_sex_age_order_implicit_resid",
                                    Raw = "overall_iat_D_score"),
               measure = fct_rev(measure)) %>%
        ggplot(aes(x = value)) +
        geom_histogram() +
        facet_grid(.~measure)  +
        xlab("Score") +
        ggtitle(paste0("\nImplicit IAT data for: ", input$this_country_name)) + 
        theme(
          strip.text = element_text(size = 16, face = "bold"),
          text = element_text(size = 17),
          legend.position = "none")
    })
  },
  
  options = list(height = 500)
)
```


Residualized gender bias by country as measured by the IAT. Larger values indicate a larger bias to associate women with the concept of family and men with the concept of career. Countries in grey correspond to countries for which there was insufficient data to estimate the country-level gender bias.
```{r}
BY_COUNTRY_DF <- "data/by_country_df.csv"
country_iat <- read_csv(BY_COUNTRY_DF)


map_world <- map_data(map = "world") %>%
    mutate(country_code = countrycode(region, 'country.name', 'iso2c'))

map_data <- country_iat %>%
  full_join(map_world, by = "country_code") %>%
  filter(lat > -57,
         long > -165)

full_world <- ggplot(map_data, aes(x = long, y = lat,
                            group = group,
                            fill = es_iat_sex_age_order_implicit_resid)) +
  #scale_fill_gradient2(low = "blue", mid = "white", high = "red",
  #                     midpoint = 0, name = "Gender bias") +

  scale_fill_viridis(direction = -1,  limits=c(-.065, .045))  +
  geom_polygon(color = "black", size = .1) +
  ggtitle("Implicit psychological gender bias by country ") +
  theme(
    #text = element_text(size = TEXT_SIZE),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        legend.position = c(.13, .35),
        plot.margin = margin(t = 60, r= 30, 0, 0, "pt"),

        legend.title = element_blank(),
       # legend.background = element_rect(fill = alpha('white', 0)),
        legend.key.size = unit(0.3, "in"))


### Europe
euro_countries <- c("Austria","Belgium","Bulgaria","Croatia",
                   "Czech Republic", "France", "Denmark", "Switzerland",
                   "Germany","Greece","Hungary","Ireland","Italy",
                   "Luxembourg","Malta","Netherlands","Poland", "UK",
                   "Portugal","Romania","Slovakia","Slovenia","Spain")

map_europe <- map_data %>%
  filter(region %in% euro_countries)

europe_inset <- ggplot(map_europe, aes(x = long, y = lat,
                            group = group,
                            fill = es_iat_sex_age_order_implicit_resid)) +
  scale_fill_viridis(direction = -1, limits=c(-.065, .045))  +
  #scale_fill_continuous()
  geom_polygon(color = "black", size = .1) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.margin = margin(.5,.5,0,0, "cm"),
        panel.background = element_rect(fill = "white"),
        plot.background = element_rect(
            fill = "white",
            colour = "black",
            size = 2),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        legend.position = "none")

full_world +
  annotation_custom(grob = ggplotGrob(europe_inset),
                    xmin = 40, xmax =160, ymin = 50, ymax = 130)
```


### Explicit

```{r, echo = FALSE, cache = F}
shinyApp(
  ui = fluidPage(
    selectInput("this_country_name", "Select Country:", 
                choices = unique(participant_df$country_name), width = '50%'),

  plotOutput("by_language_plot")

  ),
  
  server = function(input, output) {
    
     output$by_language_plot <- renderPlot({
       participant_df %>%
         filter(country_name == input$this_country_name) %>%
         select(explicit_dif, es_iat_sex_age_order_explicit_resid) %>%
         mutate(id = 1:n()) %>%
         gather("measure", "value", -id) %>%
         mutate(measure = fct_recode(measure, 
                              Residualized = "es_iat_sex_age_order_explicit_resid",
                              Raw = "explicit_dif"),
         measure = fct_rev(measure)) %>%
        ggplot(aes(x = value)) +
           geom_histogram(binwidth = 1) +
        facet_grid(.~measure)  +
        xlab("Score") +
        ggtitle(paste0("\nExplicit bias data for: ", input$this_country_name)) + 
        theme(
          strip.text = element_text(size = 16, face = "bold"),
          text = element_text(size = 17),
          legend.position = "none")
    })
  },
  
  options = list(height = 600)
)
```

# Replication of Caliskan et al. (2017){.tabset}

```{r english-language-caliskan-es-wiki}
CALISKAN_WIKI_PATH <- "data/caliskan_wiki_es.csv"
wiki_es <- read_csv(CALISKAN_WIKI_PATH,
                            col_names = c("test", "study_name", "wiki"))

CALISKAN_PATH <- "data/caliskan_paper_es.csv"
caliskan_es <- read_csv(CALISKAN_PATH)
all_es <- wiki_es %>%
  left_join(caliskan_es) %>%
  gather("es_source", "d", 4:6)  %>%
  filter(es_source != "original") %>%
  mutate(study_name2 = case_when(test == "WEAT_1" ~ "flowers-insects",
                                  test == "WEAT_2" ~  "instruments-weapons",
                                  test == "WEAT_3" ~  "race", 
                                  test == "WEAT_4" ~  "race",
                                  test == "WEAT_5" ~  "race", 
                                  test == "WEAT_6" ~  "gender-career",
                                  test == "WEAT_7" ~  "gender-math",
                                  test == "WEAT_8" ~  "gender-science",
                                  test == "WEAT_9" ~  "mental-physical",
                                  test == "WEAT_10" ~  "age"),
         WEAT_name = case_when(test == "WEAT_1" ~ "(WEAT 1)",
                                  test == "WEAT_2" ~  "(WEAT 2)",
                                  test == "WEAT_3" ~  "(WEAT 3-5)", 
                                  test == "WEAT_4" ~  "(WEAT 3-5)",
                                  test == "WEAT_5" ~  "(WEAT 3-5)", 
                                  test == "WEAT_6" ~  "(WEAT 6)",
                                  test == "WEAT_7" ~  "(WEAT 7)",
                                  test == "WEAT_8" ~  "(WEAT 8)",
                                  test == "WEAT_9" ~  "(WEAT 9)",
                                  test == "WEAT_10" ~  "(WEAT 10)"),
         point_color = study_name2,
         study_name2 = paste0(as.character(study_name2),
                              "\n", WEAT_name),
         study_name2 = ifelse(es_source == "AC_w2v" & 
                                test %in% c("WEAT_1", 
                                            "WEAT_2",
                                            "WEAT_3",
                                            "WEAT_7", 
                                            "WEAT_8", 
                                            "WEAT_9", 
                                            "WEAT_10", 
                                            "WEAT_6"),
                              study_name2, ""), 
         es_source = fct_recode(es_source,
                                `Common Crawl (GloVe)` = "AC_glove",
                                `Google News (word2vec)` = "AC_w2v"))
gender_bias_es_wiki <- filter(all_es, study_name == "gender-bias-career-family")$wiki[1]
gender_bias_es_cc <- filter(all_es, study_name == "gender-bias-career-family" &
                              es_source == "Common Crawl (GloVe)" )$d[1]
gender_bias_es_gn <- filter(all_es, study_name == "gender-bias-career-family" &
                              es_source == "Google News (word2vec)")$d[1]

```

```{r english-language-caliskan-es-sub}
CALISKAN_SUB_PATH <- "data/caliskan_sub_es.csv"
sub_es <- read_csv(CALISKAN_SUB_PATH,
                            col_names = c("test", "study_name", "sub")) 

all_es_sub <- sub_es %>%
  left_join(caliskan_es) %>%
  gather("es_source", "d", 4:6)  %>%
  filter(es_source != "original") %>%
  mutate(study_name2 = case_when(test == "WEAT_1" ~ "flowers-insects",
                                  test == "WEAT_2" ~  "instruments-weapons",
                                  test == "WEAT_3" ~  "race", 
                                  test == "WEAT_4" ~  "race",
                                  test == "WEAT_5" ~  "race", 
                                  test == "WEAT_6" ~  "gender-career",
                                  test == "WEAT_7" ~  "gender-math",
                                  test == "WEAT_8" ~  "gender-science",
                                  test == "WEAT_9" ~  "mental-physical",
                                  test == "WEAT_10" ~  "age"),
         WEAT_name = case_when(test == "WEAT_1" ~ "(WEAT 1)",
                                  test == "WEAT_2" ~  "(WEAT 2)",
                                  test == "WEAT_3" ~  "(WEAT 3-5)", 
                                  test == "WEAT_4" ~  "(WEAT 3-5)",
                                  test == "WEAT_5" ~  "(WEAT 3-5)", 
                                  test == "WEAT_6" ~  "(WEAT 6)",
                                  test == "WEAT_7" ~  "(WEAT 7)",
                                  test == "WEAT_8" ~  "(WEAT 8)",
                                  test == "WEAT_9" ~  "(WEAT 9)",
                                  test == "WEAT_10" ~  "(WEAT 10)"),
         point_color = study_name2,
         study_name2 = paste0(as.character(study_name2),
                              "\n", WEAT_name),
         study_name2 = ifelse(es_source == "AC_w2v" & 
                                test %in% c("WEAT_1", 
                                            "WEAT_2",
                                            "WEAT_3",
                                            "WEAT_7", 
                                            "WEAT_8", 
                                            "WEAT_9", 
                                            "WEAT_10", 
                                            "WEAT_6"),
                              study_name2, ""), 
         es_source = fct_recode(es_source,
                                `Common Crawl (GloVe)` = "AC_glove",
                                `Google News (word2vec)` = "AC_w2v"))

gender_bias_es_sub <- filter(all_es_sub, study_name == "gender-bias-career-family")$sub[1]
gender_bias_es_cc_sub <- filter(all_es_sub, study_name == "gender-bias-career-family" & es_source == "Common Crawl (GloVe)" )$d[1]
gender_bias_es_gn_sub <- filter(all_es_sub, study_name == "gender-bias-career-family" & es_source == "Google News (word2vec)")$d[1]

```

Here we replicate the original set of Caliskan, Bryson, and Narayanan (2017; henceforth _CBN_) findings using the models trained on the corpora used in our paper, English Wikipedia and Subtitles.

For both the Wikipedia and Subtitle trained models, we calculate an effect size for each of the 10 biases reported in CBN which correspond to behavioral IAT results existing in the literature:   flowers/insects--pleasant/unpleasant, instruments/weapons--pleasant/unpleasant, European-American/Afro-American--pleasant/unpleasant, males/females--career/family, math/arts--male/female, science/arts--male/female, mental-disease/physical-disease--permanent/temporary, and young/old--pleasant/unpleasant (labeled as Word-Embedding Association Test (WEAT) 1-10 in CBN). Note that CBN test three versions of race bias. We calculate the bias using the same effect size metric described in CBN, a  standardized difference score of the relative similarity of the target words to the target attributes (i.e.\ relative similarity of male to career vs.\ relative similarity of female to career). This measure is  analogous to the behavioral effect size measure  where larger values indicate larger gender bias.

The figure below shows the effect size measures derived from the English Wikipedia corpus and the English Subtitle corpus plotted against effect size estimates reported by CBN from two different models (trained on the Common Crawl and  Google News corpora). With the exception of biases related to race and age, effect sizes from our corpora are comparable to those reported by CBN. In particular, for the gender-career IAT---the bias relevant to our current purposes---we estimate the effect size to be  `r round(gender_bias_es_wiki,2)`, while CBN estimates it as approximately  `r round(mean(c(gender_bias_es_cc,gender_bias_es_gn)),2)`.

## Wikipedia
```{r, fig.width = 5, fig.cap = "Effect sizes for the 10 IAT biases types (WEAT 1-10) reported in Caliskan et al.\ (2017; CBN). CBN effect sizes  are plotted against effect sizes derived from the Wikipedia (left) and Subtitle (right corpora).  Point color corresponds to  bias type, and point shape corresponds to the two CBN models trained on different corpora and with different algorithms."}

ggplot(all_es, aes(x = wiki, 
                   y = d, 
                   shape = es_source, 
                   color = point_color)) +
  geom_abline(intercept = 0, slope = 1, linetype = 2, color = "darkgrey") +
  geom_point(size = 2.5) +
  ylim(-.6, 2.2) +
  xlim(-.6, 2.2) +
  ggtitle("Language-Embedding IAT biases") +
  xlab("Effect size (Wikipedia corpus)") +
  ylab("Effect size (Caliskan, et al., 2017)") +
  geom_text_repel(aes(label = study_name2), 
                             force = 5, 
                             color = "black", 
                             size = 2.3, 
                             fontface = 'bold', 
                             point.padding = 1) +
  theme_minimal() +
  scale_shape_discrete(name = "Caliskan et al. model") +
  scale_color_discrete(guide = FALSE) +
  theme(text = element_text(size = 9),
        legend.position = c(.75, 0.15),
        legend.background = element_rect(fill = "white"),
        legend.text = element_text(size = 9-1),
        legend.margin = margin(3, 3, 0, 3, unit = 'pt'))
```

## Subtitles
```{r, fig.width = 5, fig.cap = "Effect sizes for the 10 IAT biases types (WEAT 1-10) reported in Caliskan et al.\ (2017; CBN). CBN effect sizes  are plotted against effect sizes derived from the Wikipedia (left) and Subtitle (right corpora).  Point color corresponds to  bias type, and point shape corresponds to the two CBN models trained on different corpora and with different algorithms."}

ggplot(all_es_sub, aes(x = sub, 
                   y = d, 
                   shape = es_source, 
                   color = point_color)) +
  geom_abline(intercept = 0, slope = 1, linetype = 2, color = "darkgrey") +
  geom_point(size = 2.5) +
  ylim(-.6, 2.2) +
  xlim(-.6, 2.2) +
  ggtitle("Language-Embedding IAT biases") +
  xlab("Effect size (Subtitle corpus)") +
  ylab("Effect size (Caliskan, et al., 2017)") +
  geom_text_repel(aes(label = study_name2), 
                             force = 5, 
                             color = "black", 
                             size = 2.3, 
                             fontface = 'bold', 
                             point.padding = 1) +
  theme_minimal() +
  scale_shape_discrete(name = "Caliskan et al. model") +
  scale_color_discrete(guide = FALSE) +
  theme(text = element_text(size = 9),
        legend.position = c(.75, 0.15),
        legend.background = element_rect(fill = "white"),
        legend.text = element_text(size = 9-1),
        legend.margin = margin(3, 3, 0, 3, unit = 'pt'))
```

# Language exclusions

* 20 percent from *calculated* vectors
* averaged across multiple translations
* what does it look like when you change this criteria

# Correlations by language exclusion threshold
In the main text, we report behavioral IAT data for participants who came from countries with at least 400 participants. This cutoff was largely arbitrary, but was selected to allow for a relatively large number of languages to be included in our analysis while also excluding languages with small sample sizes (and therefore less reliable estimates). Nevertheless, the pattern of findings we report in the main text remains broadly the same when larger thresholds of minimum number of participants per country are used. The plot below shows pairwise correlations between the language bias measures and three behavioral/objective measures: Residualized behavorial IAT, residualized explicit IAT, and percent women in STEM. As in the main text, the residualized values are participant age, sex, and trial order. Point size corresponds to the number of languages included in the analysis at that threshold, and point color corresponds to the p-value of the pairwise Pearson's _r_ coefficient.

```{r, fig.width = 9, fig.height = 5}
exclusions_df <- "data/corrs_by_exclusions.csv"

corr_exclusions <- read_csv(exclusions_df,
                             col_names = c("var1", "var2", "simple_corr", "simple_p",
                                           "partial_corr", "partial_p", "min_per_country",
                                           "complete_explicit", "n_language_sub",
                                           "n_languages_wiki")) %>%
         filter(min_per_country >= 400)

corr_exclusions_tidy <- corr_exclusions %>%
  rowwise()%>%
  mutate(var1 = sort(c(var1, var2))[1],
         var2 = sort(c(var1, var2))[2]) %>%
  distinct(var1, var2, min_per_country, complete_explicit, .keep_all = T) %>%
  filter(var1 != var2) %>%
  filter(!(var1 %in%  c("Median Country Age", "Residualized Behavioral IAT")) ) %>%
  mutate(simple_p_cat = case_when(simple_p < .05 ~ "p < .05",
                              simple_p < .1 ~ "p < .1",
                              TRUE ~ "p > .1"),
         n = case_when(var1 == "Language IAT (Subtitles)" ~ n_language_sub, 
                       TRUE ~ n_languages_wiki))

women_stem_df <- corr_exclusions_tidy %>%
 filter(var1 == "Percent Women in STEM") %>%
 mutate(var1 = var2,
        var2 = "Percent Women in STEM") %>%
 distinct(var1, var2)

corr_exclusions_tidy %>%
  filter(var1 != "Percent Women in STEM",
         !complete_explicit,) %>%
  bind_rows(women_stem_df) %>%
  filter(!is.na(complete_explicit)) %>%
  ggplot(aes(x = min_per_country, y = simple_corr, 
             group = complete_explicit)) +
  geom_hline(aes(yintercept = 0), linetype = 2) +
  geom_line() +
  ggtitle("Language IAT correlations with range \nof minimum participants per country thresholds") +
  #geom_line(aes(linetype = complete_explicit)) +
  geom_point(aes(color = simple_p_cat, size = n)) +
  facet_grid(var1 ~ var2) +
  labs(color = "p-value", size = "# of languages") +
  ylab("Pairwise Correlation (Pearson's r)") +
  xlab("Minimum number of participants per country") +
  ylim(-.8, .8) +
  theme_bw()
```

# Study 2 Items

In Study 2, we select 20 occupation labels from the set of items used in Misersky, et al. (2014). Listed below are the 20 items along with their perceived gender bias as reported in Misersky, et al. (2014; larger values indicate occpuation is perceived as more closely associated with women).

```{r }
STUDY2_WORD_ITEMS <- "data/occupation_gender_scores_by_word.csv"
items <- read_csv(STUDY2_WORD_ITEMS) %>%
  distinct(occupation) %>%
  pull(occupation)

MISERSKY_PATH <- "data/misersky_norms_clean.csv"
misersky_norms_raw <- read_csv(MISERSKY_PATH) 

misersky_norms <- misersky_norms_raw %>%
  filter(language == "english") %>%
  select(-language) %>% 
  mutate(occupation  = substr(occupation, 1, nchar(occupation)-1)) %>% # get rid of plural
  mutate(occupation = case_when(occupation == "postme" ~ "postman/postwoman",
                                occupation == "physician" ~ "doctor/physician",
                                occupation == "secretarie" ~ "secretary",
                                TRUE ~ occupation)) %>%
  filter(occupation %in% items) %>%
  arrange(mean_gender_rating) 

datatable(misersky_norms, colnames = c("Occupation", 
                    "Perceived Gender Bias \n(Misersky, et al., 2014)"),
          options = list(
  autoWidth = TRUE,
  columnDefs = list(list(width = '200px'))
))

```


**References**

Caliskan, A., Bryson, J. J., & Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. _Science_, _356_(6334), 183–186.

Misersky, J., Gygax, P. M., Canal, P., Gabriel, U., Garnham, A., Braun, F., . . . others. (2014). Norms on the gender perception of role nouns in Czech, English, French, German, Italian, Norwegian, and Slovak. _Behavior Research Methods_, _46_(3), 841–871.

Nosek, B. A., Banaji, M. R., & Greenwald, A. G. (2002). Harvesting implicit group attitudes and beliefs from a demonstration web site. _Group Dynamics: Theory, Research, and Practice_, _6_(1), 101.

