---
title: Word 2 vec language pair models
author: Molly Lewis 
date: "`r Sys.Date()`"
output: 
  html_document:
    code_folding: hide
    number_sections: no
    toc: yes
---
  
******

```{r setup, include = F}
rm(list = ls())

# load packages
library(knitr)
library(rmarkdown)
library(tidyverse)
library(langcog)
library(forcats)
library(broom)
library(countrycode)
library(wordVectors)


opts_chunk$set(echo = T, message = F, warning = F, 
               error = F, tidy = F, cache = F)
```

```{r}
lang_pairs <- read_csv("../data/other/countries_lang.csv") %>% 
  distinct(language_code) %>%
  rename(lang_1 = language_code) %>%
  mutate(lang_2 = "en") %>%
  filter(lang_1 != lang_2)
```

# Download subttile here (bottom triangle): http://opus.lingfil.uu.se/OpenSreaubtitles2016.php

### word 2 vec models
https://github.com/bmschmidt/wordVectors/blob/master/vignettes/introduction.Rmd

```{r}

en_nl <- read_file("../data/lang/en-nl.txt/OpenSubtitles2016.en-nl.en")
# m = prep_word2vec(en_nl,destination="en-nl.txt",lowercase=T,bundle_ngrams=2)
#https://stackoverflow.com/questions/21011638/tokenizing-non-english-text-in-python
model <- train_word2vec("cookbooks.txt","cookbook_vectors.bin", vectors=200,threads=4,window=12,iter=5,negative_samples=0)

```