{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Week 4 - Word Embeddings\n",
    "\n",
    "This week, we build on last week's topic modeling techniques by taking a text corpus we have developed, specifying an underlying number of dimensions, and training a model with a neural network auto-encoder (one of Google's word2vec  algorithms) that best describes corpus words in their local linguistic contexts, and exploring their locations in the resulting space to learn about the discursive culture that produced them. Documents here are represented as densely indexed locations in dimensions, rather than sparse mixtures of topics (as in LDA topic modeling), so that distances between those documents (and words) are consistently superior, though they require the full vector of dimension loadings (rather than just a few selected topic loadings) to describe. We will explore these spaces to understand complex, semantic relationships between words, index documents with descriptive words, identify the likelihood that a given document would have been produced by a given vector model, and explore how semantic categories can help us understand the cultures that produced them.\n",
    "\n",
    "For this notebook we will be using the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#All these packages need to be installed from pip\n",
    "import gensim#For word2vec, etc\n",
    "import requests #For downloading our datasets\n",
    "import nltk #For stop words and stemmers\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "import sklearn.metrics.pairwise #For cosine similarity\n",
    "import sklearn.manifold #For T-SNE\n",
    "import sklearn.decomposition #For PCA\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning\n",
    "%matplotlib inline\n",
    "\n",
    "import os #For looking through files\n",
    "import os.path #For managing file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Getting our corpora\n",
    "\n",
    "Instead of downloading our corpora, we have download them in advance; a subset of the [senate press releases](https://github.com/lintool/GrimmerSenatePressReleases) are in `grimmerPressReleases`. We will load them into a DataFrame, but first we need to define a function to convert directories of text files into DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loadDir(targetDir, category):\n",
    "    allFileNames = os.listdir(targetDir)\n",
    "    #We need to make them into useable paths and filter out hidden files\n",
    "    filePaths = [os.path.join(targetDir, fname) for fname in allFileNames if fname[0] != '.']\n",
    "\n",
    "    #The dict that will become the DataFrame\n",
    "    senDict = {\n",
    "        'category' : [category] * len(filePaths),\n",
    "        'filePath' : [],\n",
    "        'text' : [],\n",
    "    }\n",
    "\n",
    "    for fPath in filePaths:\n",
    "        with open(fPath) as f:\n",
    "            senDict['text'].append(f.read())\n",
    "            senDict['filePath'].append(fPath)\n",
    "\n",
    "    return pandas.DataFrame(senDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can use the function in all the directories in `data/grimmerPressReleases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filePath</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Apr2005Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE   FOR IMMEDIATE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Dec2005Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     Washington ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Feb2006Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE      Fact sheet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Feb2007Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     Washington ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Jun2007Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  BOSTON  MA  Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Mar2007Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     Washington ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01May2007Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  The President ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Nov2007Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  Washington  DC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/02Aug2006Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/02Feb2005Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     The Preside...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                           filePath  \\\n",
       "0   Kennedy  data/grimmerPressReleases/Kennedy/01Apr2005Ken...   \n",
       "10  Kennedy  data/grimmerPressReleases/Kennedy/01Dec2005Ken...   \n",
       "20  Kennedy  data/grimmerPressReleases/Kennedy/01Feb2006Ken...   \n",
       "30  Kennedy  data/grimmerPressReleases/Kennedy/01Feb2007Ken...   \n",
       "40  Kennedy  data/grimmerPressReleases/Kennedy/01Jun2007Ken...   \n",
       "50  Kennedy  data/grimmerPressReleases/Kennedy/01Mar2007Ken...   \n",
       "60  Kennedy  data/grimmerPressReleases/Kennedy/01May2007Ken...   \n",
       "70  Kennedy  data/grimmerPressReleases/Kennedy/01Nov2007Ken...   \n",
       "80  Kennedy  data/grimmerPressReleases/Kennedy/02Aug2006Ken...   \n",
       "90  Kennedy  data/grimmerPressReleases/Kennedy/02Feb2005Ken...   \n",
       "\n",
       "                                                 text  \n",
       "0            FOR IMMEDIATE RELEASE   FOR IMMEDIATE...  \n",
       "10           FOR IMMEDIATE RELEASE     Washington ...  \n",
       "20           FOR IMMEDIATE RELEASE      Fact sheet...  \n",
       "30           FOR IMMEDIATE RELEASE     Washington ...  \n",
       "40           FOR IMMEDIATE RELEASE  BOSTON  MA  Se...  \n",
       "50           FOR IMMEDIATE RELEASE     Washington ...  \n",
       "60           FOR IMMEDIATE RELEASE  The President ...  \n",
       "70           FOR IMMEDIATE RELEASE  Washington  DC...  \n",
       "80           FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...  \n",
       "90           FOR IMMEDIATE RELEASE     The Preside...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDir = 'data/grimmerPressReleases'\n",
    "\n",
    "senReleasesDF = pandas.DataFrame()\n",
    "\n",
    "for senatorName in [d for d in os.listdir(dataDir) if d[0] != '.']:\n",
    "    senPath = os.path.join(dataDir, senatorName)\n",
    "    senReleasesDF = senReleasesDF.append(loadDir(senPath, senatorName), ignore_index = True)\n",
    "\n",
    "senReleasesDF[:100:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We also want to remove stop words and stem. Tokenizing requires two steps. Word2Vec needs to retain the sentence structure so as to capture a \"continuous bag of words (CBOW)\" and all of the skip-grams within a word window. The algorithm tries to preserve the distances induced by one of these two local structures. This is very different from clustering and LDA topic modeling which extract unordered words alone. As such, tokenizing is slightly more involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normlizeTokens(tokenLst, stopwordLst = None, stemmer = None, lemmer = None, vocab = None):\n",
    "    #We can use a generator here as we just need to iterate over it\n",
    "\n",
    "    #Lowering the case and removing non-words\n",
    "    workingIter = (w.lower() for w in tokenLst if w.isalpha())\n",
    "\n",
    "    #Now we can use the semmer, if provided\n",
    "    if stemmer is not None:\n",
    "        workingIter = (stemmer.stem(w) for w in workingIter)\n",
    "\n",
    "    #And the lemmer\n",
    "    if lemmer is not None:\n",
    "        workingIter = (lemmer.lemmatize(w) for w in workingIter)\n",
    "\n",
    "    #And remove the stopwords\n",
    "    if stopwordLst is not None:\n",
    "        workingIter = (w for w in workingIter if w not in stopwordLst)\n",
    "        \n",
    "    #We will return a list with the stopwords removed\n",
    "    if vocab is not None:\n",
    "        vocab_str = '|'.join(vocab)\n",
    "        workingIter = (w for w in workingIter if re.match(vocab_str, w))\n",
    "    \n",
    "    return list(workingIter)\n",
    "\n",
    "#initialize our stemmer and our stop words\n",
    "stop_words_nltk = nltk.corpus.stopwords.words('english')\n",
    "snowball = nltk.stem.snowball.SnowballStemmer('english')\n",
    "wordnet = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filePath</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>normalized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Apr2005Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE   FOR IMMEDIATE...</td>\n",
       "      <td>[[FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, REL...</td>\n",
       "      <td>[[immediate, release, immediate, release, cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Dec2005Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     Washington ...</td>\n",
       "      <td>[[FOR, IMMEDIATE, RELEASE, Washington, D, C, T...</td>\n",
       "      <td>[[immediate, release, washington, c, today, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Feb2006Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE      Fact sheet...</td>\n",
       "      <td>[[FOR, IMMEDIATE, RELEASE, Fact, sheets, on, B...</td>\n",
       "      <td>[[immediate, release, fact, sheets, bush, plan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Feb2007Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     Washington ...</td>\n",
       "      <td>[[FOR, IMMEDIATE, RELEASE, Washington, D, C, T...</td>\n",
       "      <td>[[immediate, release, washington, c, today, u,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Jun2007Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  BOSTON  MA  Se...</td>\n",
       "      <td>[[FOR, IMMEDIATE, RELEASE, BOSTON, MA, Senator...</td>\n",
       "      <td>[[immediate, release, boston, senator, edward,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Mar2007Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     Washington ...</td>\n",
       "      <td>[[FOR, IMMEDIATE, RELEASE, Washington, DC, Tod...</td>\n",
       "      <td>[[immediate, release, washington, dc, today, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01May2007Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  The President ...</td>\n",
       "      <td>[[FOR, IMMEDIATE, RELEASE, The, President, is,...</td>\n",
       "      <td>[[immediate, release, president, wrong, veto, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/01Nov2007Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  Washington  DC...</td>\n",
       "      <td>[[FOR, IMMEDIATE, RELEASE, Washington, DC, Sen...</td>\n",
       "      <td>[[immediate, release, washington, dc, senators...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/02Aug2006Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...</td>\n",
       "      <td>[[FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, REL...</td>\n",
       "      <td>[[immediate, release, immediate, release, impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Kennedy</td>\n",
       "      <td>data/grimmerPressReleases/Kennedy/02Feb2005Ken...</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     The Preside...</td>\n",
       "      <td>[[FOR, IMMEDIATE, RELEASE, The, President, gav...</td>\n",
       "      <td>[[immediate, release, president, gave, effecti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                           filePath  \\\n",
       "0   Kennedy  data/grimmerPressReleases/Kennedy/01Apr2005Ken...   \n",
       "10  Kennedy  data/grimmerPressReleases/Kennedy/01Dec2005Ken...   \n",
       "20  Kennedy  data/grimmerPressReleases/Kennedy/01Feb2006Ken...   \n",
       "30  Kennedy  data/grimmerPressReleases/Kennedy/01Feb2007Ken...   \n",
       "40  Kennedy  data/grimmerPressReleases/Kennedy/01Jun2007Ken...   \n",
       "50  Kennedy  data/grimmerPressReleases/Kennedy/01Mar2007Ken...   \n",
       "60  Kennedy  data/grimmerPressReleases/Kennedy/01May2007Ken...   \n",
       "70  Kennedy  data/grimmerPressReleases/Kennedy/01Nov2007Ken...   \n",
       "80  Kennedy  data/grimmerPressReleases/Kennedy/02Aug2006Ken...   \n",
       "90  Kennedy  data/grimmerPressReleases/Kennedy/02Feb2005Ken...   \n",
       "\n",
       "                                                 text  \\\n",
       "0            FOR IMMEDIATE RELEASE   FOR IMMEDIATE...   \n",
       "10           FOR IMMEDIATE RELEASE     Washington ...   \n",
       "20           FOR IMMEDIATE RELEASE      Fact sheet...   \n",
       "30           FOR IMMEDIATE RELEASE     Washington ...   \n",
       "40           FOR IMMEDIATE RELEASE  BOSTON  MA  Se...   \n",
       "50           FOR IMMEDIATE RELEASE     Washington ...   \n",
       "60           FOR IMMEDIATE RELEASE  The President ...   \n",
       "70           FOR IMMEDIATE RELEASE  Washington  DC...   \n",
       "80           FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...   \n",
       "90           FOR IMMEDIATE RELEASE     The Preside...   \n",
       "\n",
       "                                      tokenized_sents  \\\n",
       "0   [[FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, REL...   \n",
       "10  [[FOR, IMMEDIATE, RELEASE, Washington, D, C, T...   \n",
       "20  [[FOR, IMMEDIATE, RELEASE, Fact, sheets, on, B...   \n",
       "30  [[FOR, IMMEDIATE, RELEASE, Washington, D, C, T...   \n",
       "40  [[FOR, IMMEDIATE, RELEASE, BOSTON, MA, Senator...   \n",
       "50  [[FOR, IMMEDIATE, RELEASE, Washington, DC, Tod...   \n",
       "60  [[FOR, IMMEDIATE, RELEASE, The, President, is,...   \n",
       "70  [[FOR, IMMEDIATE, RELEASE, Washington, DC, Sen...   \n",
       "80  [[FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, REL...   \n",
       "90  [[FOR, IMMEDIATE, RELEASE, The, President, gav...   \n",
       "\n",
       "                                     normalized_sents  \n",
       "0   [[immediate, release, immediate, release, cont...  \n",
       "10  [[immediate, release, washington, c, today, se...  \n",
       "20  [[immediate, release, fact, sheets, bush, plan...  \n",
       "30  [[immediate, release, washington, c, today, u,...  \n",
       "40  [[immediate, release, boston, senator, edward,...  \n",
       "50  [[immediate, release, washington, dc, today, s...  \n",
       "60  [[immediate, release, president, wrong, veto, ...  \n",
       "70  [[immediate, release, washington, dc, senators...  \n",
       "80  [[immediate, release, immediate, release, impo...  \n",
       "90  [[immediate, release, president, gave, effecti...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply our functions, notice each row is a list of lists now\n",
    "senReleasesDF['tokenized_sents'] = senReleasesDF['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "senReleasesDF['normalized_sents'] = senReleasesDF['tokenized_sents'].apply(lambda x: [normlizeTokens(s, stopwordLst = stop_words_nltk, stemmer = None) for s in x])\n",
    "\n",
    "senReleasesDF[:100:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Word2Vec\n",
    "\n",
    "We will be using the gensim implementation of [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec).\n",
    "\n",
    "To load our data our data we give all the sentences to the trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "senReleasesW2V = gensim.models.word2vec.Word2Vec(senReleasesDF['normalized_sents'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Inside the word2vec object the words each have a vector. To access the vector directly, use the square braces (`__getitem__`) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.06326377,  2.02479982, -0.09738726,  0.14563167, -1.10790741,\n",
       "        2.10640955, -0.84484929, -0.01115551,  2.46411848, -0.30817747], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senReleasesW2V['president'][:10] #Shortening because it's very large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you want the full matrix, `syn0` stores all the vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.51659167e-01,   1.11746378e-01,   3.39373052e-01, ...,\n",
       "         -1.53112304e+00,  -3.86392683e-01,   7.17271328e-01],\n",
       "       [ -4.15639549e-01,  -2.58935380e+00,   4.33433801e-01, ...,\n",
       "          6.03842199e-01,   1.18445802e+00,   3.39808851e-01],\n",
       "       [  1.27404296e+00,  -1.37027740e-01,  -3.64800286e+00, ...,\n",
       "          4.35518175e-01,   3.34935427e-01,   2.09079838e+00],\n",
       "       ..., \n",
       "       [ -6.67212754e-02,   6.19501546e-02,   4.62294444e-02, ...,\n",
       "         -1.54445390e-03,  -6.92520514e-02,   1.63869839e-02],\n",
       "       [ -1.30032022e-02,  -1.56835839e-02,   5.18649034e-02, ...,\n",
       "          6.89637884e-02,  -4.67118956e-02,   2.74992501e-03],\n",
       "       [ -3.70698161e-02,   2.76115797e-02,   1.43389525e-02, ...,\n",
       "          3.31219323e-02,  -1.86381675e-02,  -5.03743358e-04]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senReleasesW2V.wv.syn0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then, `index2word` lets you translate from the matrix to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'american'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senReleasesW2V.wv.index2word[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can look at a few things that come from the word vectors. The first is to find similar vectors (cosine similarity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('administration', 0.7728768587112427),\n",
       " ('presidents', 0.7355631589889526),\n",
       " ('cheney', 0.6577303409576416),\n",
       " ('administrations', 0.6400836706161499),\n",
       " ('george', 0.6061344742774963),\n",
       " ('responds', 0.5762455463409424),\n",
       " ('veto', 0.5353409051895142),\n",
       " ('quoting', 0.5304190516471863),\n",
       " ('ronald', 0.5139835476875305),\n",
       " ('lamont', 0.5112457275390625)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senReleasesW2V.most_similar('president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wars', 0.6836376190185547),\n",
       " ('disobedience', 0.6507139205932617),\n",
       " ('afghanistan', 0.6269845366477966),\n",
       " ('quagmire', 0.6209313273429871),\n",
       " ('unresisted', 0.6124815940856934),\n",
       " ('foment', 0.6071888208389282),\n",
       " ('battle', 0.6043447852134705),\n",
       " ('chaos', 0.5951266288757324),\n",
       " ('elsewhere', 0.5933961868286133),\n",
       " ('invasion', 0.5822458267211914)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senReleasesW2V.most_similar('war')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Find which word least matches the others within a word set (cosine similarity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'washington'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senReleasesW2V.doesnt_match(['administration', 'administrations', 'presidents', 'president', 'washington'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Find which word best matches the result of a semantic *equation* (here, we seek the words whose vectors best fit the missing entry from the equation: **X + Y - Z = _**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bush', 0.6846977472305298),\n",
       " ('veto', 0.6844460368156433),\n",
       " ('signature', 0.6695114374160767),\n",
       " ('signed', 0.6670805215835571),\n",
       " ('vetoed', 0.6528983116149902),\n",
       " ('reverse', 0.6462544798851013),\n",
       " ('desk', 0.6367318630218506),\n",
       " ('bushs', 0.6363381147384644),\n",
       " ('signing', 0.6148209571838379),\n",
       " ('sign', 0.6067128777503967)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senReleasesW2V.most_similar(positive=['clinton', 'republican'], negative = ['democrat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we see that **Clinton + Republican - Democrat = Bush**. In other words, in this dataset, **Clinton** is to **Democrat** as **Bush** is to **Republican**. Whoah!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also save the vectors for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "senReleasesW2V.save(\"data/senpressreleasesWORD2Vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also use dimension reduction to visulize the vectors. We will start by selecting a subset we want to plot. Let's look at the top words from the set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "numWords = 50\n",
    "targetWords = senReleasesW2V.wv.index2word[:numWords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can then extract their vectors and create our own smaller matrix that preserved the distances from the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wordsSubMatrix = []\n",
    "for word in targetWords:\n",
    "    wordsSubMatrix.append(senReleasesW2V[word])\n",
    "wordsSubMatrix = np.array(wordsSubMatrix)\n",
    "wordsSubMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then we can use PCA to reduce the dimesions (e.g., to 50), and T-SNE to project them down to the two we will visualize. We note that this is nondeterministic process, and so you can repeat and achieve alternative projectsions/visualizations of the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pcaWords = sklearn.decomposition.PCA(n_components = 50).fit(wordsSubMatrix)\n",
    "reducedPCA_data = pcaWords.transform(wordsSubMatrix)\n",
    "#T-SNE is theoretically better, but you should experiment\n",
    "tsneWords = sklearn.manifold.TSNE(n_components = 2).fit_transform(reducedPCA_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We now can plot the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "plt.scatter(tsneWords[:, 0], tsneWords[:, 1], alpha = 0)#Making the points invisible \n",
    "for i, word in enumerate(targetWords):\n",
    "    ax.annotate(word, (tsneWords[:, 0][i],tsneWords[:, 1][i]), size =  20 * (numWords - i) / numWords)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "My visualization above puts ``said`` next to ``congress`` and ``bill`` near ``act``. ``health`` is beside ``care`` and ``national`` abuts ``security``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <span style=\"color:red\">*Your Turn*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that build a word2vec model with your corpus. Interrogate word relationships in the resulting space. Plot a subset of your words. What do these word relationships reveal about the *social* and *cultural game* underlying your corpus? What was surprising--what violated your prior understanding of the corpus? What was expected--what confirmed your knowledge about this domain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Instead of just looking at just how words embed within in the space, we can look at how the different documents relate to each other within the space. First lets load our data--abstracts of most U.S. physics papers from the 1950s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>copyrightYear</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950</td>\n",
       "      <td>10.1103/RevModPhys.22.221</td>\n",
       "      <td>A summarizing account is given of the research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951</td>\n",
       "      <td>10.1103/RevModPhys.23.147</td>\n",
       "      <td>New tables of coulomb functions are presented ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951</td>\n",
       "      <td>10.1103/RevModPhys.23.185</td>\n",
       "      <td>Ionization by electron impact in diatomic gase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951</td>\n",
       "      <td>10.1103/RevModPhys.23.203</td>\n",
       "      <td>It is shown that the conductivity in the ohmic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1951</td>\n",
       "      <td>10.1103/RevModPhys.23.21</td>\n",
       "      <td>The factorization method is an operational pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1951</td>\n",
       "      <td>10.1103/RevModPhys.23.311</td>\n",
       "      <td>A brief account is given of Dyson's proof of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1951</td>\n",
       "      <td>10.1103/RevModPhys.23.315</td>\n",
       "      <td>A systematics is given of all transitions for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1951</td>\n",
       "      <td>10.1103/RevModPhys.23.322</td>\n",
       "      <td>A systematics of the -transitions of even A nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1951</td>\n",
       "      <td>10.1103/RevModPhys.23.328</td>\n",
       "      <td>The available experiments on the absorption sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1952</td>\n",
       "      <td>10.1103/RevModPhys.24.108</td>\n",
       "      <td>The classical theory of the dynamics of viscou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   copyrightYear                        doi  \\\n",
       "0           1950  10.1103/RevModPhys.22.221   \n",
       "1           1951  10.1103/RevModPhys.23.147   \n",
       "2           1951  10.1103/RevModPhys.23.185   \n",
       "3           1951  10.1103/RevModPhys.23.203   \n",
       "4           1951   10.1103/RevModPhys.23.21   \n",
       "5           1951  10.1103/RevModPhys.23.311   \n",
       "6           1951  10.1103/RevModPhys.23.315   \n",
       "7           1951  10.1103/RevModPhys.23.322   \n",
       "8           1951  10.1103/RevModPhys.23.328   \n",
       "9           1952  10.1103/RevModPhys.24.108   \n",
       "\n",
       "                                            abstract  \n",
       "0  A summarizing account is given of the research...  \n",
       "1  New tables of coulomb functions are presented ...  \n",
       "2  Ionization by electron impact in diatomic gase...  \n",
       "3  It is shown that the conductivity in the ohmic...  \n",
       "4  The factorization method is an operational pro...  \n",
       "5  A brief account is given of Dyson's proof of t...  \n",
       "6  A systematics is given of all transitions for ...  \n",
       "7  A systematics of the -transitions of even A nu...  \n",
       "8  The available experiments on the absorption sp...  \n",
       "9  The classical theory of the dynamics of viscou...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apsDF = pandas.read_csv('data/APSabstracts1950s.csv', index_col = 0)\n",
    "apsDF[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will load these as documents into Word2Vec, but first we need to normalize and pick some tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keywords = ['photomagnetoelectric', 'quantum', 'boltzmann', 'proton', 'positron', 'feynman', 'classical', 'relativity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "taggedDocs = []\n",
    "for index, row in apsDF.iterrows():\n",
    "    #Just doing a simple keyword assignment\n",
    "    docKeywords = [s for s in keywords if s in row['normalized_words']]\n",
    "    docKeywords.append(row['copyrightYear'])\n",
    "    docKeywords.append(row['doi']) #This lets us extract individual documnets since doi's are unique\n",
    "    taggedDocs.append(gensim.models.doc2vec.LabeledSentence(words = row['normalized_words'], tags = docKeywords))\n",
    "apsDF['TaggedAbstracts'] = taggedDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "apsDF['tokenized_words'] = apsDF['abstract'].apply(lambda x: nltk.word_tokenize(x))\n",
    "apsDF['normalized_words'] = apsDF['tokenized_words'].apply(lambda x: normlizeTokens(x, stopwordLst = stop_words_nltk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>copyrightYear</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>normalized_words</th>\n",
       "      <th>TaggedAbstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950</td>\n",
       "      <td>10.1103/RevModPhys.22.221</td>\n",
       "      <td>A summarizing account is given of the research...</td>\n",
       "      <td>[A, summarizing, account, is, given, of, the, ...</td>\n",
       "      <td>[summarizing, account, given, research, barium...</td>\n",
       "      <td>([summarizing, account, given, research, bariu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   copyrightYear                        doi  \\\n",
       "0           1950  10.1103/RevModPhys.22.221   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A summarizing account is given of the research...   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0  [A, summarizing, account, is, given, of, the, ...   \n",
       "\n",
       "                                    normalized_words  \\\n",
       "0  [summarizing, account, given, research, barium...   \n",
       "\n",
       "                                     TaggedAbstracts  \n",
       "0  ([summarizing, account, given, research, bariu...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apsDF['TaggedAbstracts'][0]\n",
    "apsDF[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can train a Doc2Vec model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(apsDF['TaggedAbstracts'], size = 100) #Limiting to 100 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can get vectors for the tags/documents, just as we did with words. Documents are actually the centroids (high dimensional average points) of their words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.24434882e-04,  -2.81383446e-03,  -3.49344965e-03,\n",
       "        -3.52120283e-03,   2.10497272e-03,   2.20782077e-03,\n",
       "         4.96080983e-03,  -3.35402158e-03,  -3.26248788e-04,\n",
       "         2.77331891e-03,  -1.83972775e-03,   2.90331925e-04,\n",
       "         2.72146426e-03,   7.75111257e-04,   3.93828377e-03,\n",
       "         1.94841658e-03,  -3.51175666e-03,  -1.09201192e-03,\n",
       "         2.73855217e-03,  -3.34320753e-03,   4.35161730e-03,\n",
       "        -1.02956500e-03,  -4.41436190e-03,  -2.43590376e-03,\n",
       "         1.11444958e-03,  -2.44796812e-03,  -5.45589312e-04,\n",
       "         3.00587411e-03,  -3.47863242e-04,   3.17840627e-03,\n",
       "        -2.67863693e-03,  -1.79236289e-03,   1.81266700e-03,\n",
       "         2.38996069e-03,   2.04479252e-03,  -3.03744595e-03,\n",
       "        -4.92588850e-03,   1.76853879e-04,  -4.66012210e-03,\n",
       "         3.75691219e-03,  -1.05661270e-03,  -3.91381280e-03,\n",
       "        -4.86697163e-03,  -4.46196971e-03,  -2.24144687e-03,\n",
       "        -4.03614389e-03,   3.47469607e-03,   4.88655083e-03,\n",
       "         6.32650510e-04,   2.37191911e-03,  -4.67888080e-03,\n",
       "        -1.77467836e-03,   1.29572977e-03,   2.40358175e-03,\n",
       "        -2.47628242e-03,   2.54080095e-03,  -1.41528808e-03,\n",
       "        -3.71075445e-03,   8.51674937e-04,  -4.00911551e-03,\n",
       "        -3.76231130e-03,  -2.46670051e-03,   4.72649699e-03,\n",
       "         4.71191294e-03,  -3.13749956e-03,   3.53958877e-03,\n",
       "         4.40137461e-03,  -5.49801509e-04,   4.24532266e-03,\n",
       "        -3.64835258e-04,  -2.45296839e-03,   4.50889766e-03,\n",
       "         4.32044780e-03,   4.16686409e-04,   2.83673941e-03,\n",
       "        -1.31994404e-03,   3.42103373e-03,  -3.66482395e-03,\n",
       "        -5.20711299e-04,  -1.16009195e-03,   4.45105042e-03,\n",
       "         3.46452347e-03,   3.04227788e-03,  -4.12658881e-03,\n",
       "         1.18071970e-03,   4.53364803e-04,  -3.65346344e-03,\n",
       "         1.49983665e-04,   4.48696176e-03,  -4.02158825e-03,\n",
       "        -3.58739845e-03,   3.83422681e-04,   7.94954132e-04,\n",
       "        -9.08867733e-05,   1.40343246e-03,   1.80177775e-03,\n",
       "        -2.39937939e-03,   4.46632458e-03,   1.25964067e-03,\n",
       "         3.14748730e-03], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The words can still be accessed in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.71478704e-01,   5.57709754e-01,  -2.39277616e-01,\n",
       "         1.89557302e+00,   1.05721606e-02,   1.13062716e+00,\n",
       "         1.73369372e+00,   5.95275283e-01,   4.26039517e-01,\n",
       "         4.33214158e-01,   5.58934212e-01,  -6.87973857e-01,\n",
       "        -4.06074196e-01,   1.11699112e-01,  -3.59207958e-01,\n",
       "        -1.13094842e+00,  -7.97190517e-02,  -8.48728120e-01,\n",
       "         9.74277258e-01,   1.23627329e+00,   5.92505217e-01,\n",
       "         1.45396519e+00,   1.09852862e+00,   3.42489719e-01,\n",
       "        -3.90426606e-01,  -1.29355490e+00,  -9.51005876e-01,\n",
       "        -1.94677436e+00,  -5.16768277e-01,  -6.09883904e-01,\n",
       "         8.81353542e-02,   1.48576570e+00,  -6.36652231e-01,\n",
       "         4.37380910e-01,   1.02179325e+00,  -5.15523791e-01,\n",
       "        -8.82806599e-01,  -5.93681633e-01,   5.86479545e-01,\n",
       "         2.19993308e-01,  -1.64953887e-01,   7.23905742e-01,\n",
       "         8.08413923e-01,   1.08805335e+00,  -6.96955831e-04,\n",
       "        -1.90924093e-01,   9.79856472e-04,   2.32833937e-01,\n",
       "         3.44960511e-01,  -3.78025807e-02,   9.48707879e-01,\n",
       "        -8.00201118e-01,  -1.40421283e+00,   1.13560832e+00,\n",
       "         8.00560951e-01,   3.64476711e-01,  -5.06980240e-01,\n",
       "        -4.66739625e-01,  -5.60031593e-01,   3.53690863e-01,\n",
       "         1.01710245e-01,  -1.11462556e-01,  -1.04029751e+00,\n",
       "        -7.83195943e-02,   1.31905317e+00,  -2.38048345e-01,\n",
       "        -1.20486641e+00,   1.28770816e+00,   5.76243639e-01,\n",
       "        -1.31630391e-01,  -1.23587966e+00,  -4.80734557e-02,\n",
       "        -1.29160261e+00,   1.08199048e+00,  -1.64711297e-01,\n",
       "        -1.86813498e+00,  -1.87948024e+00,   2.88658410e-01,\n",
       "         1.31255603e+00,   1.28274179e+00,  -3.05215210e-01,\n",
       "        -1.37845695e+00,  -5.19831121e-01,   2.52788901e-01,\n",
       "        -9.67858806e-02,   1.02129245e+00,  -2.70877212e-01,\n",
       "        -5.27822495e-01,  -8.32413316e-01,   3.63097191e-01,\n",
       "         1.67177010e+00,   1.05975235e+00,  -3.12007159e-01,\n",
       "        -7.92535186e-01,  -6.32995069e-01,   5.90241790e-01,\n",
       "         5.45084357e-01,  -7.62816966e-01,  -6.55601323e-01,\n",
       "        -5.97205341e-01], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.syn0[4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can still use the ``most_similar`` command to perform simple semantic equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['energy',\n",
       " 'mev',\n",
       " 'found',\n",
       " 'cross',\n",
       " 'scattering',\n",
       " 'theory',\n",
       " 'results',\n",
       " 'observed',\n",
       " 'field',\n",
       " 'measured',\n",
       " 'obtained',\n",
       " 'state',\n",
       " 'magnetic',\n",
       " 'two',\n",
       " 'temperature',\n",
       " 'section',\n",
       " 'energies',\n",
       " 'values',\n",
       " 'nuclear',\n",
       " 'measurements',\n",
       " 'data',\n",
       " 'electron',\n",
       " 'made',\n",
       " 'function',\n",
       " 'shown',\n",
       " 'given',\n",
       " 'value',\n",
       " 'used',\n",
       " 'one',\n",
       " 'particles',\n",
       " 'experimental',\n",
       " 'electrons',\n",
       " 'interaction',\n",
       " 'method',\n",
       " 'also',\n",
       " 'range',\n",
       " 'decay',\n",
       " 'states',\n",
       " 'distribution',\n",
       " 'kev',\n",
       " 'using',\n",
       " 'angular',\n",
       " 'effect',\n",
       " 'calculated',\n",
       " 'agreement',\n",
       " 'model',\n",
       " 'sections',\n",
       " 'p',\n",
       " 'neutron',\n",
       " 'determined',\n",
       " 'discussed',\n",
       " 'terms',\n",
       " 'protons',\n",
       " 'transition',\n",
       " 'spin',\n",
       " 'spectrum',\n",
       " 'percent',\n",
       " 'reaction',\n",
       " 'level',\n",
       " 'levels',\n",
       " 'resonance',\n",
       " 'absorption',\n",
       " 'order',\n",
       " 'wave',\n",
       " 'number',\n",
       " 'potential',\n",
       " 'may',\n",
       " 'case',\n",
       " 'effects',\n",
       " 'total',\n",
       " 'n',\n",
       " 'mass',\n",
       " 'gamma',\n",
       " 'proton',\n",
       " 'ratio',\n",
       " 'first',\n",
       " 'excited',\n",
       " 'functions',\n",
       " 'large',\n",
       " 'nuclei',\n",
       " 'studied',\n",
       " 'neutrons',\n",
       " 'excitation',\n",
       " 'compared',\n",
       " 'small',\n",
       " 'constant',\n",
       " 'crystal',\n",
       " 'system',\n",
       " 'due',\n",
       " 'transitions',\n",
       " 'possible',\n",
       " 'nucleus',\n",
       " 'radiation',\n",
       " 'produced',\n",
       " 'form',\n",
       " 'rays',\n",
       " 'high',\n",
       " 'region',\n",
       " 'dependence',\n",
       " 'structure',\n",
       " 'general',\n",
       " 'result',\n",
       " 'ev',\n",
       " 'charge',\n",
       " 'equation',\n",
       " 'production',\n",
       " 'low',\n",
       " 'time',\n",
       " 'density',\n",
       " 'ground',\n",
       " 'approximation',\n",
       " 'coupling',\n",
       " 'single',\n",
       " 'particle',\n",
       " 'surface',\n",
       " 'crystals',\n",
       " 'experiments',\n",
       " 'different',\n",
       " 'investigated',\n",
       " 'corresponding',\n",
       " 'relative',\n",
       " 'theoretical',\n",
       " 'well',\n",
       " 'analysis',\n",
       " 'applied',\n",
       " 'temperatures',\n",
       " 'emission',\n",
       " 'derived',\n",
       " 'three',\n",
       " 'various',\n",
       " 'band',\n",
       " 'present',\n",
       " 'respectively',\n",
       " 'intensity',\n",
       " 'equations',\n",
       " 'distributions',\n",
       " 'momentum',\n",
       " 'interactions',\n",
       " 'mesons',\n",
       " 'beam',\n",
       " 'new',\n",
       " 'calculations',\n",
       " 'reactions',\n",
       " 'show',\n",
       " 'experiment',\n",
       " 'polarization',\n",
       " 'maximum',\n",
       " 'elements',\n",
       " 'properties',\n",
       " 'presented',\n",
       " 'meson',\n",
       " 'fields',\n",
       " 'atomic',\n",
       " 'previously',\n",
       " 'ions',\n",
       " 'yield',\n",
       " 'simple',\n",
       " 'k',\n",
       " 'several',\n",
       " 'lattice',\n",
       " 'light',\n",
       " 'elastic',\n",
       " 'capture',\n",
       " 'moment',\n",
       " 'electric',\n",
       " 'good',\n",
       " 'per',\n",
       " 'higher',\n",
       " 'second',\n",
       " 'process',\n",
       " 'calculation',\n",
       " 'spectrometer',\n",
       " 'mean',\n",
       " 'phase',\n",
       " 'free',\n",
       " 'less',\n",
       " 'within',\n",
       " 'consistent',\n",
       " 'differential',\n",
       " 'matrix',\n",
       " 'fission',\n",
       " 'coefficient',\n",
       " 'spectra',\n",
       " 'following',\n",
       " 'atoms',\n",
       " 'lead',\n",
       " 'described',\n",
       " 'gas',\n",
       " 'average',\n",
       " 'comparison',\n",
       " 'thermal',\n",
       " 'considered',\n",
       " 'point',\n",
       " 'current',\n",
       " 'parameters',\n",
       " 'curves',\n",
       " 'study',\n",
       " 'liquid',\n",
       " 'near',\n",
       " 'approximately',\n",
       " 'reported',\n",
       " 'cases',\n",
       " 'angles',\n",
       " 'paper',\n",
       " 'direction',\n",
       " 'change',\n",
       " 'indicate',\n",
       " 'ionization',\n",
       " 'frequency',\n",
       " 'line',\n",
       " 'means',\n",
       " 'use',\n",
       " 'incident',\n",
       " 'effective',\n",
       " 'evidence',\n",
       " 'correlation',\n",
       " 'type',\n",
       " 'however',\n",
       " 'helium',\n",
       " 'based',\n",
       " 'hydrogen',\n",
       " 'give',\n",
       " 'lower',\n",
       " 'constants',\n",
       " 'exchange',\n",
       " 'known',\n",
       " 'pressure',\n",
       " 'limit',\n",
       " 'basis',\n",
       " 'yields',\n",
       " 'angle',\n",
       " 'ion',\n",
       " 'rate',\n",
       " 'proposed',\n",
       " 'previous',\n",
       " 'account',\n",
       " 'cm',\n",
       " 'similar',\n",
       " 'shows',\n",
       " 'problem',\n",
       " 'associated',\n",
       " 'negative',\n",
       " 'expected',\n",
       " 'part',\n",
       " 'coincidence',\n",
       " 'samples',\n",
       " 'scintillation',\n",
       " 'target',\n",
       " 'variation',\n",
       " 'predicted',\n",
       " 'factor',\n",
       " 'deuteron',\n",
       " 'processes',\n",
       " 'quadrupole',\n",
       " 'conditions',\n",
       " 'beta',\n",
       " 'velocity',\n",
       " 'sec',\n",
       " 'absolute',\n",
       " 'behavior',\n",
       " 'developed',\n",
       " 'lines',\n",
       " 'magnitude',\n",
       " 'groups',\n",
       " 'coulomb',\n",
       " 'zero',\n",
       " 'resonances',\n",
       " 'curve',\n",
       " 'certain',\n",
       " 'work',\n",
       " 'positive',\n",
       " 'moments',\n",
       " 'scattered',\n",
       " 'strong',\n",
       " 'quantum',\n",
       " 'independent',\n",
       " 'direct',\n",
       " 'greater',\n",
       " 'gives',\n",
       " 'inelastic',\n",
       " 'nucleon',\n",
       " 'shape',\n",
       " 'motion',\n",
       " 'resulting',\n",
       " 'increase',\n",
       " 'shift',\n",
       " 'pair',\n",
       " 'coefficients',\n",
       " 'emitted',\n",
       " 'width',\n",
       " 'upon',\n",
       " 'normal',\n",
       " 'term',\n",
       " 'formula',\n",
       " 'measurement',\n",
       " 'relation',\n",
       " 'particular',\n",
       " 'charged',\n",
       " 'b',\n",
       " 'solution',\n",
       " 'conversion',\n",
       " 'methods',\n",
       " 'group',\n",
       " 'difference',\n",
       " 'heat',\n",
       " 'perturbation',\n",
       " 'optical',\n",
       " 'chamber',\n",
       " 'nucleons',\n",
       " 'atom',\n",
       " 'series',\n",
       " 'diffusion',\n",
       " 'proportional',\n",
       " 'assumption',\n",
       " 'treatment',\n",
       " 'c',\n",
       " 'taken',\n",
       " 'hall',\n",
       " 'times',\n",
       " 'pure',\n",
       " 'germanium',\n",
       " 'alpha',\n",
       " 'counter',\n",
       " 'appears',\n",
       " 'space',\n",
       " 'collisions',\n",
       " 'thus',\n",
       " 'isotopes',\n",
       " 'assumed',\n",
       " 'linear',\n",
       " 'heavy',\n",
       " 'threshold',\n",
       " 'primary',\n",
       " 'estimated',\n",
       " 'internal',\n",
       " 'parity',\n",
       " 'addition',\n",
       " 'suggested',\n",
       " 'would',\n",
       " 'set',\n",
       " 'carried',\n",
       " 'component',\n",
       " 'much',\n",
       " 'corrections',\n",
       " 'statistical',\n",
       " 'conductivity',\n",
       " 'impurity',\n",
       " 'solutions',\n",
       " 'even',\n",
       " 'radius',\n",
       " 'correction',\n",
       " 'four',\n",
       " 'bombardment',\n",
       " 'source',\n",
       " 'larger',\n",
       " 'indicates',\n",
       " 'carbon',\n",
       " 'shifts',\n",
       " 'concentration',\n",
       " 'analyzed',\n",
       " 'contribution',\n",
       " 'conduction',\n",
       " 'photon',\n",
       " 'electronic',\n",
       " 'latter',\n",
       " 'forces',\n",
       " 'intensities',\n",
       " 'ray',\n",
       " 'relaxation',\n",
       " 'changes',\n",
       " 'fermi',\n",
       " 'scheme',\n",
       " 'deuterons',\n",
       " 'presence',\n",
       " 'symmetry',\n",
       " 'lt',\n",
       " 'interpreted',\n",
       " 'leads',\n",
       " 'approximate',\n",
       " 'sample',\n",
       " 'expression',\n",
       " 'power',\n",
       " 'expansion',\n",
       " 'bands',\n",
       " 'specific',\n",
       " 'q',\n",
       " 'resistivity',\n",
       " 'shell',\n",
       " 'usual',\n",
       " 'technique',\n",
       " 'either',\n",
       " 'equal',\n",
       " 'collision',\n",
       " 'mobility',\n",
       " 'examined',\n",
       " 'f',\n",
       " 'decays',\n",
       " 'waves',\n",
       " 'error',\n",
       " 'anisotropy',\n",
       " 'existence',\n",
       " 'integral',\n",
       " 'room',\n",
       " 'electromagnetic',\n",
       " 'copper',\n",
       " 'events',\n",
       " 'detected',\n",
       " 'targets',\n",
       " 'neutral',\n",
       " 'peak',\n",
       " 'could',\n",
       " 'without',\n",
       " 'probability',\n",
       " 'must',\n",
       " 'determine',\n",
       " 'formation',\n",
       " 'parameter',\n",
       " 'agree',\n",
       " 'thin',\n",
       " 'computed',\n",
       " 'mb',\n",
       " 'plane',\n",
       " 'hamiltonian',\n",
       " 'photons',\n",
       " 'upper',\n",
       " 'finite',\n",
       " 'predictions',\n",
       " 'rather',\n",
       " 'ratios',\n",
       " 'rotational',\n",
       " 'classical',\n",
       " 'increasing',\n",
       " 'concluded',\n",
       " 'force',\n",
       " 'smaller',\n",
       " 'recent',\n",
       " 'mechanism',\n",
       " 'involving',\n",
       " 'loss',\n",
       " 'numerical',\n",
       " 'e',\n",
       " 'molecular',\n",
       " 'extended',\n",
       " 'dispersion',\n",
       " 'weak',\n",
       " 'g',\n",
       " 'dipole',\n",
       " 'components',\n",
       " 'information',\n",
       " 'susceptibility',\n",
       " 'amplitude',\n",
       " 'tensor',\n",
       " 'electrical',\n",
       " 'decrease',\n",
       " 'since',\n",
       " 'lifetime',\n",
       " 'increases',\n",
       " 'principle',\n",
       " 'axis',\n",
       " 'pairs',\n",
       " 'interpretation',\n",
       " 'r',\n",
       " 'magnetization',\n",
       " 'obtain',\n",
       " 'bremsstrahlung',\n",
       " 'reduced',\n",
       " 'bombarding',\n",
       " 'pion',\n",
       " 'spins',\n",
       " 'al',\n",
       " 'relations',\n",
       " 'along',\n",
       " 'characteristic',\n",
       " 'important',\n",
       " 'assuming',\n",
       " 'occur',\n",
       " 'relativistic',\n",
       " 'determination',\n",
       " 'theories',\n",
       " 'earlier',\n",
       " 'observations',\n",
       " 'appear',\n",
       " 'initial',\n",
       " 'expressions',\n",
       " 'metal',\n",
       " 'oxygen',\n",
       " 'binding',\n",
       " 'probably',\n",
       " 'critical',\n",
       " 'way',\n",
       " 'discussion',\n",
       " 'explained',\n",
       " 'occurs',\n",
       " 'activity',\n",
       " 'accuracy',\n",
       " 'minimum',\n",
       " 'pions',\n",
       " 'fit',\n",
       " 'additional',\n",
       " 'potentials',\n",
       " 'strength',\n",
       " 'treated',\n",
       " 'complex',\n",
       " 'hyperfine',\n",
       " 'intermediate',\n",
       " 'containing',\n",
       " 'aluminum',\n",
       " 'physical',\n",
       " 'material',\n",
       " 'silicon',\n",
       " 'metals',\n",
       " 'systems',\n",
       " 'indicated',\n",
       " 'isotopic',\n",
       " 'compound',\n",
       " 'detailed',\n",
       " 'many',\n",
       " 'special',\n",
       " 'positron',\n",
       " 'although',\n",
       " 'centers',\n",
       " 'bound',\n",
       " 'directly',\n",
       " 'external',\n",
       " 'procedure',\n",
       " 'flux',\n",
       " 'allowed',\n",
       " 'least',\n",
       " 'solid',\n",
       " 'available',\n",
       " 'forward',\n",
       " 'techniques',\n",
       " 'nitrogen',\n",
       " 'whose',\n",
       " 'molecules',\n",
       " 'experimentally',\n",
       " 'iron',\n",
       " 'law',\n",
       " 'application',\n",
       " 'secondary',\n",
       " 'decreases',\n",
       " 'cascade',\n",
       " 'laboratory',\n",
       " 'recoil',\n",
       " 'rise',\n",
       " 'essentially',\n",
       " 'resolution',\n",
       " 'cubic',\n",
       " 'detail',\n",
       " 'exact',\n",
       " 'cyclotron',\n",
       " 'size',\n",
       " 'configuration',\n",
       " 'including',\n",
       " 'l',\n",
       " 'kinetic',\n",
       " 'masses',\n",
       " 'z',\n",
       " 'types',\n",
       " 'gases',\n",
       " 'fast',\n",
       " 'nature',\n",
       " 'frequencies',\n",
       " 'related',\n",
       " 'equivalent',\n",
       " 'formulas',\n",
       " 'studies',\n",
       " 'cu',\n",
       " 'equilibrium',\n",
       " 'born',\n",
       " 'employed',\n",
       " 'showers',\n",
       " 'holes',\n",
       " 'wavelength',\n",
       " 'polarized',\n",
       " 'plasma',\n",
       " 'except',\n",
       " 'v',\n",
       " 'necessary',\n",
       " 'isotope',\n",
       " 'modes',\n",
       " 'recombination',\n",
       " 'deduced',\n",
       " 'modified',\n",
       " 'paramagnetic',\n",
       " 'probable',\n",
       " 'identified',\n",
       " 'induced',\n",
       " 'element',\n",
       " 'counters',\n",
       " 'together',\n",
       " 'bev',\n",
       " 'vector',\n",
       " 'path',\n",
       " 'complete',\n",
       " 'required',\n",
       " 'parallel',\n",
       " 'multiple',\n",
       " 'disintegration',\n",
       " 'final',\n",
       " 'resistance',\n",
       " 'therefore',\n",
       " 'anomalous',\n",
       " 'vacuum',\n",
       " 'expressed',\n",
       " 'operator',\n",
       " 'strongly',\n",
       " 'pb',\n",
       " 'evaluated',\n",
       " 'saturation',\n",
       " 'close',\n",
       " 'investigation',\n",
       " 'splitting',\n",
       " 'activation',\n",
       " 'features',\n",
       " 'ii',\n",
       " 'widths',\n",
       " 'nearly',\n",
       " 'emulsion',\n",
       " 'transformation',\n",
       " 'defined',\n",
       " 'argon',\n",
       " 'depends',\n",
       " 'accurate',\n",
       " 'points',\n",
       " 'center',\n",
       " 'volume',\n",
       " 'possibility',\n",
       " 'core',\n",
       " 'measuring',\n",
       " 'factors',\n",
       " 'ferromagnetic',\n",
       " 'arbitrary',\n",
       " 'include',\n",
       " 'square',\n",
       " 'respect',\n",
       " 'introduced',\n",
       " 'contributions',\n",
       " 'molecule',\n",
       " 'air',\n",
       " 'natural',\n",
       " 'measure',\n",
       " 'thickness',\n",
       " 'assignment',\n",
       " 'radiations',\n",
       " 'gt',\n",
       " 'differences',\n",
       " 'numbers',\n",
       " 'slow',\n",
       " 'superconducting',\n",
       " 'irradiation',\n",
       " 'variational',\n",
       " 'separation',\n",
       " 'reasonable',\n",
       " 'products',\n",
       " 'included',\n",
       " 'quite',\n",
       " 'amplitudes',\n",
       " 'carrier',\n",
       " 'static',\n",
       " 'established',\n",
       " 'bombarded',\n",
       " 'cosmic',\n",
       " 'microwave',\n",
       " 'fraction',\n",
       " 'qualitative',\n",
       " 'representation',\n",
       " 'seems',\n",
       " 'leading',\n",
       " 'length',\n",
       " 'pseudoscalar',\n",
       " 'assigned',\n",
       " 'counting',\n",
       " 'lowest',\n",
       " 'assignments',\n",
       " 'gap',\n",
       " 'assumptions',\n",
       " 'condition',\n",
       " 'involved',\n",
       " 'degrees',\n",
       " 'silver',\n",
       " 'alloys',\n",
       " 'cloud',\n",
       " 'diffraction',\n",
       " 'transmission',\n",
       " 'arising',\n",
       " 'approach',\n",
       " 'limits',\n",
       " 'distance',\n",
       " 'correct',\n",
       " 'fact',\n",
       " 'detector',\n",
       " 'spectral',\n",
       " 'estimate',\n",
       " 'h',\n",
       " 'sodium',\n",
       " 'boundary',\n",
       " 'valence',\n",
       " 'radiative',\n",
       " 'showed',\n",
       " 'formalism',\n",
       " 'carriers',\n",
       " 'operators',\n",
       " 'transfer',\n",
       " 'partial',\n",
       " 'somewhat',\n",
       " 'according',\n",
       " 'forbidden',\n",
       " 'variations',\n",
       " 'approximations',\n",
       " 'appropriate',\n",
       " 'standard',\n",
       " 'real',\n",
       " 'attributed',\n",
       " 'curie',\n",
       " 'observation',\n",
       " 'follows',\n",
       " 'double',\n",
       " 'five',\n",
       " 'becomes',\n",
       " 'satisfactory',\n",
       " 'materials',\n",
       " 'long',\n",
       " 'formed',\n",
       " 'intrinsic',\n",
       " 'dirac',\n",
       " 'deviations',\n",
       " 'rates',\n",
       " 'isotropic',\n",
       " 'peaks',\n",
       " 'increased',\n",
       " 'explain',\n",
       " 'performed',\n",
       " 'positrons',\n",
       " 'dielectric',\n",
       " 'caused',\n",
       " 'represented',\n",
       " 'description',\n",
       " 'scalar',\n",
       " 'manner',\n",
       " 'phenomenological',\n",
       " 'sum',\n",
       " 'unit',\n",
       " 'sign',\n",
       " 'stars',\n",
       " 'individual',\n",
       " 'units',\n",
       " 'edge',\n",
       " 'errors',\n",
       " 'annihilation',\n",
       " 'produce',\n",
       " 'symmetric',\n",
       " 'central',\n",
       " 'depend',\n",
       " 'relatively',\n",
       " 'slightly',\n",
       " 'rapidly',\n",
       " 'nickel',\n",
       " 'deviation',\n",
       " 'emulsions',\n",
       " 'quantities',\n",
       " 'correlations',\n",
       " 'nai',\n",
       " 'asymmetry',\n",
       " 'agrees',\n",
       " 'atmosphere',\n",
       " 'gauss',\n",
       " 'solar',\n",
       " 'problems',\n",
       " 'models',\n",
       " 'indicating',\n",
       " 'odd',\n",
       " 'films',\n",
       " 'product',\n",
       " 'amount',\n",
       " 'spherical',\n",
       " 'densities',\n",
       " 'six',\n",
       " 'interval',\n",
       " 'antiferromagnetic',\n",
       " 'ranges',\n",
       " 'taking',\n",
       " 'directions',\n",
       " 'degree',\n",
       " 'local',\n",
       " 'validity',\n",
       " 'probabilities',\n",
       " 'orbital',\n",
       " 'pointed',\n",
       " 'combined',\n",
       " 'explanation',\n",
       " 'ordinary',\n",
       " 'fitted',\n",
       " 'find',\n",
       " 'medium',\n",
       " 'gold',\n",
       " 'sources',\n",
       " 'character',\n",
       " 'film',\n",
       " 'regions',\n",
       " 'earth',\n",
       " 'suggests',\n",
       " 'pulse',\n",
       " 'example',\n",
       " 'maxima',\n",
       " 'considerably',\n",
       " 'uniform',\n",
       " 'valid',\n",
       " 'calculate',\n",
       " 'connection',\n",
       " 'residual',\n",
       " 'x',\n",
       " 'provided',\n",
       " 'recently',\n",
       " 'barns',\n",
       " 'depth',\n",
       " 'best',\n",
       " 'exist',\n",
       " 'specimens',\n",
       " 'sensitive',\n",
       " 'stripping',\n",
       " 'view',\n",
       " 'infinite',\n",
       " 'electrostatic',\n",
       " 'end',\n",
       " 'make',\n",
       " 'deuterium',\n",
       " 'integrated',\n",
       " 'metastable',\n",
       " 'domain',\n",
       " 'determining',\n",
       " 'phenomena',\n",
       " 'significant',\n",
       " 'stopping',\n",
       " 'surfaces',\n",
       " 'separated',\n",
       " 'transverse',\n",
       " 'finally',\n",
       " 'j',\n",
       " 'theorem',\n",
       " 'w',\n",
       " 'concerning',\n",
       " 'influence',\n",
       " 'collective',\n",
       " 'position',\n",
       " 'place',\n",
       " 'longitudinal',\n",
       " 'identical',\n",
       " 'completely',\n",
       " 'interference',\n",
       " 'vibrational',\n",
       " 'oscillations',\n",
       " 'attempt',\n",
       " 'origin',\n",
       " 'discrepancy',\n",
       " 'generalized',\n",
       " 'mixture',\n",
       " 'flow',\n",
       " 'dependent',\n",
       " 'configurations',\n",
       " 'hg',\n",
       " 'fluctuations',\n",
       " 'years',\n",
       " 'tl',\n",
       " 'currents',\n",
       " 'provide',\n",
       " 'penetrating',\n",
       " 'pressures',\n",
       " 'test',\n",
       " 'vacancies',\n",
       " 'efficiency',\n",
       " 'impurities',\n",
       " 'momenta',\n",
       " 'discharge',\n",
       " 'closely',\n",
       " 'almost',\n",
       " 'geomagnetic',\n",
       " 'transport',\n",
       " 'another',\n",
       " 'suitable',\n",
       " 'fixed',\n",
       " 'concentrations',\n",
       " 'fragments',\n",
       " 'placed',\n",
       " 'thick',\n",
       " 'cathode',\n",
       " 'mode',\n",
       " 'better',\n",
       " 'matter',\n",
       " 'photographic',\n",
       " 'quantitative',\n",
       " 'consideration',\n",
       " 'conventional',\n",
       " 'oscillator',\n",
       " 'exponential',\n",
       " 'arise',\n",
       " 'empirical',\n",
       " 'barrier',\n",
       " 'geometry',\n",
       " 'chemical',\n",
       " 'among',\n",
       " 'giving',\n",
       " 'whereas',\n",
       " 'combination',\n",
       " 'mm',\n",
       " 'debye',\n",
       " 'hypothesis',\n",
       " 'thermodynamic',\n",
       " 'appreciable',\n",
       " 'rest',\n",
       " 'rules',\n",
       " 'characteristics',\n",
       " 'relationship',\n",
       " 'explicit',\n",
       " 'voltage',\n",
       " 'suggest',\n",
       " 'short',\n",
       " 'sufficient',\n",
       " 'breakdown',\n",
       " 'formulation',\n",
       " 'plates',\n",
       " 'estimates',\n",
       " 'closed',\n",
       " 'solved',\n",
       " 'principal',\n",
       " 'excess',\n",
       " 'contains',\n",
       " 'exhibit',\n",
       " 'third',\n",
       " 'occurring',\n",
       " 'enriched',\n",
       " 'nuclides',\n",
       " 'qualitatively',\n",
       " 'extension',\n",
       " 'decreasing',\n",
       " 'photoconductivity',\n",
       " 'sufficiently',\n",
       " 'rule',\n",
       " 'spontaneous',\n",
       " 'radial',\n",
       " 'published',\n",
       " 'days',\n",
       " 'followed',\n",
       " 'entropy',\n",
       " 'varies',\n",
       " 'annealing',\n",
       " 'around',\n",
       " 'broadening',\n",
       " 'orientation',\n",
       " 'ge',\n",
       " 'tin',\n",
       " 'broad',\n",
       " 'hole',\n",
       " 'radioactive',\n",
       " 'provides',\n",
       " 'briefly',\n",
       " 'vary',\n",
       " 'corresponds',\n",
       " 'coupled',\n",
       " 'ag',\n",
       " 'specimen',\n",
       " 'absence',\n",
       " 'invariance',\n",
       " 'sharp',\n",
       " 'others',\n",
       " 'perpendicular',\n",
       " 'apparatus',\n",
       " 'making',\n",
       " 'attenuation',\n",
       " 'latitude',\n",
       " 'resolved',\n",
       " 'negligible',\n",
       " 'consists',\n",
       " 'fine',\n",
       " 'van',\n",
       " 'explicitly',\n",
       " 'shower',\n",
       " 'green',\n",
       " 'theoretically',\n",
       " 'au',\n",
       " 'systematic',\n",
       " 'main',\n",
       " 'varying',\n",
       " 'evaluation',\n",
       " 'selection',\n",
       " 'vapor',\n",
       " 'integrals',\n",
       " 'considerations',\n",
       " 'variables',\n",
       " 'exposed',\n",
       " 'branching',\n",
       " 'correspond',\n",
       " 'far',\n",
       " 'irradiated',\n",
       " 'apparent',\n",
       " 'fundamental',\n",
       " 'vacancy',\n",
       " 'crystalline',\n",
       " 'indium',\n",
       " 'infrared',\n",
       " ...]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Vocab at 0x12214ee10>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab['four']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10.1103/PhysRev.106.188': Doctag(offset=1985, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.96.1163': Doctag(offset=8592, word_count=376, doc_count=2),\n",
       " '10.1103/PhysRev.111.1187': Doctag(offset=3336, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.103.1227': Doctag(offset=1006, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.83.69': Doctag(offset=5933, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.111.1182': Doctag(offset=3335, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.104.411': Doctag(offset=1464, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.104.413': Doctag(offset=1465, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.98.1067': Doctag(offset=9150, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.104.416': Doctag(offset=1466, word_count=20, doc_count=2),\n",
       " '10.1103/PhysRev.104.419': Doctag(offset=1467, word_count=48, doc_count=2),\n",
       " '10.1103/PhysRev.92.482': Doctag(offset=7675, word_count=228, doc_count=2),\n",
       " '10.1103/PhysRev.92.481': Doctag(offset=7674, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.101.1291': Doctag(offset=429, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.90.557': Doctag(offset=7168, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.101.1295': Doctag(offset=430, word_count=122, doc_count=2),\n",
       " '10.1103/PhysRev.101.1298': Doctag(offset=431, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.91.1058': Doctag(offset=7256, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.100.1208': Doctag(offset=125, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.99.986': Doctag(offset=9713, word_count=86, doc_count=2),\n",
       " '10.1103/PhysRev.100.1755': Doctag(offset=227, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.78.36': Doctag(offset=5173, word_count=32, doc_count=2),\n",
       " '10.1103/PhysRev.101.999': Doctag(offset=684, word_count=28, doc_count=2),\n",
       " '10.1103/PhysRev.101.998': Doctag(offset=683, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.112.1419': Doctag(offset=3661, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.95.1061': Doctag(offset=8306, word_count=114, doc_count=2),\n",
       " '10.1103/RevModPhys.27.1': Doctag(offset=67, word_count=140, doc_count=2),\n",
       " '10.1103/PhysRev.95.1065': Doctag(offset=8307, word_count=248, doc_count=2),\n",
       " '10.1103/PhysRev.101.993': Doctag(offset=682, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.97.290': Doctag(offset=9011, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.109.256': Doctag(offset=2934, word_count=190, doc_count=2),\n",
       " '10.1103/PhysRev.102.1584': Doctag(offset=792, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.85.517': Doctag(offset=6229, word_count=266, doc_count=2),\n",
       " '10.1103/PhysRev.84.877': Doctag(offset=6139, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.91.1234': Doctag(offset=7295, word_count=8, doc_count=2),\n",
       " '10.1103/PhysRev.91.1237': Doctag(offset=7296, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.91.1232': Doctag(offset=7293, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.106.183': Doctag(offset=1984, word_count=194, doc_count=2),\n",
       " '10.1103/PhysRev.92.626': Doctag(offset=7693, word_count=250, doc_count=2),\n",
       " '10.1103/PhysRev.89.490': Doctag(offset=6967, word_count=282, doc_count=2),\n",
       " '10.1103/PhysRev.107.279': Doctag(offset=2317, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.107.272': Doctag(offset=2314, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.89.947': Doctag(offset=7049, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.107.277': Doctag(offset=2316, word_count=46, doc_count=2),\n",
       " '10.1103/PhysRev.107.274': Doctag(offset=2315, word_count=42, doc_count=2),\n",
       " '10.1103/PhysRev.89.941': Doctag(offset=7048, word_count=228, doc_count=2),\n",
       " '10.1103/PhysRev.108.878': Doctag(offset=2703, word_count=86, doc_count=2),\n",
       " '10.1103/PhysRev.108.872': Doctag(offset=2702, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.105.896': Doctag(offset=1886, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.101.1619': Doctag(offset=488, word_count=30, doc_count=2),\n",
       " '10.1103/PhysRev.83.756': Doctag(offset=5947, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.98.1063': Doctag(offset=9149, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.97.288': Doctag(offset=9010, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.98.1061': Doctag(offset=9148, word_count=34, doc_count=2),\n",
       " '10.1103/PhysRev.112.2135': Doctag(offset=3783, word_count=196, doc_count=2),\n",
       " '10.1103/PhysRev.88.987': Doctag(offset=6848, word_count=428, doc_count=2),\n",
       " '10.1103/PhysRev.88.451': Doctag(offset=6742, word_count=270, doc_count=2),\n",
       " '10.1103/PhysRev.94.1545': Doctag(offset=8099, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.94.1011': Doctag(offset=8018, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.94.1017': Doctag(offset=8019, word_count=372, doc_count=2),\n",
       " '10.1103/PhysRev.101.371': Doctag(offset=567, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.114.502': Doctag(offset=4371, word_count=18, doc_count=2),\n",
       " '10.1103/PhysRev.113.647': Doctag(offset=4127, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.113.641': Doctag(offset=4126, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.101.377': Doctag(offset=568, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.111.967': Doctag(offset=3583, word_count=206, doc_count=2),\n",
       " '10.1103/PhysRev.111.965': Doctag(offset=3582, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.111.616': Doctag(offset=3523, word_count=136, doc_count=2),\n",
       " '10.1103/PhysRev.92.1234': Doctag(offset=7536, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.103.304': Doctag(offset=1134, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.108.1390': Doctag(offset=2530, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.81.222': Doctag(offset=5572, word_count=170, doc_count=2),\n",
       " '10.1103/PhysRev.97.463': Doctag(offset=9038, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.108.1394': Doctag(offset=2531, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.81.953': Doctag(offset=5679, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.108.1397': Doctag(offset=2532, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.108.1398': Doctag(offset=2533, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.77.77': Doctag(offset=5117, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.77.75': Doctag(offset=5115, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.81.958': Doctag(offset=5680, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.77.71': Doctag(offset=5113, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.86.288': Doctag(offset=6337, word_count=170, doc_count=2),\n",
       " '10.1103/PhysRev.86.280': Doctag(offset=6336, word_count=222, doc_count=2),\n",
       " '10.1103/PhysRev.116.1022': Doctag(offset=4752, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.116.1027': Doctag(offset=4753, word_count=182, doc_count=2),\n",
       " '10.1103/PhysRev.77.706': Doctag(offset=5112, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.107.1616': Doctag(offset=2272, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.91.1516': Doctag(offset=7344, word_count=220, doc_count=2),\n",
       " '10.1103/PhysRev.107.1612': Doctag(offset=2271, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.107.859': Doctag(offset=2432, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.107.856': Doctag(offset=2431, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.107.850': Doctag(offset=2430, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.101.740': Doctag(offset=638, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.113.252': Doctag(offset=4054, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.113.256': Doctag(offset=4055, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.101.746': Doctag(offset=639, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.113.259': Doctag(offset=4056, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.80.171': Doctag(offset=5406, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.80.177': Doctag(offset=5407, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.88.184': Doctag(offset=6689, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.88.1392': Doctag(offset=6684, word_count=190, doc_count=2),\n",
       " '10.1103/PhysRev.99.301': Doctag(offset=9600, word_count=136, doc_count=2),\n",
       " '10.1103/PhysRev.104.254': Doctag(offset=1432, word_count=32, doc_count=2),\n",
       " '10.1103/PhysRev.100.606': Doctag(offset=300, word_count=158, doc_count=2),\n",
       " '10.1103/PhysRev.94.945': Doctag(offset=8275, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.94.947': Doctag(offset=8276, word_count=140, doc_count=2),\n",
       " '10.1103/PhysRev.111.1406': Doctag(offset=3379, word_count=256, doc_count=2),\n",
       " '10.1103/PhysRev.94.941': Doctag(offset=8273, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.104.259': Doctag(offset=1433, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.94.943': Doctag(offset=8274, word_count=48, doc_count=2),\n",
       " '10.1103/PhysRev.107.1266': Doctag(offset=2198, word_count=246, doc_count=2),\n",
       " '10.1103/PhysRev.107.1261': Doctag(offset=2197, word_count=128, doc_count=2),\n",
       " '10.1103/RevModPhys.23.203': Doctag(offset=3, word_count=408, doc_count=2),\n",
       " '10.1103/PhysRev.91.803': Doctag(offset=7450, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.91.804': Doctag(offset=7451, word_count=208, doc_count=2),\n",
       " '10.1103/PhysRev.80.396': Doctag(offset=5445, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.113.828': Doctag(offset=4172, word_count=128, doc_count=2),\n",
       " '10.1103/PhysRev.80.392': Doctag(offset=5444, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.80.1030': Doctag(offset=5388, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.80.1035': Doctag(offset=5389, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.86.753': Doctag(offset=6395, word_count=152, doc_count=2),\n",
       " '10.1103/PhysRev.95.1669': Doctag(offset=8420, word_count=52, doc_count=2),\n",
       " '10.1103/PhysRev.104.1364': Doctag(offset=1328, word_count=196, doc_count=2),\n",
       " '10.1103/PhysRev.104.626': Doctag(offset=1509, word_count=190, doc_count=2),\n",
       " '10.1103/PhysRev.104.624': Doctag(offset=1508, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.104.623': Doctag(offset=1507, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.105.302': Doctag(offset=1775, word_count=42, doc_count=2),\n",
       " '10.1103/PhysRev.94.419': Doctag(offset=8195, word_count=166, doc_count=2),\n",
       " '10.1103/PhysRev.95.1635': Doctag(offset=8417, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.110.1093': Doctag(offset=3083, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.94.412': Doctag(offset=8194, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.110.1094': Doctag(offset=3084, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.91.1054': Doctag(offset=7255, word_count=146, doc_count=2),\n",
       " '10.1103/PhysRev.109.1755': Doctag(offset=2851, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.114.1028': Doctag(offset=4212, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.84.644': Doctag(offset=6098, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.109.1750': Doctag(offset=2850, word_count=86, doc_count=2),\n",
       " '10.1103/PhysRev.84.648': Doctag(offset=6099, word_count=216, doc_count=2),\n",
       " '10.1103/PhysRev.114.1026': Doctag(offset=4211, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.109.1759': Doctag(offset=2852, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.104.1099': Doctag(offset=1281, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.104.1093': Doctag(offset=1280, word_count=168, doc_count=2),\n",
       " '10.1103/PhysRev.91.76': Doctag(offset=7442, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.91.74': Doctag(offset=7438, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.95.1279': Doctag(offset=8351, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.87.46': Doctag(offset=6516, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.110.1272': Doctag(offset=3114, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.116.526': Doctag(offset=4934, word_count=188, doc_count=2),\n",
       " '10.1103/PhysRev.93.45': Doctag(offset=7915, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.115.1053': Doctag(offset=4463, word_count=146, doc_count=2),\n",
       " '10.1103/PhysRev.93.46': Doctag(offset=7919, word_count=158, doc_count=2),\n",
       " '10.1103/PhysRev.100.1431': Doctag(offset=167, word_count=176, doc_count=2),\n",
       " '10.1103/PhysRev.92.1419': Doctag(offset=7576, word_count=192, doc_count=2),\n",
       " '10.1103/PhysRev.115.1058': Doctag(offset=4464, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.110.652': Doctag(offset=3237, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.110.657': Doctag(offset=3238, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.96.1378': Doctag(offset=8636, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.102.1641': Doctag(offset=802, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.112.1773': Doctag(offset=3720, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.96.1372': Doctag(offset=8635, word_count=176, doc_count=2),\n",
       " '10.1103/PhysRev.102.1648': Doctag(offset=803, word_count=256, doc_count=2),\n",
       " '10.1103/PhysRev.89.168': Doctag(offset=6912, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.102.851': Doctag(offset=944, word_count=188, doc_count=2),\n",
       " '10.1103/PhysRev.102.857': Doctag(offset=945, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.102.933': Doctag(offset=956, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.91.1408': Doctag(offset=7325, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.100.632': Doctag(offset=305, word_count=300, doc_count=2),\n",
       " '10.1103/PhysRev.102.939': Doctag(offset=957, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.98.1470': Doctag(offset=9210, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.95.67': Doctag(offset=8491, word_count=54, doc_count=2),\n",
       " '10.1103/RevModPhys.24.45': Doctag(offset=16, word_count=218, doc_count=2),\n",
       " '10.1103/PhysRev.87.1016': Doctag(offset=6448, word_count=40, doc_count=2),\n",
       " '10.1103/PhysRev.108.466': Doctag(offset=2632, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.108.460': Doctag(offset=2630, word_count=132, doc_count=2),\n",
       " '10.1103/PhysRev.108.463': Doctag(offset=2631, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.95.676': Doctag(offset=8494, word_count=226, doc_count=2),\n",
       " '10.1103/PhysRev.83.586': Doctag(offset=5922, word_count=180, doc_count=2),\n",
       " '10.1103/PhysRev.95.674': Doctag(offset=8493, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.90.126': Doctag(offset=7091, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.83.582': Doctag(offset=5921, word_count=186, doc_count=2),\n",
       " '10.1103/PhysRev.109.89': Doctag(offset=3044, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.81.761': Doctag(offset=5650, word_count=208, doc_count=2),\n",
       " '10.1103/PhysRev.109.1806': Doctag(offset=2859, word_count=122, doc_count=2),\n",
       " '10.1103/PhysRev.109.1801': Doctag(offset=2858, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.109.85': Doctag(offset=3036, word_count=26, doc_count=2),\n",
       " '10.1103/PhysRev.96.1081': Doctag(offset=8576, word_count=36, doc_count=2),\n",
       " '10.1103/PhysRev.77.771': Doctag(offset=5118, word_count=132, doc_count=2),\n",
       " '10.1103/PhysRev.77.777': Doctag(offset=5119, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.96.1085': Doctag(offset=8577, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.96.1089': Doctag(offset=8578, word_count=338, doc_count=2),\n",
       " '10.1103/PhysRev.113.1277': Doctag(offset=3978, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.106.513': Doctag(offset=2046, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.89.552': Doctag(offset=6974, word_count=68, doc_count=2),\n",
       " '10.1103/PhysRev.106.516': Doctag(offset=2047, word_count=36, doc_count=2),\n",
       " '10.1103/PhysRev.106.517': Doctag(offset=2048, word_count=258, doc_count=2),\n",
       " '10.1103/PhysRev.84.1': Doctag(offset=5980, word_count=278, doc_count=2),\n",
       " '10.1103/PhysRev.89.559': Doctag(offset=6976, word_count=40, doc_count=2),\n",
       " '10.1103/PhysRev.98.1213': Doctag(offset=9161, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.113.815': Doctag(offset=4168, word_count=118, doc_count=2),\n",
       " '10.1103/PhysRev.109.2133': Doctag(offset=2917, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.98.1216': Doctag(offset=9162, word_count=150, doc_count=2),\n",
       " '10.1103/PhysRev.113.816': Doctag(offset=4169, word_count=68, doc_count=2),\n",
       " '10.1103/PhysRev.110.900': Doctag(offset=3280, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.96.293': Doctag(offset=8731, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.96.296': Doctag(offset=8732, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.83.1044': Doctag(offset=5824, word_count=86, doc_count=2),\n",
       " '10.1103/PhysRev.110.906': Doctag(offset=3281, word_count=168, doc_count=2),\n",
       " '10.1103/PhysRev.113.572': Doctag(offset=4112, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.96.929': Doctag(offset=8853, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.100.1698': Doctag(offset=218, word_count=436, doc_count=2),\n",
       " '10.1103/PhysRev.100.1692': Doctag(offset=217, word_count=146, doc_count=2),\n",
       " '10.1103/PhysRev.77.597': Doctag(offset=5091, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.77.594': Doctag(offset=5090, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.85.808': Doctag(offset=6271, word_count=22, doc_count=2),\n",
       " '10.1103/PhysRev.104.1': Doctag(offset=1261, word_count=194, doc_count=2),\n",
       " '10.1103/PhysRev.104.6': Doctag(offset=1502, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.103.1565': Doctag(offset=1060, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.115.374': Doctag(offset=4631, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.106.1215': Doctag(offset=1947, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.85.60': Doctag(offset=6244, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.101.1469': Doctag(offset=463, word_count=36, doc_count=2),\n",
       " '10.1103/PhysRev.85.65': Doctag(offset=6255, word_count=158, doc_count=2),\n",
       " '10.1103/PhysRev.109.625': Doctag(offset=3000, word_count=174, doc_count=2),\n",
       " '10.1103/PhysRev.92.291': Doctag(offset=7635, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.85.68': Doctag(offset=6260, word_count=224, doc_count=2),\n",
       " '10.1103/PhysRev.101.1467': Doctag(offset=462, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.91.256': Doctag(offset=7357, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.101.1460': Doctag(offset=461, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.80.943': Doctag(offset=5533, word_count=174, doc_count=2),\n",
       " '10.1103/PhysRev.84.519': Doctag(offset=6077, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.111.1235': Doctag(offset=3348, word_count=86, doc_count=2),\n",
       " '10.1103/PhysRev.103.67': Doctag(offset=1203, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.112.1534': Doctag(offset=3680, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.103.61': Doctag(offset=1191, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.115.150': Doctag(offset=4543, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.107.135': Doctag(offset=2220, word_count=140, doc_count=2),\n",
       " '10.1103/PhysRev.102.208': Doctag(offset=819, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.107.139': Doctag(offset=2227, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.115.158': Doctag(offset=4556, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.102.203': Doctag(offset=818, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.102.200': Doctag(offset=817, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.105.936': Doctag(offset=1896, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.87.568': Doctag(offset=6534, word_count=122, doc_count=2),\n",
       " '10.1103/PhysRev.92.123': Doctag(offset=7535, word_count=52, doc_count=2),\n",
       " '10.1103/PhysRev.105.931': Doctag(offset=1895, word_count=192, doc_count=2),\n",
       " '10.1103/PhysRev.92.127': Doctag(offset=7552, word_count=186, doc_count=2),\n",
       " '10.1103/PhysRev.87.290': Doctag(offset=6488, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.87.561': Doctag(offset=6533, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.82.181': Doctag(offset=5692, word_count=236, doc_count=2),\n",
       " '10.1103/PhysRev.87.297': Doctag(offset=6490, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.91.784': Doctag(offset=7446, word_count=196, doc_count=2),\n",
       " '10.1103/PhysRev.109.1115': Doctag(offset=2748, word_count=192, doc_count=2),\n",
       " '10.1103/PhysRev.91.780': Doctag(offset=7445, word_count=216, doc_count=2),\n",
       " '10.1103/PhysRev.88.867': Doctag(offset=6825, word_count=296, doc_count=2),\n",
       " '10.1103/PhysRev.88.860': Doctag(offset=6824, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.98.938': Doctag(offset=9403, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.98.934': Doctag(offset=9401, word_count=166, doc_count=2),\n",
       " '10.1103/PhysRev.98.936': Doctag(offset=9402, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.94.1203': Doctag(offset=8052, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.94.1209': Doctag(offset=8053, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.104.399': Doctag(offset=1462, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.81.612': Doctag(offset=5630, word_count=274, doc_count=2),\n",
       " '10.1103/PhysRev.105.1521': Doctag(offset=1686, word_count=50, doc_count=2),\n",
       " '10.1103/PhysRev.105.1250': Doctag(offset=1629, word_count=214, doc_count=2),\n",
       " '10.1103/PhysRev.105.1524': Doctag(offset=1687, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.102.1008': Doctag(offset=688, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.105.1528': Doctag(offset=1688, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.91.1551': Doctag(offset=7349, word_count=154, doc_count=2),\n",
       " '10.1103/PhysRev.102.1004': Doctag(offset=687, word_count=128, doc_count=2),\n",
       " '10.1103/PhysRev.85.309': Doctag(offset=6199, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.102.1000': Doctag(offset=686, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.102.1348': Doctag(offset=748, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.88.242': Doctag(offset=6699, word_count=170, doc_count=2),\n",
       " '10.1103/PhysRev.93.394': Doctag(offset=7902, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.102.1341': Doctag(offset=745, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.95.941': Doctag(offset=8544, word_count=300, doc_count=2),\n",
       " '10.1103/PhysRev.102.1344': Doctag(offset=746, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.102.1347': Doctag(offset=747, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.88.9': Doctag(offset=6834, word_count=118, doc_count=2),\n",
       " '10.1103/PhysRev.88.1234': Doctag(offset=6650, word_count=198, doc_count=2),\n",
       " '10.1103/PhysRev.80.655': Doctag(offset=5491, word_count=178, doc_count=2),\n",
       " '10.1103/PhysRev.88.1230': Doctag(offset=6649, word_count=52, doc_count=2),\n",
       " '10.1103/PhysRev.94.885': Doctag(offset=8262, word_count=32, doc_count=2),\n",
       " '10.1103/PhysRev.88.1239': Doctag(offset=6651, word_count=208, doc_count=2),\n",
       " '10.1103/PhysRev.114.717': Doctag(offset=4405, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.114.240': Doctag(offset=4334, word_count=182, doc_count=2),\n",
       " '10.1103/PhysRev.103.516': Doctag(offset=1173, word_count=184, doc_count=2),\n",
       " '10.1103/PhysRev.114.719': Doctag(offset=4406, word_count=150, doc_count=2),\n",
       " '10.1103/PhysRev.93.471': Doctag(offset=7922, word_count=168, doc_count=2),\n",
       " '10.1103/PhysRev.103.511': Doctag(offset=1172, word_count=58, doc_count=2),\n",
       " '10.1103/RevModPhys.25.151': Doctag(offset=26, word_count=204, doc_count=2),\n",
       " '10.1103/PhysRev.116.862': Doctag(offset=4992, word_count=146, doc_count=2),\n",
       " '10.1103/PhysRev.93.477': Doctag(offset=7923, word_count=14, doc_count=2),\n",
       " '10.1103/PhysRev.97.607': Doctag(offset=9060, word_count=186, doc_count=2),\n",
       " '10.1103/PhysRev.116.868': Doctag(offset=4993, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.89.310': Doctag(offset=6934, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.85.73': Doctag(offset=6262, word_count=106, doc_count=2),\n",
       " '10.1103/PhysRev.113.70': Doctag(offset=4139, word_count=122, doc_count=2),\n",
       " '10.1103/PhysRev.85.71': Doctag(offset=6261, word_count=52, doc_count=2),\n",
       " '10.1103/PhysRev.113.72': Doctag(offset=4143, word_count=194, doc_count=2),\n",
       " '10.1103/PhysRev.115.1300': Doctag(offset=4516, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.111.394': Doctag(offset=3485, word_count=234, doc_count=2),\n",
       " '10.1103/PhysRev.96.730': Doctag(offset=8823, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.111.390': Doctag(offset=3484, word_count=128, doc_count=2),\n",
       " '10.1103/PhysRev.113.79': Doctag(offset=4160, word_count=236, doc_count=2),\n",
       " '10.1103/PhysRev.110.332': Doctag(offset=3181, word_count=158, doc_count=2),\n",
       " '10.1103/PhysRev.90.1036': Doctag(offset=7071, word_count=168, doc_count=2),\n",
       " '10.1103/PhysRev.110.337': Doctag(offset=3182, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.97.1266': Doctag(offset=8917, word_count=50, doc_count=2),\n",
       " '10.1103/PhysRev.97.1267': Doctag(offset=8918, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.110.338': Doctag(offset=3183, word_count=136, doc_count=2),\n",
       " '10.1103/PhysRev.83.307': Doctag(offset=5875, word_count=46, doc_count=2),\n",
       " '10.1103/PhysRev.113.1462': Doctag(offset=4006, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.104.1424': Doctag(offset=1337, word_count=42, doc_count=2),\n",
       " '10.1103/PhysRev.104.1425': Doctag(offset=1338, word_count=144, doc_count=2),\n",
       " '10.1103/PhysRev.104.1131': Doctag(offset=1288, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.100.841': Doctag(offset=344, word_count=30, doc_count=2),\n",
       " '10.1103/PhysRev.93.843': Doctag(offset=7993, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.100.847': Doctag(offset=347, word_count=68, doc_count=2),\n",
       " '10.1103/PhysRev.100.844': Doctag(offset=345, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.100.845': Doctag(offset=346, word_count=68, doc_count=2),\n",
       " '10.1103/PhysRev.116.738': Doctag(offset=4968, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.99.510': Doctag(offset=9638, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.99.843': Doctag(offset=9688, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.116.734': Doctag(offset=4967, word_count=26, doc_count=2),\n",
       " '10.1103/PhysRev.116.730': Doctag(offset=4966, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.114.867': Doctag(offset=4429, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.101.554': Doctag(offset=598, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.108.1025': Doctag(offset=2460, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.101.551': Doctag(offset=597, word_count=160, doc_count=2),\n",
       " '10.1103/PhysRev.114.862': Doctag(offset=4428, word_count=180, doc_count=2),\n",
       " '10.1103/PhysRev.110.485': Doctag(offset=3205, word_count=46, doc_count=2),\n",
       " '10.1103/PhysRev.97.1086': Doctag(offset=8888, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.115.1601': Doctag(offset=4564, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.108.1028': Doctag(offset=2461, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.95.105': Doctag(offset=8303, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.81.489': Doctag(offset=5608, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.113.1649': Doctag(offset=4035, word_count=136, doc_count=2),\n",
       " '10.1103/PhysRev.113.1640': Doctag(offset=4034, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.79.481': Doctag(offset=5302, word_count=48, doc_count=2),\n",
       " '10.1103/PhysRev.79.487': Doctag(offset=5303, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.81.1035': Doctag(offset=5552, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.108.677': Doctag(offset=2667, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.112.739': Doctag(offset=3879, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.92.727': Doctag(offset=7714, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.92.724': Doctag(offset=7713, word_count=42, doc_count=2),\n",
       " '10.1103/PhysRev.92.722': Doctag(offset=7712, word_count=26, doc_count=2),\n",
       " '10.1103/PhysRev.95.464': Doctag(offset=8476, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.112.732': Doctag(offset=3878, word_count=144, doc_count=2),\n",
       " '10.1103/PhysRev.83.919': Doctag(offset=5965, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.100.1593': Doctag(offset=196, word_count=86, doc_count=2),\n",
       " '10.1103/PhysRev.100.1597': Doctag(offset=198, word_count=292, doc_count=2),\n",
       " '10.1103/PhysRev.100.1595': Doctag(offset=197, word_count=34, doc_count=2),\n",
       " '10.1103/PhysRev.103.1796': Doctag(offset=1097, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.112.1436': Doctag(offset=3663, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.112.1437': Doctag(offset=3664, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.96.1144': Doctag(offset=8588, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.96.1145': Doctag(offset=8589, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.96.1142': Doctag(offset=8587, word_count=32, doc_count=2),\n",
       " '10.1103/PhysRev.104.479': Doctag(offset=1479, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.98.1045': Doctag(offset=9144, word_count=168, doc_count=2),\n",
       " '10.1103/PhysRev.104.471': Doctag(offset=1477, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.104.475': Doctag(offset=1478, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.94.625': Doctag(offset=8225, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.108.580': Doctag(offset=2651, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.108.587': Doctag(offset=2652, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.116.194': Doctag(offset=4869, word_count=86, doc_count=2),\n",
       " '10.1103/PhysRev.92.464': Doctag(offset=7672, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.92.461': Doctag(offset=7671, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.89.1081': Doctag(offset=6867, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.100.1775': Doctag(offset=232, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.92.970': Doctag(offset=7760, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.100.1771': Doctag(offset=231, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.91.1035': Doctag(offset=7253, word_count=106, doc_count=2),\n",
       " '10.1103/PhysRev.83.510': Doctag(offset=5908, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.95.1045': Doctag(offset=8301, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.95.1048': Doctag(offset=8302, word_count=128, doc_count=2),\n",
       " '10.1103/PhysRev.101.1815': Doctag(offset=527, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.101.1810': Doctag(offset=526, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.108.850': Doctag(offset=2700, word_count=258, doc_count=2),\n",
       " '10.1103/PhysRev.98.28': Doctag(offset=9280, word_count=204, doc_count=2),\n",
       " '10.1103/PhysRev.85.532': Doctag(offset=6232, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.98.24': Doctag(offset=9278, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.85.530': Doctag(offset=6231, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.98.22': Doctag(offset=9277, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.84.814': Doctag(offset=6132, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.89.1227': Doctag(offset=6887, word_count=166, doc_count=2),\n",
       " '10.1103/PhysRev.98.1729': Doctag(offset=9243, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.89.968': Doctag(offset=7053, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.98.387': Doctag(offset=9295, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.98.1099': Doctag(offset=9155, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.89.965': Doctag(offset=7052, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.78.567': Doctag(offset=5206, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.111.803': Doctag(offset=3555, word_count=136, doc_count=2),\n",
       " '10.1103/PhysRev.93.1286': Doctag(offset=7820, word_count=144, doc_count=2),\n",
       " '10.1103/PhysRev.92.1211': Doctag(offset=7531, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.108.1629': Doctag(offset=2574, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.92.1218': Doctag(offset=7532, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.97.263': Doctag(offset=9006, word_count=168, doc_count=2),\n",
       " '10.1103/PhysRev.82.646': Doctag(offset=5758, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.94.1541': Doctag(offset=8098, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.116.1591': Doctag(offset=4852, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.116.1221': Doctag(offset=4786, word_count=132, doc_count=2),\n",
       " '10.1103/PhysRev.116.1226': Doctag(offset=4787, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.116.1597': Doctag(offset=4853, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.95.982': Doctag(offset=8552, word_count=170, doc_count=2),\n",
       " '10.1103/PhysRev.94.1567': Doctag(offset=8105, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.116.1229': Doctag(offset=4788, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.104.892': Doctag(offset=1562, word_count=190, doc_count=2),\n",
       " '10.1103/PhysRev.111.948': Doctag(offset=3579, word_count=34, doc_count=2),\n",
       " '10.1103/PhysRev.106.703': Doctag(offset=2084, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.113.666': Doctag(offset=4132, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.111.940': Doctag(offset=3576, word_count=50, doc_count=2),\n",
       " '10.1103/PhysRev.100.545': Doctag(offset=290, word_count=196, doc_count=2),\n",
       " '10.1103/PhysRev.100.544': Doctag(offset=289, word_count=68, doc_count=2),\n",
       " '10.1103/PhysRev.111.944': Doctag(offset=3578, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.101.314': Doctag(offset=558, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.103.182': Doctag(offset=1100, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.107.1639': Doctag(offset=2278, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.103.186': Doctag(offset=1105, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.111.494': Doctag(offset=3502, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.96.126': Doctag(offset=8609, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.107.1631': Doctag(offset=2276, word_count=152, doc_count=2),\n",
       " '10.1103/PhysRev.81.973': Doctag(offset=5683, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.96.121': Doctag(offset=8601, word_count=46, doc_count=2),\n",
       " '10.1103/PhysRev.96.122': Doctag(offset=8602, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.107.1635': Doctag(offset=2277, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.77.54': Doctag(offset=5085, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.77.50': Doctag(offset=5078, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.116.1047': Doctag(offset=4757, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.116.1045': Doctag(offset=4756, word_count=128, doc_count=2),\n",
       " '10.1103/PhysRev.88.473': Doctag(offset=6746, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.116.1041': Doctag(offset=4755, word_count=214, doc_count=2),\n",
       " '10.1103/PhysRev.88.1007': Doctag(offset=6613, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.88.1003': Doctag(offset=6612, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.95.121': Doctag(offset=8337, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.107.830': Doctag(offset=2426, word_count=118, doc_count=2),\n",
       " '10.1103/PhysRev.115.521': Doctag(offset=4656, word_count=48, doc_count=2),\n",
       " '10.1103/PhysRev.111.1397': Doctag(offset=3378, word_count=166, doc_count=2),\n",
       " '10.1103/PhysRev.107.836': Doctag(offset=2427, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.111.1395': Doctag(offset=3377, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.101.768': Doctag(offset=644, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.114.389': Doctag(offset=4356, word_count=154, doc_count=2),\n",
       " '10.1103/PhysRev.112.283': Doctag(offset=3795, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.114.383': Doctag(offset=4355, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.112.287': Doctag(offset=3796, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.101.765': Doctag(offset=643, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.97.926': Doctag(offset=9118, word_count=122, doc_count=2),\n",
       " '10.1103/PhysRev.80.154': Doctag(offset=5403, word_count=72, doc_count=2),\n",
       " '10.1103/PhysRev.80.157': Doctag(offset=5404, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.80.150': Doctag(offset=5402, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.88.653': Doctag(offset=6786, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.88.655': Doctag(offset=6787, word_count=300, doc_count=2),\n",
       " '10.1103/PhysRev.95.1606': Doctag(offset=8414, word_count=86, doc_count=2),\n",
       " '10.1103/PhysRev.88.659': Doctag(offset=6788, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.104.273': Doctag(offset=1434, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.92.1236': Doctag(offset=7537, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.104.278': Doctag(offset=1435, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.96.102': Doctag(offset=8564, word_count=24, doc_count=2),\n",
       " '10.1103/PhysRev.96.897': Doctag(offset=8846, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.92.918': Doctag(offset=7747, word_count=72, doc_count=2),\n",
       " '10.1103/PhysRev.96.103': Doctag(offset=8567, word_count=168, doc_count=2),\n",
       " '10.1103/PhysRev.92.913': Doctag(offset=7746, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.111.237': Doctag(offset=3453, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.103.727': Doctag(offset=1214, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.103.720': Doctag(offset=1213, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.91.864': Doctag(offset=7460, word_count=192, doc_count=2),\n",
       " '10.1103/PhysRev.81.951': Doctag(offset=5678, word_count=40, doc_count=2),\n",
       " '10.1103/PhysRev.93.406': Doctag(offset=7906, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.77.314': Doctag(offset=5052, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.93.400': Doctag(offset=7904, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.93.401': Doctag(offset=7905, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.80.1053': Doctag(offset=5392, word_count=152, doc_count=2),\n",
       " '10.1103/PhysRev.105.1751': Doctag(offset=1726, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.77.79': Doctag(offset=5123, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.105.1757': Doctag(offset=1727, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.98.565': Doctag(offset=9326, word_count=160, doc_count=2),\n",
       " '10.1103/PhysRev.97.469': Doctag(offset=9039, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.104.1307': Doctag(offset=1317, word_count=232, doc_count=2),\n",
       " '10.1103/PhysRev.104.1303': Doctag(offset=1316, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.109.1243': Doctag(offset=2770, word_count=280, doc_count=2),\n",
       " '10.1103/PhysRev.104.1301': Doctag(offset=1315, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.110.1070': Doctag(offset=3078, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.110.1071': Doctag(offset=3079, word_count=68, doc_count=2),\n",
       " '10.1103/PhysRev.110.1073': Doctag(offset=3080, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.104.645': Doctag(offset=1514, word_count=140, doc_count=2),\n",
       " '10.1103/PhysRev.110.1076': Doctag(offset=3081, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.104.649': Doctag(offset=1515, word_count=166, doc_count=2),\n",
       " '10.1103/PhysRev.105.320': Doctag(offset=1778, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.92.547': Doctag(offset=7677, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.99.1396': Doctag(offset=9492, word_count=36, doc_count=2),\n",
       " '10.1103/PhysRev.99.1427': Doctag(offset=9499, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.99.1393': Doctag(offset=9491, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.114.1002': Doctag(offset=4206, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.114.1006': Doctag(offset=4207, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.114.1009': Doctag(offset=4208, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.84.621': Doctag(offset=6094, word_count=182, doc_count=2),\n",
       " '10.1103/PhysRev.84.626': Doctag(offset=6095, word_count=194, doc_count=2),\n",
       " '10.1103/PhysRev.96.551': Doctag(offset=8778, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.109.1779': Doctag(offset=2855, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.78.363': Doctag(offset=5174, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.109.1770': Doctag(offset=2854, word_count=228, doc_count=2),\n",
       " '10.1103/PhysRev.92.1448': Doctag(offset=7583, word_count=300, doc_count=2),\n",
       " '10.1103/PhysRev.99.1302': Doctag(offset=9472, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.91.58': Doctag(offset=7409, word_count=228, doc_count=2),\n",
       " '10.1103/PhysRev.102.870': Doctag(offset=949, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.79.549': Doctag(offset=5315, word_count=270, doc_count=2),\n",
       " '10.1103/PhysRev.101.627': Doctag(offset=615, word_count=122, doc_count=2),\n",
       " '10.1103/PhysRev.102.879': Doctag(offset=950, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.91.53': Doctag(offset=7399, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.93.62': Doctag(offset=7951, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.116.507': Doctag(offset=4931, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.93.65': Doctag(offset=7953, word_count=174, doc_count=2),\n",
       " '10.1103/PhysRev.93.64': Doctag(offset=7952, word_count=20, doc_count=2),\n",
       " '10.1103/PhysRev.93.68': Doctag(offset=7962, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.88.673': Doctag(offset=6791, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.115.1039': Doctag(offset=4461, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.108.1131': Doctag(offset=2483, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.96.1310': Doctag(offset=8622, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.96.1316': Doctag(offset=8623, word_count=188, doc_count=2),\n",
       " '10.1103/PhysRev.89.106': Doctag(offset=6862, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.78.799': Doctag(offset=5243, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.87.499': Doctag(offset=6525, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.106.286': Doctag(offset=2005, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.102.913': Doctag(offset=954, word_count=28, doc_count=2),\n",
       " '10.1103/PhysRev.78.791': Doctag(offset=5241, word_count=106, doc_count=2),\n",
       " '10.1103/PhysRev.78.794': Doctag(offset=5242, word_count=46, doc_count=2),\n",
       " '10.1103/PhysRev.98.1456': Doctag(offset=9208, word_count=220, doc_count=2),\n",
       " '10.1103/PhysRev.108.116': Doctag(offset=2488, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.108.445': Doctag(offset=2626, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.108.110': Doctag(offset=2477, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.108.113': Doctag(offset=2482, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.110.673': Doctag(offset=3241, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.110.670': Doctag(offset=3240, word_count=172, doc_count=2),\n",
       " '10.1103/PhysRev.110.676': Doctag(offset=3242, word_count=68, doc_count=2),\n",
       " '10.1103/PhysRev.109.1823': Doctag(offset=2861, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.81.747': Doctag(offset=5649, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.98.6': Doctag(offset=9333, word_count=166, doc_count=2),\n",
       " '10.1103/PhysRev.98.1': Doctag(offset=9132, word_count=152, doc_count=2),\n",
       " '10.1103/PhysRev.113.1254': Doctag(offset=3974, word_count=328, doc_count=2),\n",
       " '10.1103/PhysRev.101.1798': Doctag(offset=523, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.92.355': Doctag(offset=7646, word_count=40, doc_count=2),\n",
       " '10.1103/PhysRev.89.570': Doctag(offset=6978, word_count=20, doc_count=2),\n",
       " '10.1103/PhysRev.89.575': Doctag(offset=6980, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.98.1230': Doctag(offset=9164, word_count=170, doc_count=2),\n",
       " '10.1103/PhysRev.98.1237': Doctag(offset=9165, word_count=186, doc_count=2),\n",
       " '10.1103/PhysRev.113.875': Doctag(offset=4180, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.110.922': Doctag(offset=3284, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.106.1182': Doctag(offset=1941, word_count=44, doc_count=2),\n",
       " '10.1103/RevModPhys.25.2': Doctag(offset=35, word_count=418, doc_count=2),\n",
       " '10.1103/PhysRev.106.1186': Doctag(offset=1942, word_count=176, doc_count=2),\n",
       " '10.1103/PhysRev.110.924': Doctag(offset=3285, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.90.102': Doctag(offset=7065, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.101.1668': Doctag(offset=498, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.112.503': Doctag(offset=3839, word_count=156, doc_count=2),\n",
       " '10.1103/PhysRev.101.1660': Doctag(offset=497, word_count=210, doc_count=2),\n",
       " '10.1103/PhysRev.90.6': Doctag(offset=7179, word_count=30, doc_count=2),\n",
       " '10.1103/PhysRev.90.4': Doctag(offset=7133, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.90.1': Doctag(offset=7061, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.106.1232': Doctag(offset=1951, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.115.314': Doctag(offset=4620, word_count=212, doc_count=2),\n",
       " '10.1103/PhysRev.106.1236': Doctag(offset=1952, word_count=222, doc_count=2),\n",
       " '10.1103/PhysRev.107.337': Doctag(offset=2327, word_count=24, doc_count=2),\n",
       " '10.1103/PhysRev.107.488': Doctag(offset=2356, word_count=188, doc_count=2),\n",
       " '10.1103/PhysRev.107.333': Doctag(offset=2326, word_count=176, doc_count=2),\n",
       " '10.1103/PhysRev.87.768': Doctag(offset=6570, word_count=158, doc_count=2),\n",
       " '10.1103/PhysRev.82.349': Doctag(offset=5707, word_count=252, doc_count=2),\n",
       " '10.1103/PhysRev.101.1485': Doctag(offset=467, word_count=178, doc_count=2),\n",
       " '10.1103/PhysRev.109.355': Doctag(offset=2951, word_count=200, doc_count=2),\n",
       " '10.1103/PhysRev.85.85': Doctag(offset=6277, word_count=136, doc_count=2),\n",
       " '10.1103/PhysRev.109.351': Doctag(offset=2950, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.91.273': Doctag(offset=7360, word_count=166, doc_count=2),\n",
       " '10.1103/PhysRev.91.271': Doctag(offset=7359, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.91.278': Doctag(offset=7361, word_count=172, doc_count=2),\n",
       " '10.1103/PhysRev.103.41': Doctag(offset=1157, word_count=202, doc_count=2),\n",
       " '10.1103/PhysRev.102.667': Doctag(offset=906, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.103.47': Doctag(offset=1167, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.102.269': Doctag(offset=830, word_count=26, doc_count=2),\n",
       " '10.1103/PhysRev.107.159': Doctag(offset=2266, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.101.56': Doctag(offset=599, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.94.1191': Doctag(offset=8051, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.102.262': Doctag(offset=828, word_count=30, doc_count=2),\n",
       " '10.1103/PhysRev.102.264': Doctag(offset=829, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.101.58': Doctag(offset=604, word_count=182, doc_count=2),\n",
       " '10.1103/PhysRev.107.155': Doctag(offset=2258, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.97.673': Doctag(offset=9070, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.105.914': Doctag(offset=1889, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.97.676': Doctag(offset=9071, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.92.145': Doctag(offset=7584, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.93.182': Doctag(offset=7855, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.93.181': Doctag(offset=7854, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.114.1648': Doctag(offset=4323, word_count=140, doc_count=2),\n",
       " '10.1103/PhysRev.109.1172': Doctag(offset=2757, word_count=140, doc_count=2),\n",
       " '10.1103/PhysRev.100.1013': Doctag(offset=87, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.95.1161': Doctag(offset=8323, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.114.1640': Doctag(offset=4321, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.114.1645': Doctag(offset=4322, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.100.1014': Doctag(offset=88, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.109.1211': Doctag(offset=2764, word_count=140, doc_count=2),\n",
       " '10.1103/PhysRev.109.1217': Doctag(offset=2765, word_count=36, doc_count=2),\n",
       " '10.1103/PhysRev.111.425': Doctag(offset=3490, word_count=52, doc_count=2),\n",
       " '10.1103/PhysRev.94.1221': Doctag(offset=8056, word_count=158, doc_count=2),\n",
       " '10.1103/PhysRev.94.1227': Doctag(offset=8057, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.94.1228': Doctag(offset=8058, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.102.1065': Doctag(offset=702, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.105.1502': Doctag(offset=1681, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.102.1063': Doctag(offset=701, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.88.228': Doctag(offset=6696, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.102.1325': Doctag(offset=742, word_count=244, doc_count=2),\n",
       " '10.1103/PhysRev.114.1257': Doctag(offset=4248, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.102.1321': Doctag(offset=741, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.88.225': Doctag(offset=6695, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.78.802': Doctag(offset=5244, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.93.768': Doctag(offset=7978, word_count=410, doc_count=2),\n",
       " '10.1103/PhysRev.88.1217': Doctag(offset=6647, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.94.893': Doctag(offset=8263, word_count=248, doc_count=2),\n",
       " '10.1103/PhysRev.100.376': Doctag(offset=270, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.100.370': Doctag(offset=268, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.114.268': Doctag(offset=4338, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.100.372': Doctag(offset=269, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.103.534': Doctag(offset=1175, word_count=166, doc_count=2),\n",
       " '10.1103/PhysRev.108.1459': Doctag(offset=2545, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.92.1002': Doctag(offset=7496, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.116.888': Doctag(offset=4998, word_count=178, doc_count=2),\n",
       " '10.1103/PhysRev.108.1453': Doctag(offset=2544, word_count=218, doc_count=2),\n",
       " '10.1103/PhysRev.116.885': Doctag(offset=4997, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.92.1009': Doctag(offset=7497, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.116.880': Doctag(offset=4996, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.102.1496': Doctag(offset=774, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.102.1490': Doctag(offset=773, word_count=176, doc_count=2),\n",
       " '10.1103/PhysRev.89.370': Doctag(offset=6942, word_count=232, doc_count=2),\n",
       " '10.1103/PhysRev.89.375': Doctag(offset=6943, word_count=312, doc_count=2),\n",
       " '10.1103/PhysRev.107.776': Doctag(offset=2419, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.113.97': Doctag(offset=4201, word_count=200, doc_count=2),\n",
       " '10.1103/PhysRev.113.595': Doctag(offset=4117, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.113.91': Doctag(offset=4188, word_count=132, doc_count=2),\n",
       " '10.1103/PhysRev.112.344': Doctag(offset=3812, word_count=434, doc_count=2),\n",
       " '10.1103/PhysRev.97.1249': Doctag(offset=8913, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.110.319': Doctag(offset=3178, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.112.341': Doctag(offset=3811, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.90.1019': Doctag(offset=7064, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.110.314': Doctag(offset=3177, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.96.719': Doctag(offset=8820, word_count=46, doc_count=2),\n",
       " '10.1103/PhysRev.90.1013': Doctag(offset=7063, word_count=118, doc_count=2),\n",
       " '10.1103/PhysRev.97.1245': Doctag(offset=8912, word_count=174, doc_count=2),\n",
       " '10.1103/PhysRev.80.457': Doctag(offset=5456, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.108.1048': Doctag(offset=2467, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.81.171': Doctag(offset=5562, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.108.1046': Doctag(offset=2466, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.108.1040': Doctag(offset=2465, word_count=168, doc_count=2),\n",
       " '10.1103/PhysRev.93.1232': Doctag(offset=7812, word_count=154, doc_count=2),\n",
       " '10.1103/PhysRev.78.656': Doctag(offset=5216, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.113.1406': Doctag(offset=3999, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.79.710': Doctag(offset=5341, word_count=158, doc_count=2),\n",
       " '10.1103/PhysRev.99.537': Doctag(offset=9642, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.99.59': Doctag(offset=9653, word_count=176, doc_count=2),\n",
       " '10.1103/PhysRev.107.1542': Doctag(offset=2255, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.102.1355': Doctag(offset=749, word_count=204, doc_count=2),\n",
       " '10.1103/PhysRev.107.1544': Doctag(offset=2256, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.115.1627': Doctag(offset=4566, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.114.847': Doctag(offset=4426, word_count=184, doc_count=2),\n",
       " '10.1103/PhysRev.107.1549': Doctag(offset=2257, word_count=72, doc_count=2),\n",
       " '10.1103/PhysRev.99.1092': Doctag(offset=9432, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.89.98': Doctag(offset=7056, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.112.751': Doctag(offset=3880, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.114.505': Doctag(offset=4372, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.112.755': Doctag(offset=3881, word_count=210, doc_count=2),\n",
       " '10.1103/PhysRev.89.92': Doctag(offset=7044, word_count=72, doc_count=2),\n",
       " '10.1103/PhysRev.103.1004': Doctag(offset=969, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.103.1000': Doctag(offset=968, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.112.1637': Doctag(offset=3698, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.112.1187': Doctag(offset=3623, word_count=218, doc_count=2),\n",
       " '10.1103/PhysRev.103.1008': Doctag(offset=970, word_count=260, doc_count=2),\n",
       " '10.1103/PhysRev.95.750': Doctag(offset=8509, word_count=26, doc_count=2),\n",
       " '10.1103/PhysRev.104.1119': Doctag(offset=1286, word_count=48, doc_count=2),\n",
       " '10.1103/PhysRev.95.751': Doctag(offset=8510, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.104.1444': Doctag(offset=1342, word_count=46, doc_count=2),\n",
       " '10.1103/PhysRev.104.1113': Doctag(offset=1284, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.104.1446': Doctag(offset=1343, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.104.1116': Doctag(offset=1285, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.104.1441': Doctag(offset=1341, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.104.185': Doctag(offset=1418, word_count=226, doc_count=2),\n",
       " '10.1103/PhysRev.108.612': Doctag(offset=2655, word_count=152, doc_count=2),\n",
       " '10.1103/PhysRev.107.1094': Doctag(offset=2167, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.90.738': Doctag(offset=7201, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.83.975': Doctag(offset=5973, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.107.1091': Doctag(offset=2166, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.83.979': Doctag(offset=5974, word_count=140, doc_count=2),\n",
       " '10.1103/PhysRev.108.619': Doctag(offset=2656, word_count=174, doc_count=2),\n",
       " '10.1103/PhysRev.90.730': Doctag(offset=7200, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.95.440': Doctag(offset=8467, word_count=26, doc_count=2),\n",
       " '10.1103/PhysRev.95.441': Doctag(offset=8468, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.107.1099': Doctag(offset=2168, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.93.965': Doctag(offset=8008, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.100.1571': Doctag(offset=192, word_count=158, doc_count=2),\n",
       " '10.1103/PhysRev.86.838': Doctag(offset=6406, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.92.441': Doctag(offset=7667, word_count=216, doc_count=2),\n",
       " '10.1103/PhysRev.100.1579': Doctag(offset=193, word_count=72, doc_count=2),\n",
       " '10.1103/PhysRev.115.1243': Doctag(offset=4501, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.95.974': Doctag(offset=8551, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.112.1456': Doctag(offset=3668, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.112.1451': Doctag(offset=3667, word_count=190, doc_count=2),\n",
       " '10.1103/PhysRev.112.1981': Doctag(offset=3757, word_count=150, doc_count=2),\n",
       " '10.1103/PhysRev.96.1124': Doctag(offset=8584, word_count=228, doc_count=2),\n",
       " '10.1103/PhysRev.112.1989': Doctag(offset=3758, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.104.456': Doctag(offset=1474, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.116.317': Doctag(offset=4891, word_count=180, doc_count=2),\n",
       " '10.1103/PhysRev.116.315': Doctag(offset=4890, word_count=68, doc_count=2),\n",
       " '10.1103/PhysRev.116.314': Doctag(offset=4889, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.100.1713': Doctag(offset=220, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.95.916': Doctag(offset=8540, word_count=52, doc_count=2),\n",
       " '10.1103/PhysRev.95.917': Doctag(offset=8541, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.95.914': Doctag(offset=8539, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.95.912': Doctag(offset=8538, word_count=24, doc_count=2),\n",
       " '10.1103/PhysRev.100.1719': Doctag(offset=221, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.95.911': Doctag(offset=8537, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.96.1433': Doctag(offset=8646, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.96.1438': Doctag(offset=8647, word_count=50, doc_count=2),\n",
       " '10.1103/PhysRev.103.886': Doctag(offset=1242, word_count=334, doc_count=2),\n",
       " '10.1103/PhysRev.104.1481': Doctag(offset=1352, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.83.798': Doctag(offset=5955, word_count=40, doc_count=2),\n",
       " '10.1103/PhysRev.83.792': Doctag(offset=5954, word_count=158, doc_count=2),\n",
       " '10.1103/PhysRev.84.833': Doctag(offset=6137, word_count=146, doc_count=2),\n",
       " '10.1103/PhysRev.101.1349': Doctag(offset=439, word_count=200, doc_count=2),\n",
       " '10.1103/PhysRev.89.1202': Doctag(offset=6884, word_count=152, doc_count=2),\n",
       " '10.1103/PhysRev.84.387': Doctag(offset=6055, word_count=72, doc_count=2),\n",
       " '10.1103/PhysRev.89.1209': Doctag(offset=6885, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.101.1342': Doctag(offset=438, word_count=220, doc_count=2),\n",
       " '10.1103/PhysRev.94.1767': Doctag(offset=8143, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.94.1760': Doctag(offset=8142, word_count=40, doc_count=2),\n",
       " '10.1103/PhysRev.77.258': Doctag(offset=5047, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.78.587': Doctag(offset=5210, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.111.822': Doctag(offset=3560, word_count=312, doc_count=2),\n",
       " '10.1103/PhysRev.106.499': Doctag(offset=2043, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.78.581': Doctag(offset=5209, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.101.337': Doctag(offset=562, word_count=196, doc_count=2),\n",
       " '10.1103/PhysRev.111.920': Doctag(offset=3572, word_count=68, doc_count=2),\n",
       " '10.1103/PhysRev.101.843': Doctag(offset=659, word_count=166, doc_count=2),\n",
       " '10.1103/PhysRev.111.925': Doctag(offset=3573, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.86.755': Doctag(offset=6396, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.111.929': Doctag(offset=3574, word_count=166, doc_count=2),\n",
       " '10.1103/PhysRev.97.791': Doctag(offset=9096, word_count=120, doc_count=2),\n",
       " '10.1103/PhysRev.97.797': Doctag(offset=9097, word_count=240, doc_count=2),\n",
       " '10.1103/PhysRev.109.165': Doctag(offset=2838, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.82.664': Doctag(offset=5762, word_count=516, doc_count=2),\n",
       " '10.1103/PhysRev.82.885': Doctag(offset=5805, word_count=140, doc_count=2),\n",
       " '10.1103/PhysRev.82.883': Doctag(offset=5804, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.106.721': Doctag(offset=2086, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.96.722': Doctag(offset=8821, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.106.723': Doctag(offset=2087, word_count=72, doc_count=2),\n",
       " '10.1103/PhysRev.106.726': Doctag(offset=2088, word_count=180, doc_count=2),\n",
       " '10.1103/PhysRev.116.1201': Doctag(offset=4784, word_count=150, doc_count=2),\n",
       " '10.1103/PhysRev.113.602': Doctag(offset=4118, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.100.564': Doctag(offset=291, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.81.919': Doctag(offset=5669, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.115.503': Doctag(offset=4654, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.81.910': Doctag(offset=5668, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.97.427': Doctag(offset=9030, word_count=34, doc_count=2),\n",
       " '10.1103/PhysRev.96.725': Doctag(offset=8822, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.97.428': Doctag(offset=9031, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.88.412': Doctag(offset=6737, word_count=42, doc_count=2),\n",
       " '10.1103/PhysRev.94.1143': Doctag(offset=8040, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.97.1272': Doctag(offset=8919, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.91.728': Doctag(offset=7437, word_count=150, doc_count=2),\n",
       " '10.1103/PhysRev.88.1027': Doctag(offset=6616, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.111.1373': Doctag(offset=3373, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.116.1069': Doctag(offset=4762, word_count=172, doc_count=2),\n",
       " '10.1103/PhysRev.116.1066': Doctag(offset=4761, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.116.1063': Doctag(offset=4760, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.98.1622': Doctag(offset=9226, word_count=98, doc_count=2),\n",
       " '10.1103/PhysRev.105.806': Doctag(offset=1870, word_count=220, doc_count=2),\n",
       " '10.1103/PhysRev.80.608': Doctag(offset=5481, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.98.666': Doctag(offset=9345, word_count=64, doc_count=2),\n",
       " '10.1103/PhysRev.80.603': Doctag(offset=5480, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.93.796': Doctag(offset=7981, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.105.1198': Doctag(offset=1617, word_count=132, doc_count=2),\n",
       " '10.1103/PhysRev.92.1521': Doctag(offset=7601, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.86.243': Doctag(offset=6331, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.105.1192': Doctag(offset=1616, word_count=332, doc_count=2),\n",
       " '10.1103/PhysRev.85.582': Doctag(offset=6240, word_count=86, doc_count=2),\n",
       " '10.1103/PhysRev.104.218': Doctag(offset=1425, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.104.211': Doctag(offset=1424, word_count=132, doc_count=2),\n",
       " '10.1103/PhysRev.95.1628': Doctag(offset=8416, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.105.692': Doctag(offset=1849, word_count=30, doc_count=2),\n",
       " '10.1103/PhysRev.105.121': Doctag(offset=1621, word_count=32, doc_count=2),\n",
       " '10.1103/PhysRev.105.123': Doctag(offset=1624, word_count=144, doc_count=2),\n",
       " '10.1103/PhysRev.114.104': Doctag(offset=4214, word_count=242, doc_count=2),\n",
       " '10.1103/PhysRev.92.935': Doctag(offset=7754, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.111.212': Doctag(offset=3450, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.92.931': Doctag(offset=7752, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.103.704': Doctag(offset=1209, word_count=184, doc_count=2),\n",
       " '10.1103/PhysRev.91.842': Doctag(offset=7457, word_count=238, doc_count=2),\n",
       " '10.1103/PhysRev.103.701': Doctag(offset=1208, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.93.420': Doctag(offset=7910, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.105.1772': Doctag(offset=1730, word_count=404, doc_count=2),\n",
       " '10.1103/PhysRev.93.425': Doctag(offset=7911, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.85.112': Doctag(offset=6174, word_count=118, doc_count=2),\n",
       " '10.1103/PhysRev.80.1076': Doctag(offset=5395, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.105.348': Doctag(offset=1782, word_count=52, doc_count=2),\n",
       " '10.1103/PhysRev.110.1057': Doctag(offset=3073, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.110.1050': Doctag(offset=3072, word_count=286, doc_count=2),\n",
       " '10.1103/PhysRev.104.662': Doctag(offset=1517, word_count=40, doc_count=2),\n",
       " '10.1103/PhysRev.104.660': Doctag(offset=1516, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.104.666': Doctag(offset=1519, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.81.517': Doctag(offset=5614, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.105.347': Doctag(offset=1781, word_count=42, doc_count=2),\n",
       " '10.1103/PhysRev.101.216': Doctag(offset=539, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.94.454': Doctag(offset=8199, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.101.214': Doctag(offset=538, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.114.1065': Doctag(offset=4218, word_count=132, doc_count=2),\n",
       " '10.1103/PhysRev.114.1060': Doctag(offset=4217, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.109.1792': Doctag(offset=2857, word_count=156, doc_count=2),\n",
       " '10.1103/PhysRev.89.299': Doctag(offset=6932, word_count=30, doc_count=2),\n",
       " '10.1103/PhysRev.89.295': Doctag(offset=6931, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.104.1580': Doctag(offset=1374, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.104.1585': Doctag(offset=1375, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.89.123': Doctag(offset=6888, word_count=106, doc_count=2),\n",
       " '10.1103/PhysRev.79.520': Doctag(offset=5312, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.91.31': Doctag(offset=7369, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.96.643': Doctag(offset=8800, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.102.891': Doctag(offset=952, word_count=224, doc_count=2),\n",
       " '10.1103/PhysRev.79.526': Doctag(offset=5313, word_count=20, doc_count=2),\n",
       " '10.1103/PhysRev.83.899': Doctag(offset=5963, word_count=168, doc_count=2),\n",
       " '10.1103/PhysRev.110.1232': Doctag(offset=3109, word_count=136, doc_count=2),\n",
       " '10.1103/PhysRev.96.645': Doctag(offset=8801, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.110.1235': Doctag(offset=3110, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.99.1406': Doctag(offset=9494, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.94.683': Doctag(offset=8238, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.96.503': Doctag(offset=8772, word_count=128, doc_count=2),\n",
       " '10.1103/PhysRev.99.1400': Doctag(offset=9493, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.96.508': Doctag(offset=8773, word_count=260, doc_count=2),\n",
       " '10.1103/PhysRev.102.1684': Doctag(offset=808, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.96.1335': Doctag(offset=8626, word_count=156, doc_count=2),\n",
       " '10.1103/PhysRev.96.1337': Doctag(offset=8627, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.82.52': Doctag(offset=5739, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.96.1333': Doctag(offset=8625, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.106.266': Doctag(offset=2002, word_count=240, doc_count=2),\n",
       " '10.1103/PhysRev.106.261': Doctag(offset=2001, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.93.270': Doctag(offset=7876, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.108.421': Doctag(offset=2623, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.108.427': Doctag(offset=2624, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.93.882': Doctag(offset=8001, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.90.695': Doctag(offset=7196, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.93.880': Doctag(offset=8000, word_count=154, doc_count=2),\n",
       " '10.1103/PhysRev.90.690': Doctag(offset=7195, word_count=46, doc_count=2),\n",
       " '10.1103/PhysRev.99.1667': Doctag(offset=9532, word_count=144, doc_count=2),\n",
       " '10.1103/PhysRev.115.1015': Doctag(offset=4458, word_count=52, doc_count=2),\n",
       " '10.1103/PhysRev.107.1372': Doctag(offset=2223, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.93.888': Doctag(offset=8002, word_count=22, doc_count=2),\n",
       " '10.1103/PhysRev.115.1016': Doctag(offset=4459, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.115.1546': Doctag(offset=4551, word_count=216, doc_count=2),\n",
       " '10.1103/PhysRev.110.692': Doctag(offset=3244, word_count=276, doc_count=2),\n",
       " '10.1103/PhysRev.115.1012': Doctag(offset=4457, word_count=118, doc_count=2),\n",
       " '10.1103/PhysRev.113.1236': Doctag(offset=3972, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.109.47': Doctag(offset=2973, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.109.43': Doctag(offset=2965, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.109.40': Doctag(offset=2959, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.96.1590': Doctag(offset=8681, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.96.1593': Doctag(offset=8682, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.112.1848': Doctag(offset=3735, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.112.1843': Doctag(offset=3734, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.103.1619': Doctag(offset=1068, word_count=132, doc_count=2),\n",
       " '10.1103/PhysRev.109.2178': Doctag(offset=2925, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.113.857': Doctag(offset=4177, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.109.2177': Doctag(offset=2924, word_count=80, doc_count=2),\n",
       " '10.1103/PhysRev.113.852': Doctag(offset=4176, word_count=144, doc_count=2),\n",
       " '10.1103/PhysRev.112.568': Doctag(offset=3851, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.101.1647': Doctag(offset=493, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.90.473': Doctag(offset=7150, word_count=214, doc_count=2),\n",
       " '10.1103/PhysRev.101.1641': Doctag(offset=491, word_count=54, doc_count=2),\n",
       " '10.1103/PhysRev.90.476': Doctag(offset=7151, word_count=128, doc_count=2),\n",
       " '10.1103/PhysRev.101.1642': Doctag(offset=492, word_count=132, doc_count=2),\n",
       " '10.1103/PhysRev.112.560': Doctag(offset=3850, word_count=126, doc_count=2),\n",
       " '10.1103/PhysRev.90.479': Doctag(offset=7152, word_count=172, doc_count=2),\n",
       " '10.1103/PhysRev.101.1648': Doctag(offset=494, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.108.139': Doctag(offset=2529, word_count=106, doc_count=2),\n",
       " '10.1103/PhysRev.93.114': Doctag(offset=7793, word_count=46, doc_count=2),\n",
       " '10.1103/PhysRev.105.202': Doctag(offset=1756, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.80.987': Doctag(offset=5542, word_count=44, doc_count=2),\n",
       " '10.1103/PhysRev.80.985': Doctag(offset=5541, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.93.117': Doctag(offset=7799, word_count=106, doc_count=2),\n",
       " '10.1103/PhysRev.80.982': Doctag(offset=5540, word_count=72, doc_count=2),\n",
       " '10.1103/PhysRev.98.685': Doctag(offset=9349, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.115.254': Doctag(offset=4610, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.106.1257': Doctag(offset=1958, word_count=48, doc_count=2),\n",
       " '10.1103/PhysRev.106.1256': Doctag(offset=1957, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.106.1252': Doctag(offset=1956, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.115.999': Doctag(offset=4746, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.115.330': Doctag(offset=4622, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.115.336': Doctag(offset=4623, word_count=218, doc_count=2),\n",
       " '10.1103/PhysRev.110.128': Doctag(offset=3115, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.102.797': Doctag(offset=930, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.83.1005': Doctag(offset=5817, word_count=228, doc_count=2),\n",
       " '10.1103/PhysRev.95.1365': Doctag(offset=8364, word_count=148, doc_count=2),\n",
       " '10.1103/PhysRev.109.375': Doctag(offset=2954, word_count=110, doc_count=2),\n",
       " '10.1103/PhysRev.95.1369': Doctag(offset=8365, word_count=180, doc_count=2),\n",
       " '10.1103/PhysRev.87.703': Doctag(offset=6557, word_count=176, doc_count=2),\n",
       " '10.1103/PhysRev.87.706': Doctag(offset=6558, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.95.38': Doctag(offset=8453, word_count=122, doc_count=2),\n",
       " '10.1103/PhysRev.100.1387': Doctag(offset=158, word_count=108, doc_count=2),\n",
       " '10.1103/PhysRev.93.228': Doctag(offset=7867, word_count=24, doc_count=2),\n",
       " '10.1103/PhysRev.95.31': Doctag(offset=8440, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.103.29': Doctag(offset=1131, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.109.1159': Doctag(offset=2754, word_count=178, doc_count=2),\n",
       " '10.1103/PhysRev.103.20': Doctag(offset=1112, word_count=218, doc_count=2),\n",
       " '10.1103/PhysRev.109.1153': Doctag(offset=2753, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.101.79': Doctag(offset=649, word_count=76, doc_count=2),\n",
       " '10.1103/PhysRev.105.976': Doctag(offset=1901, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.105.974': Doctag(offset=1900, word_count=40, doc_count=2),\n",
       " '10.1103/PhysRev.92.164': Doctag(offset=7614, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.83.637': Doctag(offset=5930, word_count=124, doc_count=2),\n",
       " '10.1103/PhysRev.83.634': Doctag(offset=5929, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.92.161': Doctag(offset=7613, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.100.1037': Doctag(offset=92, word_count=144, doc_count=2),\n",
       " '10.1103/PhysRev.85.474': Doctag(offset=6225, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.83.1231': Doctag(offset=5852, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.93.163': Doctag(offset=7848, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.102.1049': Doctag(offset=697, word_count=36, doc_count=2),\n",
       " '10.1103/PhysRev.99.229': Doctag(offset=9588, word_count=146, doc_count=2),\n",
       " '10.1103/PhysRev.102.1041': Doctag(offset=696, word_count=262, doc_count=2),\n",
       " '10.1103/PhysRev.105.1563': Doctag(offset=1696, word_count=196, doc_count=2),\n",
       " '10.1103/PhysRev.91.78': Doctag(offset=7444, word_count=66, doc_count=2),\n",
       " '10.1103/PhysRev.94.1243': Doctag(offset=8059, word_count=250, doc_count=2),\n",
       " '10.1103/PhysRev.102.242': Doctag(offset=823, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.102.243': Doctag(offset=824, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.115.194': Doctag(offset=4600, word_count=138, doc_count=2),\n",
       " '10.1103/PhysRev.107.176': Doctag(offset=2297, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.102.530': Doctag(offset=884, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.102.247': Doctag(offset=826, word_count=22, doc_count=2),\n",
       " '10.1103/PhysRev.102.244': Doctag(offset=825, word_count=130, doc_count=2),\n",
       " '10.1103/PhysRev.115.191': Doctag(offset=4599, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.86.497': Doctag(offset=6367, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.112.981': Doctag(offset=3920, word_count=136, doc_count=2),\n",
       " '10.1103/PhysRev.112.986': Doctag(offset=3921, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.92.1396': Doctag(offset=7573, word_count=92, doc_count=2),\n",
       " '10.1103/PhysRev.109.888': Doctag(offset=3043, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.109.884': Doctag(offset=3042, word_count=96, doc_count=2),\n",
       " '10.1103/PhysRev.114.1273': Doctag(offset=4254, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.114.1270': Doctag(offset=4253, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.87.688': Doctag(offset=6553, word_count=274, doc_count=2),\n",
       " '10.1103/PhysRev.102.1303': Doctag(offset=739, word_count=114, doc_count=2),\n",
       " '10.1103/PhysRev.102.1302': Doctag(offset=738, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.102.1308': Doctag(offset=740, word_count=200, doc_count=2),\n",
       " '10.1103/PhysRev.107.431': Doctag(offset=2348, word_count=112, doc_count=2),\n",
       " '10.1103/PhysRev.88.206': Doctag(offset=6694, word_count=232, doc_count=2),\n",
       " '10.1103/PhysRev.88.752': Doctag(offset=6807, word_count=116, doc_count=2),\n",
       " '10.1103/PhysRev.89.870': Doctag(offset=7042, word_count=242, doc_count=2),\n",
       " '10.1103/PhysRev.88.202': Doctag(offset=6693, word_count=136, doc_count=2),\n",
       " '10.1103/PhysRev.102.766': Doctag(offset=927, word_count=20, doc_count=2),\n",
       " '10.1103/PhysRev.88.1277': Doctag(offset=6658, word_count=146, doc_count=2),\n",
       " '10.1103/PhysRev.106.330': Doctag(offset=2013, word_count=264, doc_count=2),\n",
       " '10.1103/PhysRev.88.1275': Doctag(offset=6657, word_count=100, doc_count=2),\n",
       " '10.1103/PhysRev.88.759': Doctag(offset=6808, word_count=104, doc_count=2),\n",
       " '10.1103/PhysRev.92.1021': Doctag(offset=7502, word_count=26, doc_count=2),\n",
       " '10.1103/PhysRev.108.1473': Doctag(offset=2547, word_count=244, doc_count=2),\n",
       " '10.1103/PhysRev.103.558': Doctag(offset=1179, word_count=62, doc_count=2),\n",
       " '10.1103/PhysRev.98.857': Doctag(offset=9387, word_count=448, doc_count=2),\n",
       " '10.1103/PhysRev.105.1388': Doctag(offset=1657, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.89.359': Doctag(offset=6940, word_count=162, doc_count=2),\n",
       " '10.1103/PhysRev.86.476': Doctag(offset=6363, word_count=154, doc_count=2),\n",
       " '10.1103/PhysRev.89.352': Doctag(offset=6938, word_count=244, doc_count=2),\n",
       " '10.1103/PhysRev.105.1382': Doctag(offset=1656, word_count=68, doc_count=2),\n",
       " '10.1103/PhysRev.89.357': Doctag(offset=6939, word_count=56, doc_count=2),\n",
       " '10.1103/PhysRev.111.82': Doctag(offset=3559, word_count=134, doc_count=2),\n",
       " '10.1103/PhysRev.94.845': Doctag(offset=8253, word_count=40, doc_count=2),\n",
       " '10.1103/PhysRev.94.847': Doctag(offset=8254, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.105.590': Doctag(offset=1830, word_count=190, doc_count=2),\n",
       " '10.1103/PhysRev.90.1079': Doctag(offset=7083, word_count=160, doc_count=2),\n",
       " '10.1103/PhysRev.107.28': Doctag(offset=2318, word_count=82, doc_count=2),\n",
       " '10.1103/PhysRev.112.369': Doctag(offset=3814, word_count=280, doc_count=2),\n",
       " '10.1103/PhysRev.90.1072': Doctag(offset=7081, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.107.25': Doctag(offset=2311, word_count=88, doc_count=2),\n",
       " '10.1103/PhysRev.112.362': Doctag(offset=3813, word_count=210, doc_count=2),\n",
       " '10.1103/PhysRev.90.1075': Doctag(offset=7082, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.108.1063': Doctag(offset=2471, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.81.115': Doctag(offset=5556, word_count=132, doc_count=2),\n",
       " '10.1103/PhysRev.112.1779': Doctag(offset=3721, word_count=136, doc_count=2),\n",
       " '10.1103/RevModPhys.25.269': Doctag(offset=40, word_count=452, doc_count=2),\n",
       " '10.1103/PhysRev.111.1631': Doctag(offset=3425, word_count=50, doc_count=2),\n",
       " '10.1103/PhysRev.111.1633': Doctag(offset=3426, word_count=58, doc_count=2),\n",
       " '10.1103/PhysRev.99.559': Doctag(offset=9649, word_count=216, doc_count=2),\n",
       " '10.1103/PhysRev.111.1636': Doctag(offset=3427, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.99.553': Doctag(offset=9647, word_count=84, doc_count=2),\n",
       " '10.1103/PhysRev.99.550': Doctag(offset=9646, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.99.556': Doctag(offset=9648, word_count=164, doc_count=2),\n",
       " '10.1103/PhysRev.99.885': Doctag(offset=9694, word_count=74, doc_count=2),\n",
       " '10.1103/PhysRev.101.599': Doctag(offset=609, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.107.1565': Doctag(offset=2262, word_count=70, doc_count=2),\n",
       " '10.1103/PhysRev.92.896': Doctag(offset=7740, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.101.591': Doctag(offset=607, word_count=94, doc_count=2),\n",
       " '10.1103/PhysRev.114.822': Doctag(offset=4421, word_count=90, doc_count=2),\n",
       " '10.1103/PhysRev.114.820': Doctag(offset=4420, word_count=38, doc_count=2),\n",
       " '10.1103/PhysRev.114.827': Doctag(offset=4423, word_count=102, doc_count=2),\n",
       " '10.1103/PhysRev.101.594': Doctag(offset=608, word_count=78, doc_count=2),\n",
       " '10.1103/PhysRev.114.825': Doctag(offset=4422, word_count=28, doc_count=2),\n",
       " '10.1103/PhysRev.107.1569': Doctag(offset=2263, word_count=142, doc_count=2),\n",
       " '10.1103/PhysRev.115.81': Doctag(offset=4709, word_count=172, doc_count=2),\n",
       " '10.1103/PhysRev.115.87': Doctag(offset=4718, word_count=150, doc_count=2),\n",
       " '10.1103/PhysRev.99.1871': Doctag(offset=9578, word_count=60, doc_count=2),\n",
       " '10.1103/PhysRev.112.1616': Doctag(offset=3694, word_count=88, doc_count=2),\n",
       " ...}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.doctags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is interesting. **Electron** is to **electrons** as **atom** is to **atoms**. Another way to understand this, developed below is: **electrons - electron** induces a singular to plural dimension, so when we subtract **electron** from **atom** and add **electrons**, we get **atoms**! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_vocab() takes at least 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-41d56916387e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: build_vocab() takes at least 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "model.build_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('photoconductors', 0.9468032717704773)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apsD2V.most_similar(positive = ['einstein','law'], negative = ['equation'], topn = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In other words **Einstein** minus **equation** plus **law** equals **Meissner**--Walthur Meissner studied mechanical engineering and physics ... and was more likely to produce a \"law\" than a \"equation\", like the Meissner effect, the damping of the magnetic field in superconductors. If we built our word-embedding with a bigger corpus like the entire arXiv, a massive repository of physics preprints, we would see many more such relationships like **gravity - Newton + Einstein = relativity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also compute all of these *by hand*--explicitly wth vector algebra: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.pairwise.cosine_similarity(apsD2V['electron'].reshape(1,-1), apsD2V['positron'].reshape(1,-1))\n",
    "#We reorient the vectors with .reshape(1, -1) so that they can be computed without a warning in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the doc2vec model, the documents have vectors just as the words do, so that we can compare documents with each other and also with words (similar to how a search engine locates a webpage with a query). First, we will calculate the distance between a word and documents in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10.1103/PhysRev.100.1646', 0.6731252074241638),\n",
       " ('10.1103/PhysRev.84.621', 0.6257778406143188),\n",
       " ('10.1103/PhysRev.108.1322', 0.6192793846130371),\n",
       " ('10.1103/PhysRev.112.812', 0.6183947324752808),\n",
       " ('10.1103/PhysRev.104.1220', 0.5983973741531372)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apsD2V.docvecs.most_similar([ apsD2V['electron'] ], topn=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If we search for the first of these on the web (these are doi codes), we find the following...a pretty good match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's go the other way around and find words most similar to this document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reverses', 0.7260420322418213),\n",
       " ('larmor', 0.7224563360214233),\n",
       " ('constant', 0.7018139958381653),\n",
       " ('electric', 0.670346736907959),\n",
       " ('magnitude', 0.6669138073921204)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apsD2V.most_similar( [ apsD2V.docvecs['10.1103/PhysRev.98.875'] ], topn=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can even look for documents most like a query composed of multiple words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10.1103/PhysRev.109.1193', 0.7988286018371582),\n",
       " ('10.1103/PhysRev.89.1165', 0.7927871346473694),\n",
       " ('10.1103/PhysRev.81.536', 0.7840364575386047),\n",
       " ('10.1103/PhysRev.85.1012', 0.7804019451141357),\n",
       " ('10.1103/PhysRev.85.120', 0.7799358367919922)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apsD2V.docvecs.most_similar([ apsD2V['electron']+apsD2V['positron']+apsD2V['neutron']], topn=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's plot some words and documents against one another with a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "heatmapMatrix = []\n",
    "for tagOuter in keywords:\n",
    "    column = []\n",
    "    tagVec = apsD2V.docvecs[tagOuter].reshape(1, -1)\n",
    "    for tagInner in keywords:\n",
    "        column.append(sklearn.metrics.pairwise.cosine_similarity(tagVec, apsD2V.docvecs[tagInner].reshape(1, -1))[0][0])\n",
    "    heatmapMatrix.append(column)\n",
    "heatmapMatrix = np.array(heatmapMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "heatmapMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "hmap = ax.pcolor(heatmapMatrix, cmap='terrain')\n",
    "cbar = plt.colorbar(hmap)\n",
    "\n",
    "cbar.set_label('cosine similarity', rotation=270)\n",
    "a = ax.set_xticks(np.arange(heatmapMatrix.shape[1]) + 0.5, minor=False)\n",
    "a = ax.set_yticks(np.arange(heatmapMatrix.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "a = ax.set_xticklabels(keywords, minor=False, rotation=270)\n",
    "a = ax.set_yticklabels(keywords, minor=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's look at a heatmap of similarities between the first ten documents in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "targetDocs = apsDF['doi'][:10]\n",
    "\n",
    "heatmapMatrixD = []\n",
    "\n",
    "for tagOuter in targetDocs:\n",
    "    column = []\n",
    "    tagVec = apsD2V.docvecs[tagOuter].reshape(1, -1)\n",
    "    for tagInner in targetDocs:\n",
    "        column.append(sklearn.metrics.pairwise.cosine_similarity(tagVec, apsD2V.docvecs[tagInner].reshape(1, -1))[0][0])\n",
    "    heatmapMatrixD.append(column)\n",
    "heatmapMatrixD = np.array(heatmapMatrixD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "hmap = ax.pcolor(heatmapMatrixD, cmap='terrain')\n",
    "cbar = plt.colorbar(hmap)\n",
    "\n",
    "cbar.set_label('cosine similarity', rotation=270)\n",
    "a = ax.set_xticks(np.arange(heatmapMatrixD.shape[1]) + 0.5, minor=False)\n",
    "a = ax.set_yticks(np.arange(heatmapMatrixD.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "a = ax.set_xticklabels(targetDocs, minor=False, rotation=270)\n",
    "a = ax.set_yticklabels(targetDocs, minor=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's look at a heatmap of similarities between the first ten documents and our keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "heatmapMatrixC = []\n",
    "\n",
    "for tagOuter in targetDocs:\n",
    "    column = []\n",
    "    tagVec = apsD2V.docvecs[tagOuter].reshape(1, -1)\n",
    "    for tagInner in keywords:\n",
    "        column.append(sklearn.metrics.pairwise.cosine_similarity(tagVec, apsD2V.docvecs[tagInner].reshape(1, -1))[0][0])\n",
    "    heatmapMatrixC.append(column)\n",
    "heatmapMatrixC = np.array(heatmapMatrixC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "hmap = ax.pcolor(heatmapMatrixC, cmap='terrain')\n",
    "cbar = plt.colorbar(hmap)\n",
    "\n",
    "cbar.set_label('cosine similarity', rotation=270)\n",
    "a = ax.set_xticks(np.arange(heatmapMatrixC.shape[1]) + 0.5, minor=False)\n",
    "a = ax.set_yticks(np.arange(heatmapMatrixC.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "a = ax.set_xticklabels(keywords, minor=False, rotation=270)\n",
    "a = ax.set_yticklabels(targetDocs, minor=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will save the model in case we would like to use it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "apsD2V.save('data/apsW2V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can later load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#apsD2V = gensim.models.word2vec.Word2Vec.load('data/apsW2V')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <span style=\"color:red\">*Your Turn*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that build a doc2vec model with your corpus. Interrogate document and word relationships in the resulting space. Construct a heatmap that plots the distances between a subset of your documents against each other, and against a set of informative words. Find distances between *every* document in your corpus and a word or query of interest. What do these doc-doc proximities reveal about your corpus? What do these word-doc proximities highlight? Demonstrate and document one reasonable way to select a defensible subset of query-relevant documents for subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The Score Function\n",
    "\n",
    "The score function is a simple calculation developed by [Matt Taddy](https://arxiv.org/pdf/1504.07295.pdf) to calculate the likelihood that a given text would have been generated by a word-embedding model by summing the inner product between each pair of the text's word vectors. \n",
    "\n",
    "Here, we explore this using a model trained with millions of resumes from the CareerBuilder website (we can't share the private resumes...but we can share a model built with them :-):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/resume.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-849e664cbd8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresume_model\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/resume.model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Sorry we can't make this public\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/mll/.pyenv/versions/2.7.13/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m         \u001b[0;31m# update older models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mll/.pyenv/versions/2.7.13/lib/python2.7/site-packages/gensim/utils.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mll/.pyenv/versions/2.7.13/lib/python2.7/site-packages/gensim/utils.pyc\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;34m\"\"\"Load pickled object from `fname`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mll/.pyenv/versions/2.7.13/lib/python2.7/site-packages/smart_open/smart_open_lib.pyc\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;31m# local files -- both read & write supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# compression, if any, is determined by the filename extension (.gz, .bz2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile_smart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"s3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s3n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s3u\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mll/.pyenv/versions/2.7.13/lib/python2.7/site-packages/smart_open/smart_open_lib.pyc\u001b[0m in \u001b[0;36mfile_smart_open\u001b[0;34m(fname, mode)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_closing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/resume.model'"
     ]
    }
   ],
   "source": [
    "resume_model  = gensim.models.word2vec.Word2Vec.load('data/resume.model') #Sorry we can't make this public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can examine the vacabularies of this model by building a word-index map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab = resume_model.index2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's load a few job ads. Here, we only use a small sample of all of them. Uncomment this cell if you want to load more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# with open('data/joblistings.merged.parsed.unique.grpbyyear.2010-2015.02.tsv','r') as tsv:\n",
    "#     ads = [line.strip().split('\\t') for line in tsv]\n",
    "    \n",
    "# adsDF = pandas.DataFrame(ads, columns = ads[0])\n",
    "# reducedDF = adsDF[['hiringOrganization_organizationName', 'jobDescription', 'jobLocation_address_region', 'jobLocation_geo_latitude', 'jobLocation_geo_longitude', 'qualifications', 'responsibilities']][1:]\n",
    "# N = reducedDF.shape[0]\n",
    "# indices = random.sample(range(1, N+1), 100)\n",
    "# sampleDF = reducedDF.iloc[indices]\n",
    "# sampleDF.to_csv('data/SampleJobAds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's just load the sample and take a look at it. The sentences in each job description are already tokenized and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sampleDF = pandas.read_csv('data/SampleJobAds.csv', index_col = False)\n",
    "#We need to convert the last couple columns from strings to lists\n",
    "sampleDF['tokenized_sents'] = sampleDF['tokenized_sents'].apply(lambda x: eval(x))\n",
    "sampleDF['normalized_sents'] = sampleDF['normalized_sents'].apply(lambda x: eval(x))\n",
    "sampleDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's define a function to calculate the likelihood of each job description. The idea is borrowed from [Matt Taddy](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/deepir.ipynb), who shows how a document can be characterized as the inner product of the distance between its words. In other words, this analysis will show which job ads are most likely to find an appropriate pool of workers in the resume bank that generated our word embedding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def adprob(ad, model):\n",
    "    sen_scores = model.score(ad, len(ad))\n",
    "    ad_score = sen_scores.mean()\n",
    "    return ad_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's apply this function to every job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sampleDF['likelihood'] = sampleDF['normalized_sents'].apply(lambda x: adprob(x, resume_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's take a look at the top 5 job descriptions that have the highest likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for ad in sampleDF.sort_values(by = 'likelihood', ascending = False)['jobDescription'][:5]:\n",
    "    print (ad + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's take a look at the bottom 5 job descriptions that have the lowest likelihood to be matched by the resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for ad in sampleDF.sort_values(by = 'likelihood')['jobDescription'][:5]:\n",
    "    print (ad + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can do the same for phrases corresponding to job skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adprob([[\"python\", \"programming\"]], resume_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adprob([[\"basic\", \"programming\"]], resume_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Basic programming appears to be more likely in this pool of resumes than python programming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also do some simple statistics. Unfortunately, we don't have a large sample here. Nevertheless, let's first look at the mean likelihood score of each hiring organization. Some organizations will do well to hire on CareerBuilder...while others will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sampleDF.groupby(\"hiringOrganization_organizationName\")[['likelihood']].mean().sort_values('likelihood', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also look at the mean likelihood of each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sampleDF.groupby(\"jobLocation_address_region\")[['likelihood']].mean().sort_values('likelihood', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You would increase the sample size if you want to do a more serious study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <span style=\"color:red\">*Your Turn*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that calculate the scores for a small sample of documents from outside your corpus to identify which are *closest* to your corpus. Then calculate the scores for a few phrases or sentences to identify the ones most likely to have appeared in your corpus. Interrogate patterns associated with these document/phrase scores (e.g., which companies produced job ads most or least likely to find jobseekers in the resume corpus?) What do these patterns suggest about the boundaries of your corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also project word vectors to an arbitray semantic dimension. To demonstrate this possibility, let's first load a model trained with New York Times news articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nytimes_model = gensim.models.word2vec.Word2Vec.load_word2vec_format('data/nytimes_cbow.reduced.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First we can visualize with dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#words to create dimensions\n",
    "tnytTargetWords = ['man','him','he', 'woman', 'her', 'she', 'black','blacks','African', 'white', 'whites', 'Caucasian', 'rich', 'richer', 'richest', 'expensive', 'wealthy', 'poor', 'poorer', 'poorest', 'cheap', 'inexpensive']\n",
    "#words we will be mapping\n",
    "tnytTargetWords += [\"doctor\",\"lawyer\",\"plumber\",\"scientist\",\"hairdresser\", \"nanny\",\"carpenter\",\"entrepreneur\",\"musician\",\"writer\", \"banker\",\"poet\",\"nurse\", \"steak\", \"bacon\", \"croissant\", \"cheesecake\", \"salad\", \"cheeseburger\", \"vegetables\", \"beer\", \"wine\", \"pastry\", \"basketball\", \"baseball\", \"boxing\", \"softball\", \"volleyball\", \"tennis\", \"golf\", \"hockey\", \"soccer\"]\n",
    "\n",
    "\n",
    "wordsSubMatrix = []\n",
    "for word in tnytTargetWords:\n",
    "    wordsSubMatrix.append(nytimes_model[word])\n",
    "wordsSubMatrix = np.array(wordsSubMatrix)\n",
    "wordsSubMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pcaWordsNYT = sklearn.decomposition.PCA(n_components = 50).fit(wordsSubMatrix)\n",
    "reducedPCA_dataNYT = pcaWordsNYT.transform(wordsSubMatrix)\n",
    "#T-SNE is theoretically better, but you should experiment\n",
    "tsneWordsNYT = sklearn.manifold.TSNE(n_components = 2).fit_transform(reducedPCA_dataNYT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tsneWordsNYT[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "plt.scatter(tsneWordsNYT[:, 0], tsneWordsNYT[:, 1], alpha = 0) #Making the points invisible\n",
    "for i, word in enumerate(tnytTargetWords):\n",
    "    ax.annotate(word, (tsneWordsNYT[:, 0][i],tsneWordsNYT[:, 1][i]), size =  20 * (len(tnytTargetWords) - i) / len(tnytTargetWords))\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define some convenient functions for getting dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    normalized_vector = vector / np.linalg.norm(vector)\n",
    "    return normalized_vector\n",
    "\n",
    "def dimension(model, positives, negatives):\n",
    "    diff = sum([normalize(model[x]) for x in positives]) - sum([normalize(model[y]) for y in negatives])\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's calculate three dimensions: gender, race, and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Gender = dimension(nytimes_model, ['man','him','he'], ['woman', 'her', 'she'])\n",
    "Race = dimension(nytimes_model, ['black','blacks','African'], ['white', 'whites', 'Caucasian'])\n",
    "Class = dimension(nytimes_model, ['rich', 'richer', 'richest', 'expensive', 'wealthy'], ['poor', 'poorer', 'poorest', 'cheap', 'inexpensive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we have some words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Occupations = [\"doctor\",\"lawyer\",\"plumber\",\"scientist\",\"hairdresser\", \"nanny\",\"carpenter\",\"entrepreneur\",\"musician\",\"writer\", \"banker\",\"poet\",\"nurse\"]\n",
    "\n",
    "Foods = [\"steak\", \"bacon\", \"croissant\", \"cheesecake\", \"salad\", \"cheeseburger\", \"vegetables\", \"beer\", \"wine\", \"pastry\"]\n",
    "\n",
    "Sports  = [\"basketball\", \"baseball\", \"boxing\", \"softball\", \"volleyball\", \"tennis\", \"golf\", \"hockey\", \"soccer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define a function to project words in a word list to each of the three dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def makeDF(model, word_list):\n",
    "    g = []\n",
    "    r = []\n",
    "    c = []\n",
    "    for word in word_list:\n",
    "        g.append(sklearn.metrics.pairwise.cosine_similarity(nytimes_model[word].reshape(1,-1), Gender.reshape(1,-1))[0][0])\n",
    "        r.append(sklearn.metrics.pairwise.cosine_similarity(nytimes_model[word].reshape(1,-1), Race.reshape(1,-1))[0][0])\n",
    "        c.append(sklearn.metrics.pairwise.cosine_similarity(nytimes_model[word].reshape(1,-1), Class.reshape(1,-1))[0][0])\n",
    "    df = pandas.DataFrame({'gender': g, 'race': r, 'class': c}, index = word_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Get the projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "OCCdf = makeDF(nytimes_model, Occupations) \n",
    "Fooddf = makeDF(nytimes_model, Foods)\n",
    "Sportsdf = makeDF(nytimes_model, Sports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define some useful functions for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Coloring(Series):\n",
    "    x = Series.values\n",
    "    y = x-x.min()\n",
    "    z = y/y.max()\n",
    "    c = list(plt.cm.rainbow(z))\n",
    "    return c\n",
    "\n",
    "def PlotDimension(ax,df, dim):\n",
    "    ax.set_frame_on(False)\n",
    "    ax.set_title(dim, fontsize = 20)\n",
    "    colors = Coloring(df[dim])\n",
    "    for i, word in enumerate(df.index):\n",
    "        ax.annotate(word, (0, df[dim][i]), color = colors[i], alpha = 0.6, fontsize = 12)\n",
    "    MaxY = df[dim].max()\n",
    "    MinY = df[dim].min()\n",
    "    plt.ylim(MinY,MaxY)\n",
    "    plt.yticks(())\n",
    "    plt.xticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plot the occupational words in each of the three dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,4))\n",
    "ax1 = fig.add_subplot(131)\n",
    "PlotDimension(ax1, OCCdf, 'gender')\n",
    "ax2 = fig.add_subplot(132)\n",
    "PlotDimension(ax2, OCCdf, 'race')\n",
    "ax3 = fig.add_subplot(133)\n",
    "PlotDimension(ax3, OCCdf, 'class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Foods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,4))\n",
    "ax1 = fig.add_subplot(131)\n",
    "PlotDimension(ax1, Fooddf, 'gender')\n",
    "ax2 = fig.add_subplot(132)\n",
    "PlotDimension(ax2, Fooddf, 'race')\n",
    "ax3 = fig.add_subplot(133)\n",
    "PlotDimension(ax3, Fooddf, 'class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,4))\n",
    "ax1 = fig.add_subplot(131)\n",
    "PlotDimension(ax1, Sportsdf, 'gender')\n",
    "ax2 = fig.add_subplot(132)\n",
    "PlotDimension(ax2, Sportsdf, 'race')\n",
    "ax3 = fig.add_subplot(133)\n",
    "PlotDimension(ax3, Sportsdf, 'class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <span style=\"color:red\">*Your Turn*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that identify semantic dimensions of interest from your data (e.g., gender: man-woman) and project words onto these dimensions. Plot the array of relevant words along each semantic dimension. Which words are most different. Which dimensions are most different? On which dimension are your words most different? Print three short textual examples from the corpus that illustrate the association you have explored.\n",
    "\n",
    "<span style=\"color:red\">***Stretch***: Project documents from your corpus along a dimension of interest. Sample relevant documents from your corpus with this functionality and explain your rationale? Calculate the cosine of the angle between two dimensions (encoded as vectors) of interest. What does this suggest about the relationship between them within your corpus? \n",
    "\n",
    "<span style=\"color:red\">***Super stretch***: Create 90% bootstrap confidence intervals around your word projections onto a given dimension by generating 10 separate word2vec models, sampling $n$ documents (the total number in your corpus) for each, but with replacement. The bounds will be defined as the highest and lowest projection across your 10 samples. Which words are *significantly* different on your semantic dimension of interest?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
